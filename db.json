{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/umami-view.js","path":"js/umami-view.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1770053892268},{"_id":"source/_posts/init.md","hash":"50957e0dced31b84eb20247b93d010a43d3479cd","modified":1770057436323},{"_id":"source/.DS_Store","hash":"e947f69ee02bfb0b1ff4b8a0984df6972949d12d","modified":1770059466408},{"_id":"source/_posts/0209-reading.md","hash":"0d2fe2a5457bac6c88fed6c6a45ce4a2f0b06a63","modified":1771146487960},{"_id":"source/_posts/reading-DiT-code.md","hash":"b0337f6f95af06aab78b7a07a85f552838bb7b6a","modified":1770597453044},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770713907241},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"7746460fc2eba7439b494c46aa9b5ded81370819","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"ff9b0e1fb9dba665af2f1e4a577f8cb9e840464b","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"d3e2a04cd39df41297b8e21ae4d25ca4428040ee","modified":1770714280858},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":1770713906643},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":1770713906645},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":1770713906636},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":1770713906646},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"b84d575c7b7f778b4cb64e89ad3d0aed4a896820","modified":1770713906640},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":1770713906658},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":1770713906653},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"052e9fc19c753f53fdc083c7fb098e3668880140","modified":1770713906640},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":1770713906653},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"33c3317cdcee062789de2336dd8d0cc7f86d3650","modified":1770713906653},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1770713906659},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":1770713906656},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"9bf0d357a607a282f3b9cb04525a4df0cc2a8b76","modified":1770713906657},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"58dccef1d98b472dc4e6f4693c2297b0c9c5afba","modified":1770713907242},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"7c1a0c9f6186b6643b19d3980f055329bdb4efa4","modified":1770713907243},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"026ddf1a49bf8ddfef6ed86ab4d6af143c1dd95f","modified":1770713907243},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"9c580471257f5a32bee701a059a45ea96755dcdc","modified":1770713907243},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"e1043de394f6dcf5c0647adcfdefe60637f78426","modified":1770713907244},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"550b95d3614a64592f02666938d235e9f11e449e","modified":1770713907243},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"51c2b4d64c6992a39bfd2586a1bdf5fbbbdf0175","modified":1770713907244},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":1770713906643},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"a60847136709bb95586a98d9d67b50390a8d2c96","modified":1770713907244},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":1770713906646},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":1770713906646},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"1dadb118d580280524ed0a5f69bd34d234a92276","modified":1770713906648},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"93818f8bf07195fb1ebffbb5210e531b0e3a6ec4","modified":1770713907243},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"40c8b0852873032e7aaef3f68e8ea08706cdef13","modified":1770713906650},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"67be642f99482c07904474f410cfbc2f99003288","modified":1770713906652},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"d707c47b2638c94e489bc43d4cfd098b7c58447f","modified":1770713906647},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1770713906656},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d3e75f53c59674d171309e50702954671f31f1a4","modified":1770713906669},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":1770713906652},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":1770713906654},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"9ac5ddad06e9b0e6015ce531430018182a4bc0fa","modified":1770713906668},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":1770713906657},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"82bb06686158ebe160a631c79f156cd4fde35656","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":1770713906664},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"8e67b522c47aa250860e3fe2c733f1f958a506c0","modified":1770713906664},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":1770713906663},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":1770713906664},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1770713906668},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":1770713906667},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/index-generator.js","hash":"9159fc22fa84a7b605dd15fe4104f01fe9c71147","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"966689d7c5e4320008285395fbaa2751f6209be5","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"4d48c424e47ff9a17a563167ea5f480890267adf","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1770713906669},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1770713906662},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"6eaf53cf4bfc756a65bda18184cf8998a12c861d","modified":1770713906662},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1770713906667},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1770713906665},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"e3b456a079e5dc0032473b516c865b20f83d2c26","modified":1770713906669},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":1770713906657},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1770713906663},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/fold.js","hash":"73e4fd12ce3e47981479391ed354b7d9d3279f70","modified":1770713906665},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1770713906668},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":1770713906669},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/crypto.js","hash":"ae4ad8a188ef5b3fa6818b01629fc962b3de8551","modified":1770713906663},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1770713906662},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1770713906664},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1770713906668},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/source/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1770713906670},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1770713906663},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1770713906667},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1770713907241},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1770713907228},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1770713906671},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":1770713907238},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1770713907228},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1770713906661},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1770713906647},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1770713906649},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"954a29b58d72647d20450da270b5d8fb2e0824f5","modified":1770713906658},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":1770713906644},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1770713906653},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1770713906657},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1770713906651},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/discuss.ejs","hash":"98d065b58ce06b7d18bff3c974e96fa0f34ae03a","modified":1770713906649},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"d84bcb5ccd78470a60c067fc914ac0ac67ac8777","modified":1770713906659},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":1770713906660},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1770713906650},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":1770713906660},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":1770713906651},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"cbfa32c5f5973133afd043853b24f8200455cb2d","modified":1770713906648},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"375974ec017696e294dc12469fb0ae257800dc2d","modified":1770713906655},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":1770713906658},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":1770713906646},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"54dd479dbb440126e4ddd9d902229db5afaaae98","modified":1770713906655},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":1770713906658},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":1770713906644},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"e6dcbf1c2f56314d56bb46b50aca86ff68cacebd","modified":1770713906641},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"635a89060fbf72eeda066fc4bd0a97462f069417","modified":1770713906659},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"37d750428772d7c71ba36ce0c2540780d90fadea","modified":1770713906656},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"3d08c73b77e412d2f06a24d9344565fc7dbc76f8","modified":1770713906660},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":1770713906652},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":1770713906654},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"0fff24cf5bf99fbe5c56c292e2eac4a89bf29db4","modified":1770713906650},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":1770713906642},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/moment.ejs","hash":"4ff3fb1b60ccc95a0af3bbdbd0757fedefc088b5","modified":1770713906655},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1770713906656},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":1770713906663},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"c19ac8050b82c3676b0332a56099ccfcc36d9d52","modified":1770713906665},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"bd8376e1cf7892dc2daa58f2f443574be559fdbf","modified":1770713906665},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"03ac02762f801970d1c4e73d6ec8d4c503780e50","modified":1770713906654},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":1770713906647},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"a5fe1deccb73b5f578797dbb11038efc15f63ce8","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":1770713906666},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":1770713906668},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1770713906667},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":1770713906650},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"f345374885cd6a334f09a11f59c443b5d577c06c","modified":1770713906659},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":1770713907234},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1770713907233},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":1770713907234},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1770713906639},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"85492ef64d7e5f70f0f7e46d570bbc911e686d7e","modified":1770713907235},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1770713907233},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1770713907238},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":1770713907238},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1770713907230},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":1770713907234},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/print.styl","hash":"166afbc596ea4b552bad7290ec372d25ec34db7b","modified":1770713907240},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":1770713907232},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":1770713907235},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1770713907241},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"25fb6fa4c783b847c632584c49a7e1593cdb2f5d","modified":1770713907238},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":1770713907236},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"c96d36aa8fe20f0c3c1a29ee2473cd8064b10f73","modified":1770713907240},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":1770713907232},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":1770713907238},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":1770713907233},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"7eee3f78296a3c81849a5415d1d43dcc6e03e6aa","modified":1770713907240},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":1770713907235},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":1770713907235},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"d42b748f2f49ef32aafb1a21d75991d2459da927","modified":1770713907237},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":1770713907236},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":1770713907234},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":1770713907240},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1770713907240},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":1770713907239},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":1770713907241},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1770713907241},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1770713907225},{"_id":"public/local-search.xml","hash":"8fe935ac96bf7f861a6a57af3483a3d8f9a4ddfc","modified":1771147741253},{"_id":"public/2026/02/07/0209-reading/index.html","hash":"f2ca171f9549c0277ff4ca6a7eaaffd3f8674f9c","modified":1771147741253},{"_id":"public/2026/02/06/reading-DiT-code/index.html","hash":"281b2757b0e4bdb33e052663328d06ef11c7ebb2","modified":1771147741253},{"_id":"public/2026/02/03/init/index.html","hash":"b408eabeed07d4726245c7717b25026fde8af099","modified":1771147741253},{"_id":"public/2026/02/03/hello-world/index.html","hash":"a1d55241e57b7d8e3c536d9e71456a4563ce58a1","modified":1771147741253},{"_id":"public/index.html","hash":"61e5100f5bfeb93714373108a05c42200741ee0a","modified":1771147741253},{"_id":"public/archives/index.html","hash":"1c843fbc79526f9785a95077f204ddae04874632","modified":1771147741253},{"_id":"public/archives/2026/index.html","hash":"04ccd9c1dbac354cddcbb7cd51c1c0972b3d8e66","modified":1771147741253},{"_id":"public/archives/2026/02/index.html","hash":"4e8466e3dc7650f8d73c79ef04e54a8a0e54a511","modified":1771147741253},{"_id":"public/404.html","hash":"2d328ac09bc2158479967ea457bd2599d055bf4c","modified":1771147741253},{"_id":"public/tags/index.html","hash":"326a1fad2f68d8c884ef75444a258000b3277393","modified":1771147741253},{"_id":"public/categories/index.html","hash":"62eb22091852c4c65a7c5e547bbccf816fd77929","modified":1771147741253},{"_id":"public/links/index.html","hash":"f3d4d6d991669f731f201ece8d65c154c23eb354","modified":1771147741253},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1771147741253},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1771147741253},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1771147741253},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1771147741253},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1771147741253},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1771147741253},{"_id":"public/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1771147741253},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1771147741253},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1771147741253},{"_id":"public/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1771147741253},{"_id":"public/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1771147741253},{"_id":"public/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1771147741253},{"_id":"public/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1771147741253},{"_id":"public/css/highlight-dark.css","hash":"902294bada4323c0f51502d67cba8c3a0298952f","modified":1771147741253},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1771147741253},{"_id":"public/css/highlight.css","hash":"04d4ddbb5e1d1007447c2fe293ee05aae9b9563e","modified":1771147741253},{"_id":"public/css/main.css","hash":"14ebd9b515085666cee29bbcbe362ad3604ab62a","modified":1771147741253},{"_id":"public/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1771147741253},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1771147741253}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"0209_reading","date":"2026-02-07T13:09:09.000Z","math":true,"_content":"\n## Pre knowledge\n\n光流和PointTracking ：光流指的是在相邻的两张图片 点 $(u_1,v_1)$ 到 点 $(u_2,v_2)$ 所组成的矢量，而pointTracking(2D)指的是更长时的，一个点在所有帧上的轨迹，而不只是关注相邻的两帧。\n\n## 4D表征：\n\nPointWorld：3D点流，分为状态和动作，状态使用场景RGB-D图，动作使用机器人URDF推算\n\nAny4D：视频，深度图，雷达多普勒，相机位姿\n\nUni-Enter：voxel体素\n\nEgo-Twin：视频 + 文本描述 + 骨骼4D\n\nAnimateAnyMesh：关节连接矩阵 + 初始结构点云 + 移动轨迹\n\nDream2Flow：深度图到3D点云 (object flow)\n\nMoCapAnything：骨骼结构、Mesh网格、Image图片；图片帧使用DinoV2编码、视频到Mesh重建\n\nD4RT：连续的视频帧\n\n对于每一篇文章，我们关心两个问题\n\n- 如何表征 4D 的\n  - 数据如何获取，如何得到输入\n  - 如何进行编码，模型的具体架构？\n- 对我们的工作有什么启发\n\n接下来，我们将对每一篇文章展开介绍。\n\n---\n\n### Dream2Flow\n\n这篇工作实现了对机器人要操作的物体的表征，输入是一个初始帧 $I_0$ 然后使用视频生成模型生成 $I_1, I_2, ...$ \n\n> 视频生成：生成目标物体运动的视频\n\n然后用 `SpatialTrackerV2` 得到深度图，用 `Grounding DINO` 得到 **物体的检测框** 进一步用 `SAM2` 得到物体的mask，然后投到3D就得到物体的点云4D序列了。\n\n得到这个4D序列是希望能预测4D的序列，接下来我们关注三种类型的任务，以及我们分别是怎么解决的。\n\n#### Push-T\n\n对于一个在水平面上的物体，给他一个push的力，这坨点云会怎么动？我们的输入是一个14维度的query，包括 3D 的位置，3D的颜色，3D的法向量（取右边和下面的像素点 $B$ 和 $C$，投到3D上，然后计算 \n\n$$\\vec{AB}\\times \\vec{AC} $$\n\n 作用点 $(u,v)$ 和推的方向 $(\\Delta u, \\Delta v)$ 拖拽距离 $d$ \n\n接下来的问题在于模型架构，文中没有明确的说明，只说了基于`PointNet` \n\n猜测：每一个点的信息是各不相同的，但是推动作用点 $(u,v)$ 和推动的方向还有拖拽距离是都一样的，拖拽信息会给每一个点的 `14 dimension` query 都复制一份。然后经过一个 `mlp` ，再来一个全局池化综合一下信息，然后过一个 `mlp` 得到每一个点的位移预测信息。\n\n#### Real-World Domain\n\n任务是抓起来一个物体\n\n做了一些假设：末端执行器（机器人的手）碰到物体就和物体融为一体了，刚体运动。\n\n后续使用的是一个机器人的求解器，基于数学的方法。\n\n---\n\n### PointWorld\n\n论文标题：`PointWorld Scaling 3D World Model for In-The-Wild Robotic Manipulation`\n\n解读标题：\n\n一个 **Scaling** 的3D世界模型，使用了大量的机器人数据，为复杂、多任务的机器人操作任务服务\n\n同样也是用4D点流表征，和 `Dream2Flow` 的区别在于，`Dream2Flow` 好像没有使用什么模型架构，而是提出了一种新的范式，可以使用4D点流作为 `Reward` 实现机器无关的具身智能训练。`PointWorld` 是有模型架构的。\n\n有模型就会有输入输出。\n\n论文中将模型表述为\n$$\nS\\times A\\rightarrow S\n$$\n其中 `S` 表示的是场景的点云， `A` 表示的是 action space\n\n和很多自回归的方法不同，一次性会推断出未来 `H` 步的场景\n\n这里的输入还是4D点流。\n\n对于静态的场景，使用静态点云来表示。使用Point Transformer v3来处理点云。不带点追踪，减轻了很多负担\n\n> Point Transformer v3 （后面称为PTv3）是用来处理点云的 `Transformer` 注意PTv3 的输入是代表点云的语义信息，例如 $N$ 个点的点云，输入就应该是 $(N, hidden\\_size)$  \n\n对于机器人，是带时间序列 `T` 的，对于 $N_R$ 个机器人上的点，就可以出来 $T\\times N_R\\times3$ 的点云，还要进行一系列的特征化\n\n> 注意这里的点是采样过的点，只选择了机器人的夹持器上的点， 因为只有这些点直接与场景进行交互\n\n静态场景的点云是静态的，但是每一个静态的场景会和动态的每一帧进行拼接\n\n得到 $T\\times(N_R+N_S)\\times hidden\\_size$ \n\n这里的机器人点云和场景点云分别进行了不同的特征化：\n\n- 机器人点云编码了位置信息、时间步、颜色标记、法线、速度和加速度\n\n- 场景点云编码了位置信息、2D语义信息、外观特征\n\n而这些可以统一的交给 `PTv3` 可以处理混合编码\n\n---\n\n接下来我们关注 4D 重建的部分论文\n\n### Any4D\n\n[search in alphaxiv](https://www.alphaxiv.org/abs/2512.10935) 25-12-10\n\n这一篇的代码是开源的\n\n论文标题：Any4D: Unified Feed-forward Metric 4D Reconstruction\n\n模型实现了4D场景的重建\n\n可以 fomulate 成下面的形式\n$$\n(\\tilde{s},\\{\\tilde{R}_i, \\tilde{D}_i, \\tilde{T}_i,\\tilde{F}_i\\}^{N}_{i=1})=Any4D(I,O)\n$$\n这里的输入可以分为基础输入 $I$ 和额外输入 $O$ \n\n基础输入是RGB的视频流，$[N,H,W,3]$\n\n此外还可以选择性地输入深度图 + 多普勒流场（速度场）+ 相机位姿（相机外参：分为平移 + 旋转） + Rays场（相机内参）\n\n代码实现中：\n\nOptional Input 使用了两种类型的 `encoder`\n\n对于深度图，Rays场，场景流，使用 `ViTEncoderNonImageInput`\n\n对于 相机位姿（旋转 + 平移）尺度因子使用 `EncoderGlobalRepInput`\n\n论文的 `3.1` 介绍了模型的架构\n\n> 模型的架构分为了三个部分：输入的 `encoder` 中间的 `transformer` 最后输出的对于每一个 view 的`decoder`\n\n#### encoder\n\n图片使用DinoV2 最终编码成 `[hidden_size=1024, H / 14, W / 14]` \n\n其他的模态分别使用 `CNN` 或者 `MLP` 编码成相同的维度\n\n> 深度图：对于每一个 view 做独立的归一化，然后使用一个 `shallow CNN` 进行编码\n>\n> 多普勒(Doppler Velocity, 速度场)：对第一个view做归一化，然后往后的所有view沿用第一个view的归一化的参数，同样使用 `CNN based Encoder`\n>\n> 相机内参：相机的内参和rays是可以可逆转换的，这里使用rays（射线场）来表征，同样使用 `CNN` 把 3 channels map到 1024的hidden_size\n>\n> 相机位姿：分别使用两个 四层的MLP，把维度拉到 1024，使用全局（所有views）的归一化，同时加入一个表征当前是第几帧的position embedding\n>\n> metric scale token：深度图和相机位姿的归一化分别可以得到一个 `s` 然后使用两个 `MLP` 就可以得到 1024 的latent 了\n\n然后得到若干独立的 `tokens`\n\n把这些tokens直接相加，对于每一个 `view` 就可以得到 `[hidden_size=1024, H/14, W/14]`\n\n把后两个维度展平，对于每一个 `view` 可以得到 `[M = H / 14 * W / 14, hidden_size = 1024]` \n\n也就是，对于每一个view，可以得到 `M` 个 `token` ，每个 `token` 维度为 `(1024, )` \n\n总共有 `N` 个 `view` ，就会有 $N\\times M$ 个token\n\n#### transformer\n\n使用一个交替注意力transformer (alternating-attention transformer)\n\n输入是 $N\\times M + 1$ 个token，还有一个是一个 `learnable` 的参数，来表示 `scale`\n\n#### output representation head\n\n**Geometry DPT Head** \n\n预测每一个view 的深度图 $D$ 和 射线图 $R$ 以及一个 $confidence$ 表示置信度\n\n> DPT: Dense Point Transformer: 使用transformer 来实现逐个像素的预测输出\n\n**Motion DPT Head**\n\n输出每一个点的场景流 $F_i$\n\n- 以第一帧确定世界坐标系（第一帧图片的中心）\n- 只track第一帧中出现的点\n\n> 这里的输出是一个 `[N, 3, H, W]` 的格式\n>\n> 表示的是这个点相对于第一帧，在 $x,y,z$ 三个方向上发生的偏移\n\n**Pose Decoder**\n\n平均池化的 `CNN`\n\n输出 up-to-scale 比例缩放的 相机位移和相机旋转 $T_i$\n\n**Metric Scale Decoder**\n\n一个 lightweight 的 MLP 用于预测scale系数的log值（原来的数字很大）\n\n总结来说，我们得到了以下的输出\n\n- scale缩放系数 $S$\n- 相机的位姿 $T$ 相机外参\n- 射线图 $R$ 相机内参\n\n- 深度图 $D$\n- 场景流 $F$ \n\n我们来试试完成4D重建的任务，这些条件是否充分(当然是充分的hhh)\n\n完成一个场景的重建\n$$\nSceneRecon = D\\times S\\times (T\\times R)\n$$\n场景中像素的真实运动\n$$\nMotion=S\\times F\n$$\n动态4D预测\n$$\nSceneRecon'=SceneRecon + Motion\n$$\n\n\n---\n\n### D4RT\n\n---\n\n### AnimateAnyMesh\n\n这一篇的代码是开源的\n\n对主体的表征不需要骨骼！\n\n理论上只要有点云，有Mesh就能做～其中点云需要是带pointTracking的4D序列才行\n\n输入包括三个部分\n\n- 主体的Mesh网格\n\n  - >  这里其实用Mesh来建立图的邻接关系，表征主体的拓扑结构，代替了骨骼的作用？\n\n- 点云(initial 点云)\n\n- 点云的运动序列\n\n**overview：**\n\n首先训练 `encoder` 和 `decoder` 实现将一个运动序列编码为 `latent` 在 decode 出来\n\n这里没有使用 bone，需要的是mesh 网格；\n\n什么是 `mesh` 就是在 pointCloud 的基础上，添加三角面片，有了这些三角面片实际上相当于把孤立的点云表示建模成了类似 graph 的结构\n\n然后使用 DiT 去生成运动序列的 `latent` 然后再使用训练好的 `decoder` 就好了\n\n需要用 text 去引导diffusion 的过程，这里使用的是 MMDiT，Rectified Flow\n\n训练 `MMDiT` 生成从 noise 到生成目标的方向向量\n\n\n\n#### DyMeshVAE\n\n**encode**\n\n```python\ndef encode(self, pc, faces=None, valid_mask=None, adj_matrix=None):\n        # pc 维度: [B, T, N, 3] (输入动态序列)\n        B, T, N, D = pc.shape\n        device = pc.device\n```\n\n模型的输入如此，传入的点云形状是 `[B, T, N, D]` \n\n然后得到第一帧的点云\n\n```python\n        # 1. 提取初始帧\n        pc0 = pc[:, 0]  # [B, N, 3]\n```\n\n接下来是得到每一帧想对于初始帧的相对位移\n\n```python\n# 2. 计算相对轨迹（差分）并展平时间维度\n        # (pc - pc[:, :1]) -> [B, T, N, 3] (每一帧减去第一帧)\n        # .permute(0, 2, 1, 3) -> [B, N, T, 3]\n        # .flatten(2, 3) -> [B, N, T*3]\n        pct_rel = (pc - pc[:, :1]).permute(0, 2, 1, 3).flatten(2, 3) # [B, N, T*3]\n```\n\n对初始点云和轨迹点云分别进行embed\n\n```python\n       # 3. 映射到特征空间 (Embedding)\n        pc0_embed = self.point_embed(pc0)      # [B, N, C]\n        pct_embed = self.traj_embed(pct_rel)   # [B, N, C]\n```\n\n`pc0_embed` 和 `pct_embed` 分别代表了主体的静态点云信息和轨迹信息\n\n如果有 `adj_matrix` 的话，需要对 `pc0_embed` 做 `self-attention` 然后把 `adj_matrix` 作为 `mask`\n\n> 需要让 `pc0_embed` 了解拓扑信息，比如手指上的关节的两个点距离和手指上的一个点和大腿上的一个点的距离都很近，但是手指上的关节的两个点是要一起运动的，而手指和大腿是不会一起运动的\n\n```python\n# 4. 拓扑信息聚合 (公式 2: 结合 Adj 矩阵的 Self-Attention)\n        if adj_matrix is not None:\n            # adj_matrix 维度: [B, N, N]\n            for neighbor_layer in self.neighbor_layers:\n                # 这里的 mask 确保只在相连顶点间算 Attention\n                pc0_embed_res = neighbor_layer(pc0_embed, key=pc0_embed, value=pc0_embed, mask=adj_matrix) # [B, N, C]\n                pc0_embed = pc0_embed + pc0_embed_res # [B, N, C]\n```\n\n过 `n` 遍 `self-attention` + 残差连接，修改结果保存在 `pc0_embed`\n\n接下来要做最远点采样，我们先保存一版采样前的结果\n\n```python\n# 保存全量顶点特征，用于后续 Cross-Attention 的 Key 和 Value\n        pc0_embed_ori = pc0_embed # [B, N, C]\n        pct_embed_ori = pct_embed # [B, N, C]\n```\n\n然后应用最远点采样，得到采样结果 `idx` 然后更新 `pc0_embed` 和 `pct_embed` \n\n```python\n# 5. 最远点采样 (FPS)\n        with torch.no_grad():\n            valid_length = valid_mask.sum(dim=-1)\n            # 从 N 个点中选出 K 个代表点的索引\n            _, idx = ops.sample_farthest_points(points=pc0_embed, lengths=valid_length, K=self.num_traj) \n            # idx 维度: [B, K]\n            idx = replace_negative_indices(idx, valid_length)\n\n        # 6. 根据索引提取代表点的特征 (Gather)\n        # pc0_embed: [B, K, C]\n        pc0_embed = torch.gather(pc0_embed, 1, idx.unsqueeze(-1).expand(-1, -1, pc0_embed.shape[-1]))\n        # pct_embed: [B, K, C]\n        pct_embed = torch.gather(pct_embed, 1, idx.unsqueeze(-1).expand(-1, -1, pct_embed.shape[-1]))\n\n```\n\n这时， `pc0_embed` 是采样后的版本，`pc0_embed_ori` 存储采样前的结果\n\n接下来做 `cross_attention`\n\n- Query = pc0_embed （采样后）\n- Key = pc0_embed_ori (采样前)\n- Value1 = pc0_embed_ori(采样前)\n- Value2 = pct_embed_ori(采样前)\n\n每次过完一个 `attention` 后接一个前馈网络\n\n```python\n# 7. 编码器块 (公式 3 & 4: Cross-Attention 聚合全局信息)\n        for enc_attn, enc_ffn in self.enc_blocks:\n            # q_stream: 代表点 [B, K, C]\n            # k/v_stream: 原始全量点 [B, N, C]\n            attn_res_0, attn_res_t = enc_attn(\n                q_stream=pc0_embed, \n                k_stream=pc0_embed_ori, \n                v1_stream=pc0_embed_ori, \n                v2_stream=pct_embed_ori\n            )\n            pc0_embed = pc0_embed + attn_res_0 # [B, K, C]\n            pct_embed = pct_embed + attn_res_t # [B, K, C]\n            \n            # FFN 层处理\n            ffn_res_0, ffn_res_t = enc_ffn(pc0_embed, pct_embed) # [B, K, C]\n            pc0_embed = pc0_embed + ffn_res_0 # [B, K, C]\n            pct_embed = pct_embed + ffn_res_t # [B, K, C]\n```\n\n接下来我们需要一个latent来表征原始的静态结构，直接全连接就好了\n\n这大概是一个重建任务吧，所以没有什么不确定性，目标是和原本的初始动作一样就好了\n\n```python\n# 8. VAE 潜在空间映射 (公式 5 & 6)\n        # 形状特征 x0: 不做 KL 约束\n        x0 = self.mean_fc_x0(pc0_embed) # [B, K, C_latent]\n```\n\n接下来是轨迹采样，需要有不确定性了\n\nVAE采样过程：\n\n- 得到 `mean` 和 `logvar`\n\n```python\nmean = self.mean_fc_xt(pct_embed)\nlogvar = self.logvar_fc_xt(pct_embed)\n```\n\n- 接下来是采样\n\n> 直接采样高斯分布是不可导的，所以需要使用重参数化\n>\n> ```python\n> # 无法求梯度\n> z = torch.normal(mean=mean, std=std)\n> # 先采样一个随机噪声（不参与梯度的计算）\n> epsilon = torch.randn_like(mean)\n> z = mean + torch.exp(0.5*logvar) * epsilon\n> ```\n\n```python\n# 重参数化采样 (Reparameterization)\n  posterior = DiagonalGaussianDistribution(mean, logvar)\n  xt = posterior.sample() # [B, K, C_latent]\n  kl = posterior.kl()     # [B, K] 或标量\n```\n\n最后把 $x_0$ 和 $x_t$ 拼接在一起\n\n返回 `kl` encode的最终结果`x` 采样的结果 `idx` ，原始的未采样的 `pc0_embed_ori`  \n\n**decode**\n\n定义及传入参数\n\n- encode 中拼接了初始的 $x_0$ 和 $x_t$ 得到这里输入的 `x`\n- queries 是原始的 `N` 个点 $[B,N,3]$\n- pc0_embed_ori 是特征增强的原始的 `N` 个点 `[B,N,C]`\n\n```python\ndef decode(self, x, queries, pc0_embed_ori):\n```\n\n首先拆掉拼接在一起的 $x_0$ 和 $x_t$ \n\n然后把他们从 `C_latent` 维度投影到 `C` 维度\n\n```python\n# 1. 拆分形状 Latent 和 动作 Latent\n  x0_latent, xt_latent = x.chunk(2, dim=-1) # 分别为 [B, K, C_latent]\n\n  # 2. 投影回隐藏层维度\n  x0 = self.proj_x0(x0_latent) # [B, K, C]\n  xt = self.proj_xt(xt_latent) # [B, K, C]\n```\n\n然后是解码自注意力\n\n```python\n# 3. 解码器自注意力块 (代表点之间进行信息交换)\nfor dec_attn, dec_ffn in self.dec_blocks:\n    # Self-Attention: 代表点之间互相观察，优化动作逻辑\n    attn_res_0, attn_res_t = dec_attn(\n        q_stream=x0, \n        k_stream=x0, \n        v1_stream=x0, \n        v2_stream=xt\n    )\n    x0 = x0 + attn_res_0 # [B, K, C]\n    xt = xt + attn_res_t # [B, K, C]\n\n    # FFN 层\n    ffn_res_0, ffn_res_t = dec_ffn(x0, xt)\n    x0 = x0 + ffn_res_0 # [B, K, C]\n    xt = xt + ffn_res_t # [B, K, C]\n```\n\n把全量点的形状特征作为 `Query`\n\n使用 `cross-attention` \n\n$x_0$ 作为 `Key` \n\n而轨迹的特征 $x_t$ 作为 `Value`\n\n使得每一个点(全量)都能查询到关于运动轨迹的信息\n\n```python\n# 4. 最终交叉注意力 (从 K 个代表点上采样到 N 个原始点)\n  # query_embed: 将全量点的形状特征作为查询 [B, N, C]\n  query_embed = self.fc_query(pc0_embed_ori) # [B, N, C]\n\n  # Cross-Attention: \n  # 每个原始点 (N) 去询问代表点 (K)：“我该怎么动？”\n  # key=x0 (形状参考), value=xt (动作参考)\n  latents = self.decoder_final_ca(query_embed, key=x0, value=xt) # [B, N, C]\n```\n\n这时，每个点都得到了关于运动轨迹的信息，就可以开始做输出了\n\n其实就是在后面接一个 `Linear` (不是`mlp`)\n\n```python\n# 5. 投影到 3D 坐标偏移空间\n# self.to_outputs 将 C 维映射到 (T-1)*3 维\noutputs = self.to_outputs(latents) # [B, N, (T-1)*3]\n```\n\n然后就是调整一下维度 由于我们得到的都是相对于第一帧的位置偏移，所以`outputs` 中的每一个输出都要与第一帧的点云相加，才能得到4D的运动序列\n\n```python\n# 6. 重塑维度还原为序列格式\n# .view(...) -> [B, N, T-1, 3]\n# .permute(0, 2, 1, 3) -> [B, T-1, N, 3] (时间维度排在前面)\noutputs = outputs.view(x.shape[0], queries.shape[1], -1, 3).permute(0, 2, 1, 3) # [B, T-1, N, 3]\n\n# 7. 合成最终动画 (公式 1)\n# queries[:, None] 维度是 [B, 1, N, 3] (初始帧)\n# 将初始位置与每一帧的相对位移相加\noutputs = queries[:, None] + outputs # [B, T-1, N, 3]\n\nreturn outputs # 返回完整的动态序列 (不含第一帧，或根据实现包含第一帧)\n```\n\n#### Shape-Guided Text-to-Trajectory Model\n\n基于 `MMDiT`  \n\n> 传统的 `DiT` 对 `image` 做 self attention 然后对 `text` 做 `cross attention` 其中 image 是主体 text 是条件\n>\n> MMDiT: MultiModel DiT\n>\n> 把 `text` 和 `image` 同时做 `self-attention`\n>\n> 传统的 `DiT` 只有 `image` 到 `text` 的 query\n>\n> 而在MMDiT中，同时存在\n>\n> - image -> image\n> - Text -> text\n> - image -> text\n> - Text -> image\n>\n> 的query\n\n**整体结构**\n\n```tex\n输入: x (动作Latent噪声) [B,K,C], t (时间步) [B], texts (文本列表)\n                          │\n          ┌───────────────┼───────────────┐\n          ▼               ▼               ▼\n    timestep_embedding  CLIP Text       input_proj\n    + time_embed(MLP)   Encoder         (Linear)\n          │             + clip_token_mlp      │\n          ▼               ▼               ▼\n        t_emb          text_embed          h\n       [B, W]          [B, 77, W]       [B, K, W]\n          │               │               │\n          └───────┬───────┘               │\n                  ▼                       ▼\n            ┌─────────────────────────────────┐\n            │   Transformer_cogx (×N layers)  │\n            │   CogXAttentionBlock:           │\n            │     - AdaLN-Zero (x & text)     │\n            │     - Joint Self-Attention       │\n            │     - Joint MLP                  │\n            └─────────────────────────────────┘\n                          │\n                    output_proj → 预测噪声/速度场 [B, K, C]\n```\n\n这一部分考虑了文本信息和静态结构，输出是一个速度场，用来为扩散过程提供指导。\n\n每一步扩散都会调用这个 `MMDiT` 得到引导\n\n#### **Diffusion Pipeline**\n\nTraining\n\n得到时间步\n\n```python\n# ---- 1. 采样时间步 ----\n    times = torch.rand(x_start.shape[0], device=x_start.device)  # [B] — t ~ U(0,1)\n    padded_times = append_dims(times, x_start.ndim - 1)           # [B, 1, 1] — 扩展维度以广播\n    \n    # ---- 2. 构造加噪样本 ----\n    t = cosmap(padded_times)                           # [B, 1, 1] — cosine 重映射后的时间步\n    x_t = t * x_start + (1. - t) * noise              # [B, K, C] — 线性插值 (t=1→数据, t=0→噪声)\n    \n    # ---- 3. 保护 f0 通道: 用原始 x_start 的 f0 替换加噪版本 ----\n    # x_start[:, :, :f0_channels] → [B, K, f0] 静态形状，不加噪\n    # x_t[:, :, f0_channels:]     → [B, K, ft] 动态运动，已加噪\n    x_t = torch.cat([x_start[:, :, :f0_channels], x_t[:, :, f0_channels:]], dim=-1)  # [B, K, C]\n```\n\n其中 `cosmap` 会做时间步的重映射，中间的时间步 例如 $t=0.5$ 会被采样得更多\n\n$x_t$ 会得到 静态形状 + 动态运动的混合张量，只有动态运动的部分混上噪声\n\n然后计算 `flow` 也就是从 `noise` 到 `x_start` 的直线方向\n\n```python\n# ---- 4. 计算目标 flow ----\n    flow = x_start - noise     \n```\n\n然后使用 `DyMeshMMDiT` 考虑 `text` 、 运动轨迹，期望得到的是从 `noise` 到 `x_start` 或者预测结果的 方向向量\n\n```python\n# ---- 5. 模型前向传播 ----\n# model = DyMeshMMDiT, 调用其 forward(x_t, t, texts=...)\nmodel_output = model(                              # [B, K, C] — 模型预测的 flow 或 noise\n    x_t,                                           # [B, K, C] — 加噪样本 (f0 未加噪)\n    t.squeeze(-1).squeeze(-1),                     # [B]       — 时间步 (去掉扩展的维度)\n    **model_kwargs\n)\n```\n\n然后把 `model_output` 和实际得到的 `flow` 去做 `mse` 得到 `loss`\n\n```python\n# ---- 6. 选择预测目标 ----\nif predict == 'flow':\n    target = flow                                  # [B, K, C] — 目标: x_start - noise\nelif predict == 'noise':\n    target = noise                                 # [B, K, C] — 目标: 噪声本身\nelse:\n    raise ValueError(f'unknown objective {predict}')\n\n# ---- 7. 计算 MSE 损失 (仅在 ft 动态通道上) ----\nft_channels = x_start.shape[-1] - f0_channels      # ft 通道数 = C - f0\n# 只取最后 ft_channels 个通道计算损失，忽略 f0 (静态形状不需要预测)\nterms[\"mse\"] = mean_flat(                          # [B] — 逐样本 MSE\n    (target[:, :, -ft_channels:] - model_output[:, :, -ft_channels:]) ** 2\n)                                                  # target/output 切片: [B, K, ft]\n\nterms[\"loss\"] = terms[\"mse\"]                       # [B]\n\nreturn terms\n```\n\n训练的结果就是 `DyMeshMMDiT` 学会了生成 `flow` \n\n> Flow =>也就是 `noise` 到目标 `latent` （运动轨迹）的直线方向。\n\n### EgoTwin\n\n标题：EgoTwin: Dreaming Body and View in First Person\n\n生成第一人称视角的视频\n\n有两个**对齐**的挑战，一个是相机轨迹(决定了相机拍到什么)和人体的头部运动的对齐\n\n二是人体与环境交互的动作和环境变化的对齐（因果交互）\n\n#### 问题定义\n\n输入\n\n- 骨骼序列\n- RGB ego View 首帧\n- Text Prompt\n\n输出\n\n- 骨骼运动序列 4D  pose sequence\n- RGB ego 视频 view sequence\n\n#### Modality Tokenization 不同模态怎么做tokenization\n\n**视频** 使用 3D VAE，使用 $4\\times 8\\times 8$ 的压缩率\n\n> `3D VAE` 传统的 VAE 处理二维图像，3D考虑了时间维度\n\n**文本** 使用 `T5-XXL` \n\n##### motion representation 动作表征\n\n> 传统表征：过参数化，记录七个参数\n>\n> 1. 根部转圈的角速度\n> 2. 走位的速度，根部的平面线速度\n> 3. 根部的高度(屁股的高度)\n> 4. 关节的位置（除了屁股之外，其他关节相对于屁股的位置）\n> 5. 局部关节的速度\n> 6. 局部关节的旋转\n> 7. 脚与地面是否接触\n\n传统表示难以做到与 `ego view` 做对齐，需要 `head-centric` 以头部为中心\n\n> 1. 头部的移动\n> 2. 头部的速度\n> 3. 头部的旋转角度\n> 4. 头部的旋转速度\n> 5. 关节的位置  => 关节是以头为参考系的相对表示\n> 6. 关节的速度\n> 7. 关节的旋转\n\n##### motion tokenization\n\n> causal 1D CNN 处理音频或着视频生成\n>\n> 普通的 `CNN`  => 模型可以看到 $t-1, t, t+1$ 但是在生成任务中，看不到未来的数据！\n>\n> 做法：\n>\n> 左侧填充 $k-1$ 个 0， 每次运算只涉及 $t-k+1, ... , t$ 的数据\n\n\n\n\n\n\n\n我们想要做的是可交互的4D生成。从具体的任务而言，包括应用于具身的任务 一般场景的4D重建 主体的运动4D生成\n\n具身的任务是指对场景，机器人等做4D的表征，让模型了解这一个场景，然后做出决策，例如Dream2Flow、PointWorld\n\n一般场景的4D重建包括 Any4D、D4RT、TrackingWorld。\n\n这两种任务关注于对场景的表征，而主体的运动4D生成更加关注于对于特定主体的表征，往往需要添加骨骼信息，运动序列，而不仅仅是4D点流了，包括 `AnimateAnyMesh` `EgoTwin` `Uni-Inter` `Mo-CapAnything` \n","source":"_posts/0209-reading.md","raw":"---\ntitle: 0209_reading\ndate: 2026-02-07 21:09:09\ntags:\nmath: true\n---\n\n## Pre knowledge\n\n光流和PointTracking ：光流指的是在相邻的两张图片 点 $(u_1,v_1)$ 到 点 $(u_2,v_2)$ 所组成的矢量，而pointTracking(2D)指的是更长时的，一个点在所有帧上的轨迹，而不只是关注相邻的两帧。\n\n## 4D表征：\n\nPointWorld：3D点流，分为状态和动作，状态使用场景RGB-D图，动作使用机器人URDF推算\n\nAny4D：视频，深度图，雷达多普勒，相机位姿\n\nUni-Enter：voxel体素\n\nEgo-Twin：视频 + 文本描述 + 骨骼4D\n\nAnimateAnyMesh：关节连接矩阵 + 初始结构点云 + 移动轨迹\n\nDream2Flow：深度图到3D点云 (object flow)\n\nMoCapAnything：骨骼结构、Mesh网格、Image图片；图片帧使用DinoV2编码、视频到Mesh重建\n\nD4RT：连续的视频帧\n\n对于每一篇文章，我们关心两个问题\n\n- 如何表征 4D 的\n  - 数据如何获取，如何得到输入\n  - 如何进行编码，模型的具体架构？\n- 对我们的工作有什么启发\n\n接下来，我们将对每一篇文章展开介绍。\n\n---\n\n### Dream2Flow\n\n这篇工作实现了对机器人要操作的物体的表征，输入是一个初始帧 $I_0$ 然后使用视频生成模型生成 $I_1, I_2, ...$ \n\n> 视频生成：生成目标物体运动的视频\n\n然后用 `SpatialTrackerV2` 得到深度图，用 `Grounding DINO` 得到 **物体的检测框** 进一步用 `SAM2` 得到物体的mask，然后投到3D就得到物体的点云4D序列了。\n\n得到这个4D序列是希望能预测4D的序列，接下来我们关注三种类型的任务，以及我们分别是怎么解决的。\n\n#### Push-T\n\n对于一个在水平面上的物体，给他一个push的力，这坨点云会怎么动？我们的输入是一个14维度的query，包括 3D 的位置，3D的颜色，3D的法向量（取右边和下面的像素点 $B$ 和 $C$，投到3D上，然后计算 \n\n$$\\vec{AB}\\times \\vec{AC} $$\n\n 作用点 $(u,v)$ 和推的方向 $(\\Delta u, \\Delta v)$ 拖拽距离 $d$ \n\n接下来的问题在于模型架构，文中没有明确的说明，只说了基于`PointNet` \n\n猜测：每一个点的信息是各不相同的，但是推动作用点 $(u,v)$ 和推动的方向还有拖拽距离是都一样的，拖拽信息会给每一个点的 `14 dimension` query 都复制一份。然后经过一个 `mlp` ，再来一个全局池化综合一下信息，然后过一个 `mlp` 得到每一个点的位移预测信息。\n\n#### Real-World Domain\n\n任务是抓起来一个物体\n\n做了一些假设：末端执行器（机器人的手）碰到物体就和物体融为一体了，刚体运动。\n\n后续使用的是一个机器人的求解器，基于数学的方法。\n\n---\n\n### PointWorld\n\n论文标题：`PointWorld Scaling 3D World Model for In-The-Wild Robotic Manipulation`\n\n解读标题：\n\n一个 **Scaling** 的3D世界模型，使用了大量的机器人数据，为复杂、多任务的机器人操作任务服务\n\n同样也是用4D点流表征，和 `Dream2Flow` 的区别在于，`Dream2Flow` 好像没有使用什么模型架构，而是提出了一种新的范式，可以使用4D点流作为 `Reward` 实现机器无关的具身智能训练。`PointWorld` 是有模型架构的。\n\n有模型就会有输入输出。\n\n论文中将模型表述为\n$$\nS\\times A\\rightarrow S\n$$\n其中 `S` 表示的是场景的点云， `A` 表示的是 action space\n\n和很多自回归的方法不同，一次性会推断出未来 `H` 步的场景\n\n这里的输入还是4D点流。\n\n对于静态的场景，使用静态点云来表示。使用Point Transformer v3来处理点云。不带点追踪，减轻了很多负担\n\n> Point Transformer v3 （后面称为PTv3）是用来处理点云的 `Transformer` 注意PTv3 的输入是代表点云的语义信息，例如 $N$ 个点的点云，输入就应该是 $(N, hidden\\_size)$  \n\n对于机器人，是带时间序列 `T` 的，对于 $N_R$ 个机器人上的点，就可以出来 $T\\times N_R\\times3$ 的点云，还要进行一系列的特征化\n\n> 注意这里的点是采样过的点，只选择了机器人的夹持器上的点， 因为只有这些点直接与场景进行交互\n\n静态场景的点云是静态的，但是每一个静态的场景会和动态的每一帧进行拼接\n\n得到 $T\\times(N_R+N_S)\\times hidden\\_size$ \n\n这里的机器人点云和场景点云分别进行了不同的特征化：\n\n- 机器人点云编码了位置信息、时间步、颜色标记、法线、速度和加速度\n\n- 场景点云编码了位置信息、2D语义信息、外观特征\n\n而这些可以统一的交给 `PTv3` 可以处理混合编码\n\n---\n\n接下来我们关注 4D 重建的部分论文\n\n### Any4D\n\n[search in alphaxiv](https://www.alphaxiv.org/abs/2512.10935) 25-12-10\n\n这一篇的代码是开源的\n\n论文标题：Any4D: Unified Feed-forward Metric 4D Reconstruction\n\n模型实现了4D场景的重建\n\n可以 fomulate 成下面的形式\n$$\n(\\tilde{s},\\{\\tilde{R}_i, \\tilde{D}_i, \\tilde{T}_i,\\tilde{F}_i\\}^{N}_{i=1})=Any4D(I,O)\n$$\n这里的输入可以分为基础输入 $I$ 和额外输入 $O$ \n\n基础输入是RGB的视频流，$[N,H,W,3]$\n\n此外还可以选择性地输入深度图 + 多普勒流场（速度场）+ 相机位姿（相机外参：分为平移 + 旋转） + Rays场（相机内参）\n\n代码实现中：\n\nOptional Input 使用了两种类型的 `encoder`\n\n对于深度图，Rays场，场景流，使用 `ViTEncoderNonImageInput`\n\n对于 相机位姿（旋转 + 平移）尺度因子使用 `EncoderGlobalRepInput`\n\n论文的 `3.1` 介绍了模型的架构\n\n> 模型的架构分为了三个部分：输入的 `encoder` 中间的 `transformer` 最后输出的对于每一个 view 的`decoder`\n\n#### encoder\n\n图片使用DinoV2 最终编码成 `[hidden_size=1024, H / 14, W / 14]` \n\n其他的模态分别使用 `CNN` 或者 `MLP` 编码成相同的维度\n\n> 深度图：对于每一个 view 做独立的归一化，然后使用一个 `shallow CNN` 进行编码\n>\n> 多普勒(Doppler Velocity, 速度场)：对第一个view做归一化，然后往后的所有view沿用第一个view的归一化的参数，同样使用 `CNN based Encoder`\n>\n> 相机内参：相机的内参和rays是可以可逆转换的，这里使用rays（射线场）来表征，同样使用 `CNN` 把 3 channels map到 1024的hidden_size\n>\n> 相机位姿：分别使用两个 四层的MLP，把维度拉到 1024，使用全局（所有views）的归一化，同时加入一个表征当前是第几帧的position embedding\n>\n> metric scale token：深度图和相机位姿的归一化分别可以得到一个 `s` 然后使用两个 `MLP` 就可以得到 1024 的latent 了\n\n然后得到若干独立的 `tokens`\n\n把这些tokens直接相加，对于每一个 `view` 就可以得到 `[hidden_size=1024, H/14, W/14]`\n\n把后两个维度展平，对于每一个 `view` 可以得到 `[M = H / 14 * W / 14, hidden_size = 1024]` \n\n也就是，对于每一个view，可以得到 `M` 个 `token` ，每个 `token` 维度为 `(1024, )` \n\n总共有 `N` 个 `view` ，就会有 $N\\times M$ 个token\n\n#### transformer\n\n使用一个交替注意力transformer (alternating-attention transformer)\n\n输入是 $N\\times M + 1$ 个token，还有一个是一个 `learnable` 的参数，来表示 `scale`\n\n#### output representation head\n\n**Geometry DPT Head** \n\n预测每一个view 的深度图 $D$ 和 射线图 $R$ 以及一个 $confidence$ 表示置信度\n\n> DPT: Dense Point Transformer: 使用transformer 来实现逐个像素的预测输出\n\n**Motion DPT Head**\n\n输出每一个点的场景流 $F_i$\n\n- 以第一帧确定世界坐标系（第一帧图片的中心）\n- 只track第一帧中出现的点\n\n> 这里的输出是一个 `[N, 3, H, W]` 的格式\n>\n> 表示的是这个点相对于第一帧，在 $x,y,z$ 三个方向上发生的偏移\n\n**Pose Decoder**\n\n平均池化的 `CNN`\n\n输出 up-to-scale 比例缩放的 相机位移和相机旋转 $T_i$\n\n**Metric Scale Decoder**\n\n一个 lightweight 的 MLP 用于预测scale系数的log值（原来的数字很大）\n\n总结来说，我们得到了以下的输出\n\n- scale缩放系数 $S$\n- 相机的位姿 $T$ 相机外参\n- 射线图 $R$ 相机内参\n\n- 深度图 $D$\n- 场景流 $F$ \n\n我们来试试完成4D重建的任务，这些条件是否充分(当然是充分的hhh)\n\n完成一个场景的重建\n$$\nSceneRecon = D\\times S\\times (T\\times R)\n$$\n场景中像素的真实运动\n$$\nMotion=S\\times F\n$$\n动态4D预测\n$$\nSceneRecon'=SceneRecon + Motion\n$$\n\n\n---\n\n### D4RT\n\n---\n\n### AnimateAnyMesh\n\n这一篇的代码是开源的\n\n对主体的表征不需要骨骼！\n\n理论上只要有点云，有Mesh就能做～其中点云需要是带pointTracking的4D序列才行\n\n输入包括三个部分\n\n- 主体的Mesh网格\n\n  - >  这里其实用Mesh来建立图的邻接关系，表征主体的拓扑结构，代替了骨骼的作用？\n\n- 点云(initial 点云)\n\n- 点云的运动序列\n\n**overview：**\n\n首先训练 `encoder` 和 `decoder` 实现将一个运动序列编码为 `latent` 在 decode 出来\n\n这里没有使用 bone，需要的是mesh 网格；\n\n什么是 `mesh` 就是在 pointCloud 的基础上，添加三角面片，有了这些三角面片实际上相当于把孤立的点云表示建模成了类似 graph 的结构\n\n然后使用 DiT 去生成运动序列的 `latent` 然后再使用训练好的 `decoder` 就好了\n\n需要用 text 去引导diffusion 的过程，这里使用的是 MMDiT，Rectified Flow\n\n训练 `MMDiT` 生成从 noise 到生成目标的方向向量\n\n\n\n#### DyMeshVAE\n\n**encode**\n\n```python\ndef encode(self, pc, faces=None, valid_mask=None, adj_matrix=None):\n        # pc 维度: [B, T, N, 3] (输入动态序列)\n        B, T, N, D = pc.shape\n        device = pc.device\n```\n\n模型的输入如此，传入的点云形状是 `[B, T, N, D]` \n\n然后得到第一帧的点云\n\n```python\n        # 1. 提取初始帧\n        pc0 = pc[:, 0]  # [B, N, 3]\n```\n\n接下来是得到每一帧想对于初始帧的相对位移\n\n```python\n# 2. 计算相对轨迹（差分）并展平时间维度\n        # (pc - pc[:, :1]) -> [B, T, N, 3] (每一帧减去第一帧)\n        # .permute(0, 2, 1, 3) -> [B, N, T, 3]\n        # .flatten(2, 3) -> [B, N, T*3]\n        pct_rel = (pc - pc[:, :1]).permute(0, 2, 1, 3).flatten(2, 3) # [B, N, T*3]\n```\n\n对初始点云和轨迹点云分别进行embed\n\n```python\n       # 3. 映射到特征空间 (Embedding)\n        pc0_embed = self.point_embed(pc0)      # [B, N, C]\n        pct_embed = self.traj_embed(pct_rel)   # [B, N, C]\n```\n\n`pc0_embed` 和 `pct_embed` 分别代表了主体的静态点云信息和轨迹信息\n\n如果有 `adj_matrix` 的话，需要对 `pc0_embed` 做 `self-attention` 然后把 `adj_matrix` 作为 `mask`\n\n> 需要让 `pc0_embed` 了解拓扑信息，比如手指上的关节的两个点距离和手指上的一个点和大腿上的一个点的距离都很近，但是手指上的关节的两个点是要一起运动的，而手指和大腿是不会一起运动的\n\n```python\n# 4. 拓扑信息聚合 (公式 2: 结合 Adj 矩阵的 Self-Attention)\n        if adj_matrix is not None:\n            # adj_matrix 维度: [B, N, N]\n            for neighbor_layer in self.neighbor_layers:\n                # 这里的 mask 确保只在相连顶点间算 Attention\n                pc0_embed_res = neighbor_layer(pc0_embed, key=pc0_embed, value=pc0_embed, mask=adj_matrix) # [B, N, C]\n                pc0_embed = pc0_embed + pc0_embed_res # [B, N, C]\n```\n\n过 `n` 遍 `self-attention` + 残差连接，修改结果保存在 `pc0_embed`\n\n接下来要做最远点采样，我们先保存一版采样前的结果\n\n```python\n# 保存全量顶点特征，用于后续 Cross-Attention 的 Key 和 Value\n        pc0_embed_ori = pc0_embed # [B, N, C]\n        pct_embed_ori = pct_embed # [B, N, C]\n```\n\n然后应用最远点采样，得到采样结果 `idx` 然后更新 `pc0_embed` 和 `pct_embed` \n\n```python\n# 5. 最远点采样 (FPS)\n        with torch.no_grad():\n            valid_length = valid_mask.sum(dim=-1)\n            # 从 N 个点中选出 K 个代表点的索引\n            _, idx = ops.sample_farthest_points(points=pc0_embed, lengths=valid_length, K=self.num_traj) \n            # idx 维度: [B, K]\n            idx = replace_negative_indices(idx, valid_length)\n\n        # 6. 根据索引提取代表点的特征 (Gather)\n        # pc0_embed: [B, K, C]\n        pc0_embed = torch.gather(pc0_embed, 1, idx.unsqueeze(-1).expand(-1, -1, pc0_embed.shape[-1]))\n        # pct_embed: [B, K, C]\n        pct_embed = torch.gather(pct_embed, 1, idx.unsqueeze(-1).expand(-1, -1, pct_embed.shape[-1]))\n\n```\n\n这时， `pc0_embed` 是采样后的版本，`pc0_embed_ori` 存储采样前的结果\n\n接下来做 `cross_attention`\n\n- Query = pc0_embed （采样后）\n- Key = pc0_embed_ori (采样前)\n- Value1 = pc0_embed_ori(采样前)\n- Value2 = pct_embed_ori(采样前)\n\n每次过完一个 `attention` 后接一个前馈网络\n\n```python\n# 7. 编码器块 (公式 3 & 4: Cross-Attention 聚合全局信息)\n        for enc_attn, enc_ffn in self.enc_blocks:\n            # q_stream: 代表点 [B, K, C]\n            # k/v_stream: 原始全量点 [B, N, C]\n            attn_res_0, attn_res_t = enc_attn(\n                q_stream=pc0_embed, \n                k_stream=pc0_embed_ori, \n                v1_stream=pc0_embed_ori, \n                v2_stream=pct_embed_ori\n            )\n            pc0_embed = pc0_embed + attn_res_0 # [B, K, C]\n            pct_embed = pct_embed + attn_res_t # [B, K, C]\n            \n            # FFN 层处理\n            ffn_res_0, ffn_res_t = enc_ffn(pc0_embed, pct_embed) # [B, K, C]\n            pc0_embed = pc0_embed + ffn_res_0 # [B, K, C]\n            pct_embed = pct_embed + ffn_res_t # [B, K, C]\n```\n\n接下来我们需要一个latent来表征原始的静态结构，直接全连接就好了\n\n这大概是一个重建任务吧，所以没有什么不确定性，目标是和原本的初始动作一样就好了\n\n```python\n# 8. VAE 潜在空间映射 (公式 5 & 6)\n        # 形状特征 x0: 不做 KL 约束\n        x0 = self.mean_fc_x0(pc0_embed) # [B, K, C_latent]\n```\n\n接下来是轨迹采样，需要有不确定性了\n\nVAE采样过程：\n\n- 得到 `mean` 和 `logvar`\n\n```python\nmean = self.mean_fc_xt(pct_embed)\nlogvar = self.logvar_fc_xt(pct_embed)\n```\n\n- 接下来是采样\n\n> 直接采样高斯分布是不可导的，所以需要使用重参数化\n>\n> ```python\n> # 无法求梯度\n> z = torch.normal(mean=mean, std=std)\n> # 先采样一个随机噪声（不参与梯度的计算）\n> epsilon = torch.randn_like(mean)\n> z = mean + torch.exp(0.5*logvar) * epsilon\n> ```\n\n```python\n# 重参数化采样 (Reparameterization)\n  posterior = DiagonalGaussianDistribution(mean, logvar)\n  xt = posterior.sample() # [B, K, C_latent]\n  kl = posterior.kl()     # [B, K] 或标量\n```\n\n最后把 $x_0$ 和 $x_t$ 拼接在一起\n\n返回 `kl` encode的最终结果`x` 采样的结果 `idx` ，原始的未采样的 `pc0_embed_ori`  \n\n**decode**\n\n定义及传入参数\n\n- encode 中拼接了初始的 $x_0$ 和 $x_t$ 得到这里输入的 `x`\n- queries 是原始的 `N` 个点 $[B,N,3]$\n- pc0_embed_ori 是特征增强的原始的 `N` 个点 `[B,N,C]`\n\n```python\ndef decode(self, x, queries, pc0_embed_ori):\n```\n\n首先拆掉拼接在一起的 $x_0$ 和 $x_t$ \n\n然后把他们从 `C_latent` 维度投影到 `C` 维度\n\n```python\n# 1. 拆分形状 Latent 和 动作 Latent\n  x0_latent, xt_latent = x.chunk(2, dim=-1) # 分别为 [B, K, C_latent]\n\n  # 2. 投影回隐藏层维度\n  x0 = self.proj_x0(x0_latent) # [B, K, C]\n  xt = self.proj_xt(xt_latent) # [B, K, C]\n```\n\n然后是解码自注意力\n\n```python\n# 3. 解码器自注意力块 (代表点之间进行信息交换)\nfor dec_attn, dec_ffn in self.dec_blocks:\n    # Self-Attention: 代表点之间互相观察，优化动作逻辑\n    attn_res_0, attn_res_t = dec_attn(\n        q_stream=x0, \n        k_stream=x0, \n        v1_stream=x0, \n        v2_stream=xt\n    )\n    x0 = x0 + attn_res_0 # [B, K, C]\n    xt = xt + attn_res_t # [B, K, C]\n\n    # FFN 层\n    ffn_res_0, ffn_res_t = dec_ffn(x0, xt)\n    x0 = x0 + ffn_res_0 # [B, K, C]\n    xt = xt + ffn_res_t # [B, K, C]\n```\n\n把全量点的形状特征作为 `Query`\n\n使用 `cross-attention` \n\n$x_0$ 作为 `Key` \n\n而轨迹的特征 $x_t$ 作为 `Value`\n\n使得每一个点(全量)都能查询到关于运动轨迹的信息\n\n```python\n# 4. 最终交叉注意力 (从 K 个代表点上采样到 N 个原始点)\n  # query_embed: 将全量点的形状特征作为查询 [B, N, C]\n  query_embed = self.fc_query(pc0_embed_ori) # [B, N, C]\n\n  # Cross-Attention: \n  # 每个原始点 (N) 去询问代表点 (K)：“我该怎么动？”\n  # key=x0 (形状参考), value=xt (动作参考)\n  latents = self.decoder_final_ca(query_embed, key=x0, value=xt) # [B, N, C]\n```\n\n这时，每个点都得到了关于运动轨迹的信息，就可以开始做输出了\n\n其实就是在后面接一个 `Linear` (不是`mlp`)\n\n```python\n# 5. 投影到 3D 坐标偏移空间\n# self.to_outputs 将 C 维映射到 (T-1)*3 维\noutputs = self.to_outputs(latents) # [B, N, (T-1)*3]\n```\n\n然后就是调整一下维度 由于我们得到的都是相对于第一帧的位置偏移，所以`outputs` 中的每一个输出都要与第一帧的点云相加，才能得到4D的运动序列\n\n```python\n# 6. 重塑维度还原为序列格式\n# .view(...) -> [B, N, T-1, 3]\n# .permute(0, 2, 1, 3) -> [B, T-1, N, 3] (时间维度排在前面)\noutputs = outputs.view(x.shape[0], queries.shape[1], -1, 3).permute(0, 2, 1, 3) # [B, T-1, N, 3]\n\n# 7. 合成最终动画 (公式 1)\n# queries[:, None] 维度是 [B, 1, N, 3] (初始帧)\n# 将初始位置与每一帧的相对位移相加\noutputs = queries[:, None] + outputs # [B, T-1, N, 3]\n\nreturn outputs # 返回完整的动态序列 (不含第一帧，或根据实现包含第一帧)\n```\n\n#### Shape-Guided Text-to-Trajectory Model\n\n基于 `MMDiT`  \n\n> 传统的 `DiT` 对 `image` 做 self attention 然后对 `text` 做 `cross attention` 其中 image 是主体 text 是条件\n>\n> MMDiT: MultiModel DiT\n>\n> 把 `text` 和 `image` 同时做 `self-attention`\n>\n> 传统的 `DiT` 只有 `image` 到 `text` 的 query\n>\n> 而在MMDiT中，同时存在\n>\n> - image -> image\n> - Text -> text\n> - image -> text\n> - Text -> image\n>\n> 的query\n\n**整体结构**\n\n```tex\n输入: x (动作Latent噪声) [B,K,C], t (时间步) [B], texts (文本列表)\n                          │\n          ┌───────────────┼───────────────┐\n          ▼               ▼               ▼\n    timestep_embedding  CLIP Text       input_proj\n    + time_embed(MLP)   Encoder         (Linear)\n          │             + clip_token_mlp      │\n          ▼               ▼               ▼\n        t_emb          text_embed          h\n       [B, W]          [B, 77, W]       [B, K, W]\n          │               │               │\n          └───────┬───────┘               │\n                  ▼                       ▼\n            ┌─────────────────────────────────┐\n            │   Transformer_cogx (×N layers)  │\n            │   CogXAttentionBlock:           │\n            │     - AdaLN-Zero (x & text)     │\n            │     - Joint Self-Attention       │\n            │     - Joint MLP                  │\n            └─────────────────────────────────┘\n                          │\n                    output_proj → 预测噪声/速度场 [B, K, C]\n```\n\n这一部分考虑了文本信息和静态结构，输出是一个速度场，用来为扩散过程提供指导。\n\n每一步扩散都会调用这个 `MMDiT` 得到引导\n\n#### **Diffusion Pipeline**\n\nTraining\n\n得到时间步\n\n```python\n# ---- 1. 采样时间步 ----\n    times = torch.rand(x_start.shape[0], device=x_start.device)  # [B] — t ~ U(0,1)\n    padded_times = append_dims(times, x_start.ndim - 1)           # [B, 1, 1] — 扩展维度以广播\n    \n    # ---- 2. 构造加噪样本 ----\n    t = cosmap(padded_times)                           # [B, 1, 1] — cosine 重映射后的时间步\n    x_t = t * x_start + (1. - t) * noise              # [B, K, C] — 线性插值 (t=1→数据, t=0→噪声)\n    \n    # ---- 3. 保护 f0 通道: 用原始 x_start 的 f0 替换加噪版本 ----\n    # x_start[:, :, :f0_channels] → [B, K, f0] 静态形状，不加噪\n    # x_t[:, :, f0_channels:]     → [B, K, ft] 动态运动，已加噪\n    x_t = torch.cat([x_start[:, :, :f0_channels], x_t[:, :, f0_channels:]], dim=-1)  # [B, K, C]\n```\n\n其中 `cosmap` 会做时间步的重映射，中间的时间步 例如 $t=0.5$ 会被采样得更多\n\n$x_t$ 会得到 静态形状 + 动态运动的混合张量，只有动态运动的部分混上噪声\n\n然后计算 `flow` 也就是从 `noise` 到 `x_start` 的直线方向\n\n```python\n# ---- 4. 计算目标 flow ----\n    flow = x_start - noise     \n```\n\n然后使用 `DyMeshMMDiT` 考虑 `text` 、 运动轨迹，期望得到的是从 `noise` 到 `x_start` 或者预测结果的 方向向量\n\n```python\n# ---- 5. 模型前向传播 ----\n# model = DyMeshMMDiT, 调用其 forward(x_t, t, texts=...)\nmodel_output = model(                              # [B, K, C] — 模型预测的 flow 或 noise\n    x_t,                                           # [B, K, C] — 加噪样本 (f0 未加噪)\n    t.squeeze(-1).squeeze(-1),                     # [B]       — 时间步 (去掉扩展的维度)\n    **model_kwargs\n)\n```\n\n然后把 `model_output` 和实际得到的 `flow` 去做 `mse` 得到 `loss`\n\n```python\n# ---- 6. 选择预测目标 ----\nif predict == 'flow':\n    target = flow                                  # [B, K, C] — 目标: x_start - noise\nelif predict == 'noise':\n    target = noise                                 # [B, K, C] — 目标: 噪声本身\nelse:\n    raise ValueError(f'unknown objective {predict}')\n\n# ---- 7. 计算 MSE 损失 (仅在 ft 动态通道上) ----\nft_channels = x_start.shape[-1] - f0_channels      # ft 通道数 = C - f0\n# 只取最后 ft_channels 个通道计算损失，忽略 f0 (静态形状不需要预测)\nterms[\"mse\"] = mean_flat(                          # [B] — 逐样本 MSE\n    (target[:, :, -ft_channels:] - model_output[:, :, -ft_channels:]) ** 2\n)                                                  # target/output 切片: [B, K, ft]\n\nterms[\"loss\"] = terms[\"mse\"]                       # [B]\n\nreturn terms\n```\n\n训练的结果就是 `DyMeshMMDiT` 学会了生成 `flow` \n\n> Flow =>也就是 `noise` 到目标 `latent` （运动轨迹）的直线方向。\n\n### EgoTwin\n\n标题：EgoTwin: Dreaming Body and View in First Person\n\n生成第一人称视角的视频\n\n有两个**对齐**的挑战，一个是相机轨迹(决定了相机拍到什么)和人体的头部运动的对齐\n\n二是人体与环境交互的动作和环境变化的对齐（因果交互）\n\n#### 问题定义\n\n输入\n\n- 骨骼序列\n- RGB ego View 首帧\n- Text Prompt\n\n输出\n\n- 骨骼运动序列 4D  pose sequence\n- RGB ego 视频 view sequence\n\n#### Modality Tokenization 不同模态怎么做tokenization\n\n**视频** 使用 3D VAE，使用 $4\\times 8\\times 8$ 的压缩率\n\n> `3D VAE` 传统的 VAE 处理二维图像，3D考虑了时间维度\n\n**文本** 使用 `T5-XXL` \n\n##### motion representation 动作表征\n\n> 传统表征：过参数化，记录七个参数\n>\n> 1. 根部转圈的角速度\n> 2. 走位的速度，根部的平面线速度\n> 3. 根部的高度(屁股的高度)\n> 4. 关节的位置（除了屁股之外，其他关节相对于屁股的位置）\n> 5. 局部关节的速度\n> 6. 局部关节的旋转\n> 7. 脚与地面是否接触\n\n传统表示难以做到与 `ego view` 做对齐，需要 `head-centric` 以头部为中心\n\n> 1. 头部的移动\n> 2. 头部的速度\n> 3. 头部的旋转角度\n> 4. 头部的旋转速度\n> 5. 关节的位置  => 关节是以头为参考系的相对表示\n> 6. 关节的速度\n> 7. 关节的旋转\n\n##### motion tokenization\n\n> causal 1D CNN 处理音频或着视频生成\n>\n> 普通的 `CNN`  => 模型可以看到 $t-1, t, t+1$ 但是在生成任务中，看不到未来的数据！\n>\n> 做法：\n>\n> 左侧填充 $k-1$ 个 0， 每次运算只涉及 $t-k+1, ... , t$ 的数据\n\n\n\n\n\n\n\n我们想要做的是可交互的4D生成。从具体的任务而言，包括应用于具身的任务 一般场景的4D重建 主体的运动4D生成\n\n具身的任务是指对场景，机器人等做4D的表征，让模型了解这一个场景，然后做出决策，例如Dream2Flow、PointWorld\n\n一般场景的4D重建包括 Any4D、D4RT、TrackingWorld。\n\n这两种任务关注于对场景的表征，而主体的运动4D生成更加关注于对于特定主体的表征，往往需要添加骨骼信息，运动序列，而不仅仅是4D点流了，包括 `AnimateAnyMesh` `EgoTwin` `Uni-Inter` `Mo-CapAnything` \n","slug":"0209-reading","published":1,"updated":"2026-02-15T09:08:07.960Z","comments":1,"layout":"post","photos":[],"_id":"cmlnjmvuo0000a5jk2pb64g4z","content":"<h2 id=\"pre-knowledge\"><a class=\"markdownIt-Anchor\" href=\"#pre-knowledge\"></a> Pre knowledge</h2>\n<p>光流和PointTracking ：光流指的是在相邻的两张图片 点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u_1,v_1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 到 点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u_2,v_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 所组成的矢量，而pointTracking(2D)指的是更长时的，一个点在所有帧上的轨迹，而不只是关注相邻的两帧。</p>\n<h2 id=\"4d表征\"><a class=\"markdownIt-Anchor\" href=\"#4d表征\"></a> 4D表征：</h2>\n<p>PointWorld：3D点流，分为状态和动作，状态使用场景RGB-D图，动作使用机器人URDF推算</p>\n<p>Any4D：视频，深度图，雷达多普勒，相机位姿</p>\n<p>Uni-Enter：voxel体素</p>\n<p>Ego-Twin：视频 + 文本描述 + 骨骼4D</p>\n<p>AnimateAnyMesh：关节连接矩阵 + 初始结构点云 + 移动轨迹</p>\n<p>Dream2Flow：深度图到3D点云 (object flow)</p>\n<p>MoCapAnything：骨骼结构、Mesh网格、Image图片；图片帧使用DinoV2编码、视频到Mesh重建</p>\n<p>D4RT：连续的视频帧</p>\n<p>对于每一篇文章，我们关心两个问题</p>\n<ul>\n<li>如何表征 4D 的\n<ul>\n<li>数据如何获取，如何得到输入</li>\n<li>如何进行编码，模型的具体架构？</li>\n</ul>\n</li>\n<li>对我们的工作有什么启发</li>\n</ul>\n<p>接下来，我们将对每一篇文章展开介绍。</p>\n<hr />\n<h3 id=\"dream2flow\"><a class=\"markdownIt-Anchor\" href=\"#dream2flow\"></a> Dream2Flow</h3>\n<p>这篇工作实现了对机器人要操作的物体的表征，输入是一个初始帧 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">I_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 然后使用视频生成模型生成 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>I</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">I_1, I_2, ...</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span></span></span></span></p>\n<blockquote>\n<p>视频生成：生成目标物体运动的视频</p>\n</blockquote>\n<p>然后用 <code>SpatialTrackerV2</code> 得到深度图，用 <code>Grounding DINO</code> 得到 <strong>物体的检测框</strong> 进一步用 <code>SAM2</code> 得到物体的mask，然后投到3D就得到物体的点云4D序列了。</p>\n<p>得到这个4D序列是希望能预测4D的序列，接下来我们关注三种类型的任务，以及我们分别是怎么解决的。</p>\n<h4 id=\"push-t\"><a class=\"markdownIt-Anchor\" href=\"#push-t\"></a> Push-T</h4>\n<p>对于一个在水平面上的物体，给他一个push的力，这坨点云会怎么动？我们的输入是一个14维度的query，包括 3D 的位置，3D的颜色，3D的法向量（取右边和下面的像素点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span>，投到3D上，然后计算</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mrow><mi>A</mi><mi>B</mi></mrow><mo>⃗</mo></mover><mo>×</mo><mover accent=\"true\"><mrow><mi>A</mi><mi>C</mi></mrow><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{AB}\\times \\vec{AC} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0496599999999998em;vertical-align:-0.08333em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9663299999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9663299999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9663299999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>作用点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u,v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 和推的方向 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mi>u</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">Δ</mi><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\Delta u, \\Delta v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">Δ</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 拖拽距离 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span></p>\n<p>接下来的问题在于模型架构，文中没有明确的说明，只说了基于<code>PointNet</code></p>\n<p>猜测：每一个点的信息是各不相同的，但是推动作用点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u,v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 和推动的方向还有拖拽距离是都一样的，拖拽信息会给每一个点的 <code>14 dimension</code> query 都复制一份。然后经过一个 <code>mlp</code> ，再来一个全局池化综合一下信息，然后过一个 <code>mlp</code> 得到每一个点的位移预测信息。</p>\n<h4 id=\"real-world-domain\"><a class=\"markdownIt-Anchor\" href=\"#real-world-domain\"></a> Real-World Domain</h4>\n<p>任务是抓起来一个物体</p>\n<p>做了一些假设：末端执行器（机器人的手）碰到物体就和物体融为一体了，刚体运动。</p>\n<p>后续使用的是一个机器人的求解器，基于数学的方法。</p>\n<hr />\n<h3 id=\"pointworld\"><a class=\"markdownIt-Anchor\" href=\"#pointworld\"></a> PointWorld</h3>\n<p>论文标题：<code>PointWorld Scaling 3D World Model for In-The-Wild Robotic Manipulation</code></p>\n<p>解读标题：</p>\n<p>一个 <strong>Scaling</strong> 的3D世界模型，使用了大量的机器人数据，为复杂、多任务的机器人操作任务服务</p>\n<p>同样也是用4D点流表征，和 <code>Dream2Flow</code> 的区别在于，<code>Dream2Flow</code> 好像没有使用什么模型架构，而是提出了一种新的范式，可以使用4D点流作为 <code>Reward</code> 实现机器无关的具身智能训练。<code>PointWorld</code> 是有模型架构的。</p>\n<p>有模型就会有输入输出。</p>\n<p>论文中将模型表述为</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mo>×</mo><mi>A</mi><mo>→</mo><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S\\times A\\rightarrow S\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span></span></p>\n<p>其中 <code>S</code> 表示的是场景的点云， <code>A</code> 表示的是 action space</p>\n<p>和很多自回归的方法不同，一次性会推断出未来 <code>H</code> 步的场景</p>\n<p>这里的输入还是4D点流。</p>\n<p>对于静态的场景，使用静态点云来表示。使用Point Transformer v3来处理点云。不带点追踪，减轻了很多负担</p>\n<blockquote>\n<p>Point Transformer v3 （后面称为PTv3）是用来处理点云的 <code>Transformer</code> 注意PTv3 的输入是代表点云的语义信息，例如 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 个点的点云，输入就应该是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(N, hidden\\_size)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>对于机器人，是带时间序列 <code>T</code> 的，对于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>N</mi><mi>R</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 个机器人上的点，就可以出来 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>×</mo><msub><mi>N</mi><mi>R</mi></msub><mo>×</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">T\\times N_R\\times3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 的点云，还要进行一系列的特征化</p>\n<blockquote>\n<p>注意这里的点是采样过的点，只选择了机器人的夹持器上的点， 因为只有这些点直接与场景进行交互</p>\n</blockquote>\n<p>静态场景的点云是静态的，但是每一个静态的场景会和动态的每一帧进行拼接</p>\n<p>得到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msub><mi>N</mi><mi>R</mi></msub><mo>+</mo><msub><mi>N</mi><mi>S</mi></msub><mo stretchy=\"false\">)</mo><mo>×</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">T\\times(N_R+N_S)\\times hidden\\_size</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">S</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00444em;vertical-align:-0.31em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span></span></span></span></p>\n<p>这里的机器人点云和场景点云分别进行了不同的特征化：</p>\n<ul>\n<li>\n<p>机器人点云编码了位置信息、时间步、颜色标记、法线、速度和加速度</p>\n</li>\n<li>\n<p>场景点云编码了位置信息、2D语义信息、外观特征</p>\n</li>\n</ul>\n<p>而这些可以统一的交给 <code>PTv3</code> 可以处理混合编码</p>\n<hr />\n<p>接下来我们关注 4D 重建的部分论文</p>\n<h3 id=\"any4d\"><a class=\"markdownIt-Anchor\" href=\"#any4d\"></a> Any4D</h3>\n<p><a href=\"https://www.alphaxiv.org/abs/2512.10935\">search in alphaxiv</a> 25-12-10</p>\n<p>这一篇的代码是开源的</p>\n<p>论文标题：Any4D: Unified Feed-forward Metric 4D Reconstruction</p>\n<p>模型实现了4D场景的重建</p>\n<p>可以 fomulate 成下面的形式</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>s</mi><mo>~</mo></mover><mo separator=\"true\">,</mo><mo stretchy=\"false\">{</mo><msub><mover accent=\"true\"><mi>R</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>D</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>T</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>F</mi><mo>~</mo></mover><mi>i</mi></msub><msubsup><mo stretchy=\"false\">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo stretchy=\"false\">)</mo><mo>=</mo><mi>A</mi><mi>n</mi><mi>y</mi><mn>4</mn><mi>D</mi><mo stretchy=\"false\">(</mo><mi>I</mi><mo separator=\"true\">,</mo><mi>O</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\tilde{s},\\{\\tilde{R}_i, \\tilde{D}_i, \\tilde{T}_i,\\tilde{F}_i\\}^{N}_{i=1})=Any4D(I,O)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">4</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>这里的输入可以分为基础输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>I</mi></mrow><annotation encoding=\"application/x-tex\">I</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span></span></span></span> 和额外输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span></p>\n<p>基础输入是RGB的视频流，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>H</mi><mo separator=\"true\">,</mo><mi>W</mi><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[N,H,W,3]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span></span></span></span></p>\n<p>此外还可以选择性地输入深度图 + 多普勒流场（速度场）+ 相机位姿（相机外参：分为平移 + 旋转） + Rays场（相机内参）</p>\n<p>代码实现中：</p>\n<p>Optional Input 使用了两种类型的 <code>encoder</code></p>\n<p>对于深度图，Rays场，场景流，使用 <code>ViTEncoderNonImageInput</code></p>\n<p>对于 相机位姿（旋转 + 平移）尺度因子使用 <code>EncoderGlobalRepInput</code></p>\n<p>论文的 <code>3.1</code> 介绍了模型的架构</p>\n<blockquote>\n<p>模型的架构分为了三个部分：输入的 <code>encoder</code> 中间的 <code>transformer</code> 最后输出的对于每一个 view 的<code>decoder</code></p>\n</blockquote>\n<h4 id=\"encoder\"><a class=\"markdownIt-Anchor\" href=\"#encoder\"></a> encoder</h4>\n<p>图片使用DinoV2 最终编码成 <code>[hidden_size=1024, H / 14, W / 14]</code></p>\n<p>其他的模态分别使用 <code>CNN</code> 或者 <code>MLP</code> 编码成相同的维度</p>\n<blockquote>\n<p>深度图：对于每一个 view 做独立的归一化，然后使用一个 <code>shallow CNN</code> 进行编码</p>\n<p>多普勒(Doppler Velocity, 速度场)：对第一个view做归一化，然后往后的所有view沿用第一个view的归一化的参数，同样使用 <code>CNN based Encoder</code></p>\n<p>相机内参：相机的内参和rays是可以可逆转换的，这里使用rays（射线场）来表征，同样使用 <code>CNN</code> 把 3 channels map到 1024的hidden_size</p>\n<p>相机位姿：分别使用两个 四层的MLP，把维度拉到 1024，使用全局（所有views）的归一化，同时加入一个表征当前是第几帧的position embedding</p>\n<p>metric scale token：深度图和相机位姿的归一化分别可以得到一个 <code>s</code> 然后使用两个 <code>MLP</code> 就可以得到 1024 的latent 了</p>\n</blockquote>\n<p>然后得到若干独立的 <code>tokens</code></p>\n<p>把这些tokens直接相加，对于每一个 <code>view</code> 就可以得到 <code>[hidden_size=1024, H/14, W/14]</code></p>\n<p>把后两个维度展平，对于每一个 <code>view</code> 可以得到 <code>[M = H / 14 * W / 14, hidden_size = 1024]</code></p>\n<p>也就是，对于每一个view，可以得到 <code>M</code> 个 <code>token</code> ，每个 <code>token</code> 维度为 <code>(1024, )</code></p>\n<p>总共有 <code>N</code> 个 <code>view</code> ，就会有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">N\\times M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span> 个token</p>\n<h4 id=\"transformer\"><a class=\"markdownIt-Anchor\" href=\"#transformer\"></a> transformer</h4>\n<p>使用一个交替注意力transformer (alternating-attention transformer)</p>\n<p>输入是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>×</mo><mi>M</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">N\\times M + 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个token，还有一个是一个 <code>learnable</code> 的参数，来表示 <code>scale</code></p>\n<h4 id=\"output-representation-head\"><a class=\"markdownIt-Anchor\" href=\"#output-representation-head\"></a> output representation head</h4>\n<p><strong>Geometry DPT Head</strong></p>\n<p>预测每一个view 的深度图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span> 和 射线图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> 以及一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">confidence</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span></span></span></span> 表示置信度</p>\n<blockquote>\n<p>DPT: Dense Point Transformer: 使用transformer 来实现逐个像素的预测输出</p>\n</blockquote>\n<p><strong>Motion DPT Head</strong></p>\n<p>输出每一个点的场景流 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">F_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>以第一帧确定世界坐标系（第一帧图片的中心）</li>\n<li>只track第一帧中出现的点</li>\n</ul>\n<blockquote>\n<p>这里的输出是一个 <code>[N, 3, H, W]</code> 的格式</p>\n<p>表示的是这个点相对于第一帧，在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo separator=\"true\">,</mo><mi>z</mi></mrow><annotation encoding=\"application/x-tex\">x,y,z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span></span> 三个方向上发生的偏移</p>\n</blockquote>\n<p><strong>Pose Decoder</strong></p>\n<p>平均池化的 <code>CNN</code></p>\n<p>输出 up-to-scale 比例缩放的 相机位移和相机旋转 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>Metric Scale Decoder</strong></p>\n<p>一个 lightweight 的 MLP 用于预测scale系数的log值（原来的数字很大）</p>\n<p>总结来说，我们得到了以下的输出</p>\n<ul>\n<li>\n<p>scale缩放系数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span></p>\n</li>\n<li>\n<p>相机的位姿 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span> 相机外参</p>\n</li>\n<li>\n<p>射线图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> 相机内参</p>\n</li>\n<li>\n<p>深度图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span></p>\n</li>\n<li>\n<p>场景流 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span></span></p>\n</li>\n</ul>\n<p>我们来试试完成4D重建的任务，这些条件是否充分(当然是充分的hhh)</p>\n<p>完成一个场景的重建</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>D</mi><mo>×</mo><mi>S</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi>T</mi><mo>×</mo><mi>R</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">SceneRecon = D\\times S\\times (T\\times R)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>场景中像素的真实运动</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>M</mi><mi>o</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>S</mi><mo>×</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">Motion=S\\times F\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span></p>\n<p>动态4D预测</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><msup><mi>n</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>M</mi><mi>o</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">SceneRecon&#x27;=SceneRecon + Motion\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.801892em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span></span></span></span></span></p>\n<hr />\n<h3 id=\"d4rt\"><a class=\"markdownIt-Anchor\" href=\"#d4rt\"></a> D4RT</h3>\n<hr />\n<h3 id=\"animateanymesh\"><a class=\"markdownIt-Anchor\" href=\"#animateanymesh\"></a> AnimateAnyMesh</h3>\n<p>这一篇的代码是开源的</p>\n<p>对主体的表征不需要骨骼！</p>\n<p>理论上只要有点云，有Mesh就能做～其中点云需要是带pointTracking的4D序列才行</p>\n<p>输入包括三个部分</p>\n<ul>\n<li>\n<p>主体的Mesh网格</p>\n<ul>\n<li>\n<blockquote>\n<p>这里其实用Mesh来建立图的邻接关系，表征主体的拓扑结构，代替了骨骼的作用？</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>\n<p>点云(initial 点云)</p>\n</li>\n<li>\n<p>点云的运动序列</p>\n</li>\n</ul>\n<p><strong>overview：</strong></p>\n<p>首先训练 <code>encoder</code> 和 <code>decoder</code> 实现将一个运动序列编码为 <code>latent</code> 在 decode 出来</p>\n<p>这里没有使用 bone，需要的是mesh 网格；</p>\n<p>什么是 <code>mesh</code> 就是在 pointCloud 的基础上，添加三角面片，有了这些三角面片实际上相当于把孤立的点云表示建模成了类似 graph 的结构</p>\n<p>然后使用 DiT 去生成运动序列的 <code>latent</code> 然后再使用训练好的 <code>decoder</code> 就好了</p>\n<p>需要用 text 去引导diffusion 的过程，这里使用的是 MMDiT，Rectified Flow</p>\n<p>训练 <code>MMDiT</code> 生成从 noise 到生成目标的方向向量</p>\n<h4 id=\"dymeshvae\"><a class=\"markdownIt-Anchor\" href=\"#dymeshvae\"></a> DyMeshVAE</h4>\n<p><strong>encode</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode</span>(<span class=\"hljs-params\">self, pc, faces=<span class=\"hljs-literal\">None</span>, valid_mask=<span class=\"hljs-literal\">None</span>, adj_matrix=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-comment\"># pc 维度: [B, T, N, 3] (输入动态序列)</span><br>        B, T, N, D = pc.shape<br>        device = pc.device<br></code></pre></td></tr></table></figure>\n<p>模型的输入如此，传入的点云形状是 <code>[B, T, N, D]</code></p>\n<p>然后得到第一帧的点云</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 1. 提取初始帧</span><br>pc0 = pc[:, <span class=\"hljs-number\">0</span>]  <span class=\"hljs-comment\"># [B, N, 3]</span><br></code></pre></td></tr></table></figure>\n<p>接下来是得到每一帧想对于初始帧的相对位移</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 2. 计算相对轨迹（差分）并展平时间维度</span><br>        <span class=\"hljs-comment\"># (pc - pc[:, :1]) -&gt; [B, T, N, 3] (每一帧减去第一帧)</span><br>        <span class=\"hljs-comment\"># .permute(0, 2, 1, 3) -&gt; [B, N, T, 3]</span><br>        <span class=\"hljs-comment\"># .flatten(2, 3) -&gt; [B, N, T*3]</span><br>        pct_rel = (pc - pc[:, :<span class=\"hljs-number\">1</span>]).permute(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>).flatten(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>) <span class=\"hljs-comment\"># [B, N, T*3]</span><br></code></pre></td></tr></table></figure>\n<p>对初始点云和轨迹点云分别进行embed</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 3. 映射到特征空间 (Embedding)</span><br> pc0_embed = <span class=\"hljs-variable language_\">self</span>.point_embed(pc0)      <span class=\"hljs-comment\"># [B, N, C]</span><br> pct_embed = <span class=\"hljs-variable language_\">self</span>.traj_embed(pct_rel)   <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p><code>pc0_embed</code> 和 <code>pct_embed</code> 分别代表了主体的静态点云信息和轨迹信息</p>\n<p>如果有 <code>adj_matrix</code> 的话，需要对 <code>pc0_embed</code> 做 <code>self-attention</code> 然后把 <code>adj_matrix</code> 作为 <code>mask</code></p>\n<blockquote>\n<p>需要让 <code>pc0_embed</code> 了解拓扑信息，比如手指上的关节的两个点距离和手指上的一个点和大腿上的一个点的距离都很近，但是手指上的关节的两个点是要一起运动的，而手指和大腿是不会一起运动的</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 4. 拓扑信息聚合 (公式 2: 结合 Adj 矩阵的 Self-Attention)</span><br>        <span class=\"hljs-keyword\">if</span> adj_matrix <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:<br>            <span class=\"hljs-comment\"># adj_matrix 维度: [B, N, N]</span><br>            <span class=\"hljs-keyword\">for</span> neighbor_layer <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.neighbor_layers:<br>                <span class=\"hljs-comment\"># 这里的 mask 确保只在相连顶点间算 Attention</span><br>                pc0_embed_res = neighbor_layer(pc0_embed, key=pc0_embed, value=pc0_embed, mask=adj_matrix) <span class=\"hljs-comment\"># [B, N, C]</span><br>                pc0_embed = pc0_embed + pc0_embed_res <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>过 <code>n</code> 遍 <code>self-attention</code> + 残差连接，修改结果保存在 <code>pc0_embed</code></p>\n<p>接下来要做最远点采样，我们先保存一版采样前的结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 保存全量顶点特征，用于后续 Cross-Attention 的 Key 和 Value</span><br>        pc0_embed_ori = pc0_embed <span class=\"hljs-comment\"># [B, N, C]</span><br>        pct_embed_ori = pct_embed <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>然后应用最远点采样，得到采样结果 <code>idx</code> 然后更新 <code>pc0_embed</code> 和 <code>pct_embed</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 5. 最远点采样 (FPS)</span><br>        <span class=\"hljs-keyword\">with</span> torch.no_grad():<br>            valid_length = valid_mask.<span class=\"hljs-built_in\">sum</span>(dim=-<span class=\"hljs-number\">1</span>)<br>            <span class=\"hljs-comment\"># 从 N 个点中选出 K 个代表点的索引</span><br>            _, idx = ops.sample_farthest_points(points=pc0_embed, lengths=valid_length, K=<span class=\"hljs-variable language_\">self</span>.num_traj) <br>            <span class=\"hljs-comment\"># idx 维度: [B, K]</span><br>            idx = replace_negative_indices(idx, valid_length)<br><br>        <span class=\"hljs-comment\"># 6. 根据索引提取代表点的特征 (Gather)</span><br>        <span class=\"hljs-comment\"># pc0_embed: [B, K, C]</span><br>        pc0_embed = torch.gather(pc0_embed, <span class=\"hljs-number\">1</span>, idx.unsqueeze(-<span class=\"hljs-number\">1</span>).expand(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>, pc0_embed.shape[-<span class=\"hljs-number\">1</span>]))<br>        <span class=\"hljs-comment\"># pct_embed: [B, K, C]</span><br>        pct_embed = torch.gather(pct_embed, <span class=\"hljs-number\">1</span>, idx.unsqueeze(-<span class=\"hljs-number\">1</span>).expand(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>, pct_embed.shape[-<span class=\"hljs-number\">1</span>]))<br><br></code></pre></td></tr></table></figure>\n<p>这时， <code>pc0_embed</code> 是采样后的版本，<code>pc0_embed_ori</code> 存储采样前的结果</p>\n<p>接下来做 <code>cross_attention</code></p>\n<ul>\n<li>Query = pc0_embed （采样后）</li>\n<li>Key = pc0_embed_ori (采样前)</li>\n<li>Value1 = pc0_embed_ori(采样前)</li>\n<li>Value2 = pct_embed_ori(采样前)</li>\n</ul>\n<p>每次过完一个 <code>attention</code> 后接一个前馈网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 7. 编码器块 (公式 3 &amp; 4: Cross-Attention 聚合全局信息)</span><br>        <span class=\"hljs-keyword\">for</span> enc_attn, enc_ffn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.enc_blocks:<br>            <span class=\"hljs-comment\"># q_stream: 代表点 [B, K, C]</span><br>            <span class=\"hljs-comment\"># k/v_stream: 原始全量点 [B, N, C]</span><br>            attn_res_0, attn_res_t = enc_attn(<br>                q_stream=pc0_embed, <br>                k_stream=pc0_embed_ori, <br>                v1_stream=pc0_embed_ori, <br>                v2_stream=pct_embed_ori<br>            )<br>            pc0_embed = pc0_embed + attn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>            pct_embed = pct_embed + attn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br>            <br>            <span class=\"hljs-comment\"># FFN 层处理</span><br>            ffn_res_0, ffn_res_t = enc_ffn(pc0_embed, pct_embed) <span class=\"hljs-comment\"># [B, K, C]</span><br>            pc0_embed = pc0_embed + ffn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>            pct_embed = pct_embed + ffn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>接下来我们需要一个latent来表征原始的静态结构，直接全连接就好了</p>\n<p>这大概是一个重建任务吧，所以没有什么不确定性，目标是和原本的初始动作一样就好了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 8. VAE 潜在空间映射 (公式 5 &amp; 6)</span><br>        <span class=\"hljs-comment\"># 形状特征 x0: 不做 KL 约束</span><br>        x0 = <span class=\"hljs-variable language_\">self</span>.mean_fc_x0(pc0_embed) <span class=\"hljs-comment\"># [B, K, C_latent]</span><br></code></pre></td></tr></table></figure>\n<p>接下来是轨迹采样，需要有不确定性了</p>\n<p>VAE采样过程：</p>\n<ul>\n<li>得到 <code>mean</code> 和 <code>logvar</code></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">mean = <span class=\"hljs-variable language_\">self</span>.mean_fc_xt(pct_embed)<br>logvar = <span class=\"hljs-variable language_\">self</span>.logvar_fc_xt(pct_embed)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>接下来是采样</li>\n</ul>\n<blockquote>\n<p>直接采样高斯分布是不可导的，所以需要使用重参数化</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 无法求梯度</span><br>z = torch.normal(mean=mean, std=std)<br><span class=\"hljs-comment\"># 先采样一个随机噪声（不参与梯度的计算）</span><br>epsilon = torch.randn_like(mean)<br>z = mean + torch.exp(<span class=\"hljs-number\">0.5</span>*logvar) * epsilon<br></code></pre></td></tr></table></figure>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 重参数化采样 (Reparameterization)</span><br>  posterior = DiagonalGaussianDistribution(mean, logvar)<br>  xt = posterior.sample() <span class=\"hljs-comment\"># [B, K, C_latent]</span><br>  kl = posterior.kl()     <span class=\"hljs-comment\"># [B, K] 或标量</span><br></code></pre></td></tr></table></figure>\n<p>最后把 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 拼接在一起</p>\n<p>返回 <code>kl</code> encode的最终结果<code>x</code> 采样的结果 <code>idx</code> ，原始的未采样的 <code>pc0_embed_ori</code></p>\n<p><strong>decode</strong></p>\n<p>定义及传入参数</p>\n<ul>\n<li>encode 中拼接了初始的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 得到这里输入的 <code>x</code></li>\n<li>queries 是原始的 <code>N</code> 个点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>B</mi><mo separator=\"true\">,</mo><mi>N</mi><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[B,N,3]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>pc0_embed_ori 是特征增强的原始的 <code>N</code> 个点 <code>[B,N,C]</code></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decode</span>(<span class=\"hljs-params\">self, x, queries, pc0_embed_ori</span>):<br></code></pre></td></tr></table></figure>\n<p>首先拆掉拼接在一起的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>然后把他们从 <code>C_latent</code> 维度投影到 <code>C</code> 维度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 1. 拆分形状 Latent 和 动作 Latent</span><br>  x0_latent, xt_latent = x.chunk(<span class=\"hljs-number\">2</span>, dim=-<span class=\"hljs-number\">1</span>) <span class=\"hljs-comment\"># 分别为 [B, K, C_latent]</span><br><br>  <span class=\"hljs-comment\"># 2. 投影回隐藏层维度</span><br>  x0 = <span class=\"hljs-variable language_\">self</span>.proj_x0(x0_latent) <span class=\"hljs-comment\"># [B, K, C]</span><br>  xt = <span class=\"hljs-variable language_\">self</span>.proj_xt(xt_latent) <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>然后是解码自注意力</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 3. 解码器自注意力块 (代表点之间进行信息交换)</span><br><span class=\"hljs-keyword\">for</span> dec_attn, dec_ffn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.dec_blocks:<br>    <span class=\"hljs-comment\"># Self-Attention: 代表点之间互相观察，优化动作逻辑</span><br>    attn_res_0, attn_res_t = dec_attn(<br>        q_stream=x0, <br>        k_stream=x0, <br>        v1_stream=x0, <br>        v2_stream=xt<br>    )<br>    x0 = x0 + attn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>    xt = xt + attn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br><br>    <span class=\"hljs-comment\"># FFN 层</span><br>    ffn_res_0, ffn_res_t = dec_ffn(x0, xt)<br>    x0 = x0 + ffn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>    xt = xt + ffn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>把全量点的形状特征作为 <code>Query</code></p>\n<p>使用 <code>cross-attention</code></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key</code></p>\n<p>而轨迹的特征 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Value</code></p>\n<p>使得每一个点(全量)都能查询到关于运动轨迹的信息</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 4. 最终交叉注意力 (从 K 个代表点上采样到 N 个原始点)</span><br>  <span class=\"hljs-comment\"># query_embed: 将全量点的形状特征作为查询 [B, N, C]</span><br>  query_embed = <span class=\"hljs-variable language_\">self</span>.fc_query(pc0_embed_ori) <span class=\"hljs-comment\"># [B, N, C]</span><br><br>  <span class=\"hljs-comment\"># Cross-Attention: </span><br>  <span class=\"hljs-comment\"># 每个原始点 (N) 去询问代表点 (K)：“我该怎么动？”</span><br>  <span class=\"hljs-comment\"># key=x0 (形状参考), value=xt (动作参考)</span><br>  latents = <span class=\"hljs-variable language_\">self</span>.decoder_final_ca(query_embed, key=x0, value=xt) <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>这时，每个点都得到了关于运动轨迹的信息，就可以开始做输出了</p>\n<p>其实就是在后面接一个 <code>Linear</code> (不是<code>mlp</code>)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 5. 投影到 3D 坐标偏移空间</span><br><span class=\"hljs-comment\"># self.to_outputs 将 C 维映射到 (T-1)*3 维</span><br>outputs = <span class=\"hljs-variable language_\">self</span>.to_outputs(latents) <span class=\"hljs-comment\"># [B, N, (T-1)*3]</span><br></code></pre></td></tr></table></figure>\n<p>然后就是调整一下维度 由于我们得到的都是相对于第一帧的位置偏移，所以<code>outputs</code> 中的每一个输出都要与第一帧的点云相加，才能得到4D的运动序列</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 6. 重塑维度还原为序列格式</span><br><span class=\"hljs-comment\"># .view(...) -&gt; [B, N, T-1, 3]</span><br><span class=\"hljs-comment\"># .permute(0, 2, 1, 3) -&gt; [B, T-1, N, 3] (时间维度排在前面)</span><br>outputs = outputs.view(x.shape[<span class=\"hljs-number\">0</span>], queries.shape[<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>).permute(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>) <span class=\"hljs-comment\"># [B, T-1, N, 3]</span><br><br><span class=\"hljs-comment\"># 7. 合成最终动画 (公式 1)</span><br><span class=\"hljs-comment\"># queries[:, None] 维度是 [B, 1, N, 3] (初始帧)</span><br><span class=\"hljs-comment\"># 将初始位置与每一帧的相对位移相加</span><br>outputs = queries[:, <span class=\"hljs-literal\">None</span>] + outputs <span class=\"hljs-comment\"># [B, T-1, N, 3]</span><br><br><span class=\"hljs-keyword\">return</span> outputs <span class=\"hljs-comment\"># 返回完整的动态序列 (不含第一帧，或根据实现包含第一帧)</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"shape-guided-text-to-trajectory-model\"><a class=\"markdownIt-Anchor\" href=\"#shape-guided-text-to-trajectory-model\"></a> Shape-Guided Text-to-Trajectory Model</h4>\n<p>基于 <code>MMDiT</code></p>\n<blockquote>\n<p>传统的 <code>DiT</code> 对 <code>image</code> 做 self attention 然后对 <code>text</code> 做 <code>cross attention</code> 其中 image 是主体 text 是条件</p>\n<p>MMDiT: MultiModel DiT</p>\n<p>把 <code>text</code> 和 <code>image</code> 同时做 <code>self-attention</code></p>\n<p>传统的 <code>DiT</code> 只有 <code>image</code> 到 <code>text</code> 的 query</p>\n<p>而在MMDiT中，同时存在</p>\n<ul>\n<li>image -&gt; image</li>\n<li>Text -&gt; text</li>\n<li>image -&gt; text</li>\n<li>Text -&gt; image</li>\n</ul>\n<p>的query</p>\n</blockquote>\n<p><strong>整体结构</strong></p>\n<figure class=\"highlight tex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tex\">输入: x (动作Latent噪声) [B,K,C], t (时间步) [B], texts (文本列表)<br>                          │<br>          ┌───────────────┼───────────────┐<br>          ▼               ▼               ▼<br>    timestep<span class=\"hljs-built_in\">_</span>embedding  CLIP Text       input<span class=\"hljs-built_in\">_</span>proj<br>    + time<span class=\"hljs-built_in\">_</span>embed(MLP)   Encoder         (Linear)<br>          │             + clip<span class=\"hljs-built_in\">_</span>token<span class=\"hljs-built_in\">_</span>mlp      │<br>          ▼               ▼               ▼<br>        t<span class=\"hljs-built_in\">_</span>emb          text<span class=\"hljs-built_in\">_</span>embed          h<br>       [B, W]          [B, 77, W]       [B, K, W]<br>          │               │               │<br>          └───────┬───────┘               │<br>                  ▼                       ▼<br>            ┌─────────────────────────────────┐<br>            │   Transformer<span class=\"hljs-built_in\">_</span>cogx (×N layers)  │<br>            │   CogXAttentionBlock:           │<br>            │     - AdaLN-Zero (x <span class=\"hljs-built_in\">&amp;</span> text)     │<br>            │     - Joint Self-Attention       │<br>            │     - Joint MLP                  │<br>            └─────────────────────────────────┘<br>                          │<br>                    output<span class=\"hljs-built_in\">_</span>proj → 预测噪声/速度场 [B, K, C]<br></code></pre></td></tr></table></figure>\n<p>这一部分考虑了文本信息和静态结构，输出是一个速度场，用来为扩散过程提供指导。</p>\n<p>每一步扩散都会调用这个 <code>MMDiT</code> 得到引导</p>\n<h4 id=\"diffusion-pipeline\"><a class=\"markdownIt-Anchor\" href=\"#diffusion-pipeline\"></a> <strong>Diffusion Pipeline</strong></h4>\n<p>Training</p>\n<p>得到时间步</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 1. 采样时间步 ----</span><br>    times = torch.rand(x_start.shape[<span class=\"hljs-number\">0</span>], device=x_start.device)  <span class=\"hljs-comment\"># [B] — t ~ U(0,1)</span><br>    padded_times = append_dims(times, x_start.ndim - <span class=\"hljs-number\">1</span>)           <span class=\"hljs-comment\"># [B, 1, 1] — 扩展维度以广播</span><br>    <br>    <span class=\"hljs-comment\"># ---- 2. 构造加噪样本 ----</span><br>    t = cosmap(padded_times)                           <span class=\"hljs-comment\"># [B, 1, 1] — cosine 重映射后的时间步</span><br>    x_t = t * x_start + (<span class=\"hljs-number\">1.</span> - t) * noise              <span class=\"hljs-comment\"># [B, K, C] — 线性插值 (t=1→数据, t=0→噪声)</span><br>    <br>    <span class=\"hljs-comment\"># ---- 3. 保护 f0 通道: 用原始 x_start 的 f0 替换加噪版本 ----</span><br>    <span class=\"hljs-comment\"># x_start[:, :, :f0_channels] → [B, K, f0] 静态形状，不加噪</span><br>    <span class=\"hljs-comment\"># x_t[:, :, f0_channels:]     → [B, K, ft] 动态运动，已加噪</span><br>    x_t = torch.cat([x_start[:, :, :f0_channels], x_t[:, :, f0_channels:]], dim=-<span class=\"hljs-number\">1</span>)  <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>其中 <code>cosmap</code> 会做时间步的重映射，中间的时间步 例如 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">t=0.5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span></span></span></span> 会被采样得更多</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 会得到 静态形状 + 动态运动的混合张量，只有动态运动的部分混上噪声</p>\n<p>然后计算 <code>flow</code> 也就是从 <code>noise</code> 到 <code>x_start</code> 的直线方向</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 4. 计算目标 flow ----</span><br>    flow = x_start - noise     <br></code></pre></td></tr></table></figure>\n<p>然后使用 <code>DyMeshMMDiT</code> 考虑 <code>text</code> 、 运动轨迹，期望得到的是从 <code>noise</code> 到 <code>x_start</code> 或者预测结果的 方向向量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 5. 模型前向传播 ----</span><br><span class=\"hljs-comment\"># model = DyMeshMMDiT, 调用其 forward(x_t, t, texts=...)</span><br>model_output = model(                              <span class=\"hljs-comment\"># [B, K, C] — 模型预测的 flow 或 noise</span><br>    x_t,                                           <span class=\"hljs-comment\"># [B, K, C] — 加噪样本 (f0 未加噪)</span><br>    t.squeeze(-<span class=\"hljs-number\">1</span>).squeeze(-<span class=\"hljs-number\">1</span>),                     <span class=\"hljs-comment\"># [B]       — 时间步 (去掉扩展的维度)</span><br>    **model_kwargs<br>)<br></code></pre></td></tr></table></figure>\n<p>然后把 <code>model_output</code> 和实际得到的 <code>flow</code> 去做 <code>mse</code> 得到 <code>loss</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 6. 选择预测目标 ----</span><br><span class=\"hljs-keyword\">if</span> predict == <span class=\"hljs-string\">&#x27;flow&#x27;</span>:<br>    target = flow                                  <span class=\"hljs-comment\"># [B, K, C] — 目标: x_start - noise</span><br><span class=\"hljs-keyword\">elif</span> predict == <span class=\"hljs-string\">&#x27;noise&#x27;</span>:<br>    target = noise                                 <span class=\"hljs-comment\"># [B, K, C] — 目标: 噪声本身</span><br><span class=\"hljs-keyword\">else</span>:<br>    <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">f&#x27;unknown objective <span class=\"hljs-subst\">&#123;predict&#125;</span>&#x27;</span>)<br><br><span class=\"hljs-comment\"># ---- 7. 计算 MSE 损失 (仅在 ft 动态通道上) ----</span><br>ft_channels = x_start.shape[-<span class=\"hljs-number\">1</span>] - f0_channels      <span class=\"hljs-comment\"># ft 通道数 = C - f0</span><br><span class=\"hljs-comment\"># 只取最后 ft_channels 个通道计算损失，忽略 f0 (静态形状不需要预测)</span><br>terms[<span class=\"hljs-string\">&quot;mse&quot;</span>] = mean_flat(                          <span class=\"hljs-comment\"># [B] — 逐样本 MSE</span><br>    (target[:, :, -ft_channels:] - model_output[:, :, -ft_channels:]) ** <span class=\"hljs-number\">2</span><br>)                                                  <span class=\"hljs-comment\"># target/output 切片: [B, K, ft]</span><br><br>terms[<span class=\"hljs-string\">&quot;loss&quot;</span>] = terms[<span class=\"hljs-string\">&quot;mse&quot;</span>]                       <span class=\"hljs-comment\"># [B]</span><br><br><span class=\"hljs-keyword\">return</span> terms<br></code></pre></td></tr></table></figure>\n<p>训练的结果就是 <code>DyMeshMMDiT</code> 学会了生成 <code>flow</code></p>\n<blockquote>\n<p>Flow =&gt;也就是 <code>noise</code> 到目标 <code>latent</code> （运动轨迹）的直线方向。</p>\n</blockquote>\n<h3 id=\"egotwin\"><a class=\"markdownIt-Anchor\" href=\"#egotwin\"></a> EgoTwin</h3>\n<p>标题：EgoTwin: Dreaming Body and View in First Person</p>\n<p>生成第一人称视角的视频</p>\n<p>有两个<strong>对齐</strong>的挑战，一个是相机轨迹(决定了相机拍到什么)和人体的头部运动的对齐</p>\n<p>二是人体与环境交互的动作和环境变化的对齐（因果交互）</p>\n<h4 id=\"问题定义\"><a class=\"markdownIt-Anchor\" href=\"#问题定义\"></a> 问题定义</h4>\n<p>输入</p>\n<ul>\n<li>骨骼序列</li>\n<li>RGB ego View 首帧</li>\n<li>Text Prompt</li>\n</ul>\n<p>输出</p>\n<ul>\n<li>骨骼运动序列 4D  pose sequence</li>\n<li>RGB ego 视频 view sequence</li>\n</ul>\n<h4 id=\"modality-tokenization-不同模态怎么做tokenization\"><a class=\"markdownIt-Anchor\" href=\"#modality-tokenization-不同模态怎么做tokenization\"></a> Modality Tokenization 不同模态怎么做tokenization</h4>\n<p><strong>视频</strong> 使用 3D VAE，使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn><mo>×</mo><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">4\\times 8\\times 8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">8</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">8</span></span></span></span> 的压缩率</p>\n<blockquote>\n<p><code>3D VAE</code> 传统的 VAE 处理二维图像，3D考虑了时间维度</p>\n</blockquote>\n<p><strong>文本</strong> 使用 <code>T5-XXL</code></p>\n<h5 id=\"motion-representation-动作表征\"><a class=\"markdownIt-Anchor\" href=\"#motion-representation-动作表征\"></a> motion representation 动作表征</h5>\n<blockquote>\n<p>传统表征：过参数化，记录七个参数</p>\n<ol>\n<li>根部转圈的角速度</li>\n<li>走位的速度，根部的平面线速度</li>\n<li>根部的高度(屁股的高度)</li>\n<li>关节的位置（除了屁股之外，其他关节相对于屁股的位置）</li>\n<li>局部关节的速度</li>\n<li>局部关节的旋转</li>\n<li>脚与地面是否接触</li>\n</ol>\n</blockquote>\n<p>传统表示难以做到与 <code>ego view</code> 做对齐，需要 <code>head-centric</code> 以头部为中心</p>\n<blockquote>\n<ol>\n<li>头部的移动</li>\n<li>头部的速度</li>\n<li>头部的旋转角度</li>\n<li>头部的旋转速度</li>\n<li>关节的位置  =&gt; 关节是以头为参考系的相对表示</li>\n<li>关节的速度</li>\n<li>关节的旋转</li>\n</ol>\n</blockquote>\n<h5 id=\"motion-tokenization\"><a class=\"markdownIt-Anchor\" href=\"#motion-tokenization\"></a> motion tokenization</h5>\n<blockquote>\n<p>causal 1D CNN 处理音频或着视频生成</p>\n<p>普通的 <code>CNN</code>  =&gt; 模型可以看到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t-1, t, t+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 但是在生成任务中，看不到未来的数据！</p>\n<p>做法：</p>\n<p>左侧填充 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个 0， 每次运算只涉及 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t-k+1, ... , t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 的数据</p>\n</blockquote>\n<p>我们想要做的是可交互的4D生成。从具体的任务而言，包括应用于具身的任务 一般场景的4D重建 主体的运动4D生成</p>\n<p>具身的任务是指对场景，机器人等做4D的表征，让模型了解这一个场景，然后做出决策，例如Dream2Flow、PointWorld</p>\n<p>一般场景的4D重建包括 Any4D、D4RT、TrackingWorld。</p>\n<p>这两种任务关注于对场景的表征，而主体的运动4D生成更加关注于对于特定主体的表征，往往需要添加骨骼信息，运动序列，而不仅仅是4D点流了，包括 <code>AnimateAnyMesh</code> <code>EgoTwin</code> <code>Uni-Inter</code> <code>Mo-CapAnything</code></p>\n","excerpt":"","more":"<h2 id=\"pre-knowledge\"><a class=\"markdownIt-Anchor\" href=\"#pre-knowledge\"></a> Pre knowledge</h2>\n<p>光流和PointTracking ：光流指的是在相邻的两张图片 点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u_1,v_1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 到 点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u_2,v_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 所组成的矢量，而pointTracking(2D)指的是更长时的，一个点在所有帧上的轨迹，而不只是关注相邻的两帧。</p>\n<h2 id=\"4d表征\"><a class=\"markdownIt-Anchor\" href=\"#4d表征\"></a> 4D表征：</h2>\n<p>PointWorld：3D点流，分为状态和动作，状态使用场景RGB-D图，动作使用机器人URDF推算</p>\n<p>Any4D：视频，深度图，雷达多普勒，相机位姿</p>\n<p>Uni-Enter：voxel体素</p>\n<p>Ego-Twin：视频 + 文本描述 + 骨骼4D</p>\n<p>AnimateAnyMesh：关节连接矩阵 + 初始结构点云 + 移动轨迹</p>\n<p>Dream2Flow：深度图到3D点云 (object flow)</p>\n<p>MoCapAnything：骨骼结构、Mesh网格、Image图片；图片帧使用DinoV2编码、视频到Mesh重建</p>\n<p>D4RT：连续的视频帧</p>\n<p>对于每一篇文章，我们关心两个问题</p>\n<ul>\n<li>如何表征 4D 的\n<ul>\n<li>数据如何获取，如何得到输入</li>\n<li>如何进行编码，模型的具体架构？</li>\n</ul>\n</li>\n<li>对我们的工作有什么启发</li>\n</ul>\n<p>接下来，我们将对每一篇文章展开介绍。</p>\n<hr />\n<h3 id=\"dream2flow\"><a class=\"markdownIt-Anchor\" href=\"#dream2flow\"></a> Dream2Flow</h3>\n<p>这篇工作实现了对机器人要操作的物体的表征，输入是一个初始帧 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">I_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 然后使用视频生成模型生成 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>I</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">I_1, I_2, ...</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span></span></span></span></p>\n<blockquote>\n<p>视频生成：生成目标物体运动的视频</p>\n</blockquote>\n<p>然后用 <code>SpatialTrackerV2</code> 得到深度图，用 <code>Grounding DINO</code> 得到 <strong>物体的检测框</strong> 进一步用 <code>SAM2</code> 得到物体的mask，然后投到3D就得到物体的点云4D序列了。</p>\n<p>得到这个4D序列是希望能预测4D的序列，接下来我们关注三种类型的任务，以及我们分别是怎么解决的。</p>\n<h4 id=\"push-t\"><a class=\"markdownIt-Anchor\" href=\"#push-t\"></a> Push-T</h4>\n<p>对于一个在水平面上的物体，给他一个push的力，这坨点云会怎么动？我们的输入是一个14维度的query，包括 3D 的位置，3D的颜色，3D的法向量（取右边和下面的像素点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span>，投到3D上，然后计算</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mrow><mi>A</mi><mi>B</mi></mrow><mo>⃗</mo></mover><mo>×</mo><mover accent=\"true\"><mrow><mi>A</mi><mi>C</mi></mrow><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{AB}\\times \\vec{AC} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0496599999999998em;vertical-align:-0.08333em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9663299999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9663299999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9663299999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2355em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>作用点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u,v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 和推的方向 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mi>u</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">Δ</mi><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\Delta u, \\Delta v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">Δ</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 拖拽距离 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span></p>\n<p>接下来的问题在于模型架构，文中没有明确的说明，只说了基于<code>PointNet</code></p>\n<p>猜测：每一个点的信息是各不相同的，但是推动作用点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(u,v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> 和推动的方向还有拖拽距离是都一样的，拖拽信息会给每一个点的 <code>14 dimension</code> query 都复制一份。然后经过一个 <code>mlp</code> ，再来一个全局池化综合一下信息，然后过一个 <code>mlp</code> 得到每一个点的位移预测信息。</p>\n<h4 id=\"real-world-domain\"><a class=\"markdownIt-Anchor\" href=\"#real-world-domain\"></a> Real-World Domain</h4>\n<p>任务是抓起来一个物体</p>\n<p>做了一些假设：末端执行器（机器人的手）碰到物体就和物体融为一体了，刚体运动。</p>\n<p>后续使用的是一个机器人的求解器，基于数学的方法。</p>\n<hr />\n<h3 id=\"pointworld\"><a class=\"markdownIt-Anchor\" href=\"#pointworld\"></a> PointWorld</h3>\n<p>论文标题：<code>PointWorld Scaling 3D World Model for In-The-Wild Robotic Manipulation</code></p>\n<p>解读标题：</p>\n<p>一个 <strong>Scaling</strong> 的3D世界模型，使用了大量的机器人数据，为复杂、多任务的机器人操作任务服务</p>\n<p>同样也是用4D点流表征，和 <code>Dream2Flow</code> 的区别在于，<code>Dream2Flow</code> 好像没有使用什么模型架构，而是提出了一种新的范式，可以使用4D点流作为 <code>Reward</code> 实现机器无关的具身智能训练。<code>PointWorld</code> 是有模型架构的。</p>\n<p>有模型就会有输入输出。</p>\n<p>论文中将模型表述为</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mo>×</mo><mi>A</mi><mo>→</mo><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S\\times A\\rightarrow S\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span></span></p>\n<p>其中 <code>S</code> 表示的是场景的点云， <code>A</code> 表示的是 action space</p>\n<p>和很多自回归的方法不同，一次性会推断出未来 <code>H</code> 步的场景</p>\n<p>这里的输入还是4D点流。</p>\n<p>对于静态的场景，使用静态点云来表示。使用Point Transformer v3来处理点云。不带点追踪，减轻了很多负担</p>\n<blockquote>\n<p>Point Transformer v3 （后面称为PTv3）是用来处理点云的 <code>Transformer</code> 注意PTv3 的输入是代表点云的语义信息，例如 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 个点的点云，输入就应该是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(N, hidden\\_size)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>对于机器人，是带时间序列 <code>T</code> 的，对于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>N</mi><mi>R</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 个机器人上的点，就可以出来 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>×</mo><msub><mi>N</mi><mi>R</mi></msub><mo>×</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">T\\times N_R\\times3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 的点云，还要进行一系列的特征化</p>\n<blockquote>\n<p>注意这里的点是采样过的点，只选择了机器人的夹持器上的点， 因为只有这些点直接与场景进行交互</p>\n</blockquote>\n<p>静态场景的点云是静态的，但是每一个静态的场景会和动态的每一帧进行拼接</p>\n<p>得到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msub><mi>N</mi><mi>R</mi></msub><mo>+</mo><msub><mi>N</mi><mi>S</mi></msub><mo stretchy=\"false\">)</mo><mo>×</mo><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">T\\times(N_R+N_S)\\times hidden\\_size</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">S</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00444em;vertical-align:-0.31em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span></span></span></span></p>\n<p>这里的机器人点云和场景点云分别进行了不同的特征化：</p>\n<ul>\n<li>\n<p>机器人点云编码了位置信息、时间步、颜色标记、法线、速度和加速度</p>\n</li>\n<li>\n<p>场景点云编码了位置信息、2D语义信息、外观特征</p>\n</li>\n</ul>\n<p>而这些可以统一的交给 <code>PTv3</code> 可以处理混合编码</p>\n<hr />\n<p>接下来我们关注 4D 重建的部分论文</p>\n<h3 id=\"any4d\"><a class=\"markdownIt-Anchor\" href=\"#any4d\"></a> Any4D</h3>\n<p><a href=\"https://www.alphaxiv.org/abs/2512.10935\">search in alphaxiv</a> 25-12-10</p>\n<p>这一篇的代码是开源的</p>\n<p>论文标题：Any4D: Unified Feed-forward Metric 4D Reconstruction</p>\n<p>模型实现了4D场景的重建</p>\n<p>可以 fomulate 成下面的形式</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>s</mi><mo>~</mo></mover><mo separator=\"true\">,</mo><mo stretchy=\"false\">{</mo><msub><mover accent=\"true\"><mi>R</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>D</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>T</mi><mo>~</mo></mover><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>F</mi><mo>~</mo></mover><mi>i</mi></msub><msubsup><mo stretchy=\"false\">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo stretchy=\"false\">)</mo><mo>=</mo><mi>A</mi><mi>n</mi><mi>y</mi><mn>4</mn><mi>D</mi><mo stretchy=\"false\">(</mo><mi>I</mi><mo separator=\"true\">,</mo><mi>O</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\tilde{s},\\{\\tilde{R}_i, \\tilde{D}_i, \\tilde{T}_i,\\tilde{F}_i\\}^{N}_{i=1})=Any4D(I,O)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">4</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>这里的输入可以分为基础输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>I</mi></mrow><annotation encoding=\"application/x-tex\">I</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span></span></span></span> 和额外输入 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span></p>\n<p>基础输入是RGB的视频流，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>H</mi><mo separator=\"true\">,</mo><mi>W</mi><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[N,H,W,3]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span></span></span></span></p>\n<p>此外还可以选择性地输入深度图 + 多普勒流场（速度场）+ 相机位姿（相机外参：分为平移 + 旋转） + Rays场（相机内参）</p>\n<p>代码实现中：</p>\n<p>Optional Input 使用了两种类型的 <code>encoder</code></p>\n<p>对于深度图，Rays场，场景流，使用 <code>ViTEncoderNonImageInput</code></p>\n<p>对于 相机位姿（旋转 + 平移）尺度因子使用 <code>EncoderGlobalRepInput</code></p>\n<p>论文的 <code>3.1</code> 介绍了模型的架构</p>\n<blockquote>\n<p>模型的架构分为了三个部分：输入的 <code>encoder</code> 中间的 <code>transformer</code> 最后输出的对于每一个 view 的<code>decoder</code></p>\n</blockquote>\n<h4 id=\"encoder\"><a class=\"markdownIt-Anchor\" href=\"#encoder\"></a> encoder</h4>\n<p>图片使用DinoV2 最终编码成 <code>[hidden_size=1024, H / 14, W / 14]</code></p>\n<p>其他的模态分别使用 <code>CNN</code> 或者 <code>MLP</code> 编码成相同的维度</p>\n<blockquote>\n<p>深度图：对于每一个 view 做独立的归一化，然后使用一个 <code>shallow CNN</code> 进行编码</p>\n<p>多普勒(Doppler Velocity, 速度场)：对第一个view做归一化，然后往后的所有view沿用第一个view的归一化的参数，同样使用 <code>CNN based Encoder</code></p>\n<p>相机内参：相机的内参和rays是可以可逆转换的，这里使用rays（射线场）来表征，同样使用 <code>CNN</code> 把 3 channels map到 1024的hidden_size</p>\n<p>相机位姿：分别使用两个 四层的MLP，把维度拉到 1024，使用全局（所有views）的归一化，同时加入一个表征当前是第几帧的position embedding</p>\n<p>metric scale token：深度图和相机位姿的归一化分别可以得到一个 <code>s</code> 然后使用两个 <code>MLP</code> 就可以得到 1024 的latent 了</p>\n</blockquote>\n<p>然后得到若干独立的 <code>tokens</code></p>\n<p>把这些tokens直接相加，对于每一个 <code>view</code> 就可以得到 <code>[hidden_size=1024, H/14, W/14]</code></p>\n<p>把后两个维度展平，对于每一个 <code>view</code> 可以得到 <code>[M = H / 14 * W / 14, hidden_size = 1024]</code></p>\n<p>也就是，对于每一个view，可以得到 <code>M</code> 个 <code>token</code> ，每个 <code>token</code> 维度为 <code>(1024, )</code></p>\n<p>总共有 <code>N</code> 个 <code>view</code> ，就会有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">N\\times M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span> 个token</p>\n<h4 id=\"transformer\"><a class=\"markdownIt-Anchor\" href=\"#transformer\"></a> transformer</h4>\n<p>使用一个交替注意力transformer (alternating-attention transformer)</p>\n<p>输入是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>×</mo><mi>M</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">N\\times M + 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个token，还有一个是一个 <code>learnable</code> 的参数，来表示 <code>scale</code></p>\n<h4 id=\"output-representation-head\"><a class=\"markdownIt-Anchor\" href=\"#output-representation-head\"></a> output representation head</h4>\n<p><strong>Geometry DPT Head</strong></p>\n<p>预测每一个view 的深度图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span> 和 射线图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> 以及一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">confidence</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span></span></span></span> 表示置信度</p>\n<blockquote>\n<p>DPT: Dense Point Transformer: 使用transformer 来实现逐个像素的预测输出</p>\n</blockquote>\n<p><strong>Motion DPT Head</strong></p>\n<p>输出每一个点的场景流 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">F_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>以第一帧确定世界坐标系（第一帧图片的中心）</li>\n<li>只track第一帧中出现的点</li>\n</ul>\n<blockquote>\n<p>这里的输出是一个 <code>[N, 3, H, W]</code> 的格式</p>\n<p>表示的是这个点相对于第一帧，在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo separator=\"true\">,</mo><mi>z</mi></mrow><annotation encoding=\"application/x-tex\">x,y,z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span></span> 三个方向上发生的偏移</p>\n</blockquote>\n<p><strong>Pose Decoder</strong></p>\n<p>平均池化的 <code>CNN</code></p>\n<p>输出 up-to-scale 比例缩放的 相机位移和相机旋转 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>Metric Scale Decoder</strong></p>\n<p>一个 lightweight 的 MLP 用于预测scale系数的log值（原来的数字很大）</p>\n<p>总结来说，我们得到了以下的输出</p>\n<ul>\n<li>\n<p>scale缩放系数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span></p>\n</li>\n<li>\n<p>相机的位姿 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span> 相机外参</p>\n</li>\n<li>\n<p>射线图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> 相机内参</p>\n</li>\n<li>\n<p>深度图 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span></p>\n</li>\n<li>\n<p>场景流 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span></span></p>\n</li>\n</ul>\n<p>我们来试试完成4D重建的任务，这些条件是否充分(当然是充分的hhh)</p>\n<p>完成一个场景的重建</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>D</mi><mo>×</mo><mi>S</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi>T</mi><mo>×</mo><mi>R</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">SceneRecon = D\\times S\\times (T\\times R)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>场景中像素的真实运动</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>M</mi><mi>o</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>S</mi><mo>×</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">Motion=S\\times F\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span></p>\n<p>动态4D预测</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><msup><mi>n</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mi>S</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>M</mi><mi>o</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">SceneRecon&#x27;=SceneRecon + Motion\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.801892em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span></span></span></span></span></p>\n<hr />\n<h3 id=\"d4rt\"><a class=\"markdownIt-Anchor\" href=\"#d4rt\"></a> D4RT</h3>\n<hr />\n<h3 id=\"animateanymesh\"><a class=\"markdownIt-Anchor\" href=\"#animateanymesh\"></a> AnimateAnyMesh</h3>\n<p>这一篇的代码是开源的</p>\n<p>对主体的表征不需要骨骼！</p>\n<p>理论上只要有点云，有Mesh就能做～其中点云需要是带pointTracking的4D序列才行</p>\n<p>输入包括三个部分</p>\n<ul>\n<li>\n<p>主体的Mesh网格</p>\n<ul>\n<li>\n<blockquote>\n<p>这里其实用Mesh来建立图的邻接关系，表征主体的拓扑结构，代替了骨骼的作用？</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>\n<p>点云(initial 点云)</p>\n</li>\n<li>\n<p>点云的运动序列</p>\n</li>\n</ul>\n<p><strong>overview：</strong></p>\n<p>首先训练 <code>encoder</code> 和 <code>decoder</code> 实现将一个运动序列编码为 <code>latent</code> 在 decode 出来</p>\n<p>这里没有使用 bone，需要的是mesh 网格；</p>\n<p>什么是 <code>mesh</code> 就是在 pointCloud 的基础上，添加三角面片，有了这些三角面片实际上相当于把孤立的点云表示建模成了类似 graph 的结构</p>\n<p>然后使用 DiT 去生成运动序列的 <code>latent</code> 然后再使用训练好的 <code>decoder</code> 就好了</p>\n<p>需要用 text 去引导diffusion 的过程，这里使用的是 MMDiT，Rectified Flow</p>\n<p>训练 <code>MMDiT</code> 生成从 noise 到生成目标的方向向量</p>\n<h4 id=\"dymeshvae\"><a class=\"markdownIt-Anchor\" href=\"#dymeshvae\"></a> DyMeshVAE</h4>\n<p><strong>encode</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode</span>(<span class=\"hljs-params\">self, pc, faces=<span class=\"hljs-literal\">None</span>, valid_mask=<span class=\"hljs-literal\">None</span>, adj_matrix=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-comment\"># pc 维度: [B, T, N, 3] (输入动态序列)</span><br>        B, T, N, D = pc.shape<br>        device = pc.device<br></code></pre></td></tr></table></figure>\n<p>模型的输入如此，传入的点云形状是 <code>[B, T, N, D]</code></p>\n<p>然后得到第一帧的点云</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 1. 提取初始帧</span><br>pc0 = pc[:, <span class=\"hljs-number\">0</span>]  <span class=\"hljs-comment\"># [B, N, 3]</span><br></code></pre></td></tr></table></figure>\n<p>接下来是得到每一帧想对于初始帧的相对位移</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 2. 计算相对轨迹（差分）并展平时间维度</span><br>        <span class=\"hljs-comment\"># (pc - pc[:, :1]) -&gt; [B, T, N, 3] (每一帧减去第一帧)</span><br>        <span class=\"hljs-comment\"># .permute(0, 2, 1, 3) -&gt; [B, N, T, 3]</span><br>        <span class=\"hljs-comment\"># .flatten(2, 3) -&gt; [B, N, T*3]</span><br>        pct_rel = (pc - pc[:, :<span class=\"hljs-number\">1</span>]).permute(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>).flatten(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>) <span class=\"hljs-comment\"># [B, N, T*3]</span><br></code></pre></td></tr></table></figure>\n<p>对初始点云和轨迹点云分别进行embed</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 3. 映射到特征空间 (Embedding)</span><br> pc0_embed = <span class=\"hljs-variable language_\">self</span>.point_embed(pc0)      <span class=\"hljs-comment\"># [B, N, C]</span><br> pct_embed = <span class=\"hljs-variable language_\">self</span>.traj_embed(pct_rel)   <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p><code>pc0_embed</code> 和 <code>pct_embed</code> 分别代表了主体的静态点云信息和轨迹信息</p>\n<p>如果有 <code>adj_matrix</code> 的话，需要对 <code>pc0_embed</code> 做 <code>self-attention</code> 然后把 <code>adj_matrix</code> 作为 <code>mask</code></p>\n<blockquote>\n<p>需要让 <code>pc0_embed</code> 了解拓扑信息，比如手指上的关节的两个点距离和手指上的一个点和大腿上的一个点的距离都很近，但是手指上的关节的两个点是要一起运动的，而手指和大腿是不会一起运动的</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 4. 拓扑信息聚合 (公式 2: 结合 Adj 矩阵的 Self-Attention)</span><br>        <span class=\"hljs-keyword\">if</span> adj_matrix <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:<br>            <span class=\"hljs-comment\"># adj_matrix 维度: [B, N, N]</span><br>            <span class=\"hljs-keyword\">for</span> neighbor_layer <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.neighbor_layers:<br>                <span class=\"hljs-comment\"># 这里的 mask 确保只在相连顶点间算 Attention</span><br>                pc0_embed_res = neighbor_layer(pc0_embed, key=pc0_embed, value=pc0_embed, mask=adj_matrix) <span class=\"hljs-comment\"># [B, N, C]</span><br>                pc0_embed = pc0_embed + pc0_embed_res <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>过 <code>n</code> 遍 <code>self-attention</code> + 残差连接，修改结果保存在 <code>pc0_embed</code></p>\n<p>接下来要做最远点采样，我们先保存一版采样前的结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 保存全量顶点特征，用于后续 Cross-Attention 的 Key 和 Value</span><br>        pc0_embed_ori = pc0_embed <span class=\"hljs-comment\"># [B, N, C]</span><br>        pct_embed_ori = pct_embed <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>然后应用最远点采样，得到采样结果 <code>idx</code> 然后更新 <code>pc0_embed</code> 和 <code>pct_embed</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 5. 最远点采样 (FPS)</span><br>        <span class=\"hljs-keyword\">with</span> torch.no_grad():<br>            valid_length = valid_mask.<span class=\"hljs-built_in\">sum</span>(dim=-<span class=\"hljs-number\">1</span>)<br>            <span class=\"hljs-comment\"># 从 N 个点中选出 K 个代表点的索引</span><br>            _, idx = ops.sample_farthest_points(points=pc0_embed, lengths=valid_length, K=<span class=\"hljs-variable language_\">self</span>.num_traj) <br>            <span class=\"hljs-comment\"># idx 维度: [B, K]</span><br>            idx = replace_negative_indices(idx, valid_length)<br><br>        <span class=\"hljs-comment\"># 6. 根据索引提取代表点的特征 (Gather)</span><br>        <span class=\"hljs-comment\"># pc0_embed: [B, K, C]</span><br>        pc0_embed = torch.gather(pc0_embed, <span class=\"hljs-number\">1</span>, idx.unsqueeze(-<span class=\"hljs-number\">1</span>).expand(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>, pc0_embed.shape[-<span class=\"hljs-number\">1</span>]))<br>        <span class=\"hljs-comment\"># pct_embed: [B, K, C]</span><br>        pct_embed = torch.gather(pct_embed, <span class=\"hljs-number\">1</span>, idx.unsqueeze(-<span class=\"hljs-number\">1</span>).expand(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>, pct_embed.shape[-<span class=\"hljs-number\">1</span>]))<br><br></code></pre></td></tr></table></figure>\n<p>这时， <code>pc0_embed</code> 是采样后的版本，<code>pc0_embed_ori</code> 存储采样前的结果</p>\n<p>接下来做 <code>cross_attention</code></p>\n<ul>\n<li>Query = pc0_embed （采样后）</li>\n<li>Key = pc0_embed_ori (采样前)</li>\n<li>Value1 = pc0_embed_ori(采样前)</li>\n<li>Value2 = pct_embed_ori(采样前)</li>\n</ul>\n<p>每次过完一个 <code>attention</code> 后接一个前馈网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 7. 编码器块 (公式 3 &amp; 4: Cross-Attention 聚合全局信息)</span><br>        <span class=\"hljs-keyword\">for</span> enc_attn, enc_ffn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.enc_blocks:<br>            <span class=\"hljs-comment\"># q_stream: 代表点 [B, K, C]</span><br>            <span class=\"hljs-comment\"># k/v_stream: 原始全量点 [B, N, C]</span><br>            attn_res_0, attn_res_t = enc_attn(<br>                q_stream=pc0_embed, <br>                k_stream=pc0_embed_ori, <br>                v1_stream=pc0_embed_ori, <br>                v2_stream=pct_embed_ori<br>            )<br>            pc0_embed = pc0_embed + attn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>            pct_embed = pct_embed + attn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br>            <br>            <span class=\"hljs-comment\"># FFN 层处理</span><br>            ffn_res_0, ffn_res_t = enc_ffn(pc0_embed, pct_embed) <span class=\"hljs-comment\"># [B, K, C]</span><br>            pc0_embed = pc0_embed + ffn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>            pct_embed = pct_embed + ffn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>接下来我们需要一个latent来表征原始的静态结构，直接全连接就好了</p>\n<p>这大概是一个重建任务吧，所以没有什么不确定性，目标是和原本的初始动作一样就好了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 8. VAE 潜在空间映射 (公式 5 &amp; 6)</span><br>        <span class=\"hljs-comment\"># 形状特征 x0: 不做 KL 约束</span><br>        x0 = <span class=\"hljs-variable language_\">self</span>.mean_fc_x0(pc0_embed) <span class=\"hljs-comment\"># [B, K, C_latent]</span><br></code></pre></td></tr></table></figure>\n<p>接下来是轨迹采样，需要有不确定性了</p>\n<p>VAE采样过程：</p>\n<ul>\n<li>得到 <code>mean</code> 和 <code>logvar</code></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">mean = <span class=\"hljs-variable language_\">self</span>.mean_fc_xt(pct_embed)<br>logvar = <span class=\"hljs-variable language_\">self</span>.logvar_fc_xt(pct_embed)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>接下来是采样</li>\n</ul>\n<blockquote>\n<p>直接采样高斯分布是不可导的，所以需要使用重参数化</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 无法求梯度</span><br>z = torch.normal(mean=mean, std=std)<br><span class=\"hljs-comment\"># 先采样一个随机噪声（不参与梯度的计算）</span><br>epsilon = torch.randn_like(mean)<br>z = mean + torch.exp(<span class=\"hljs-number\">0.5</span>*logvar) * epsilon<br></code></pre></td></tr></table></figure>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 重参数化采样 (Reparameterization)</span><br>  posterior = DiagonalGaussianDistribution(mean, logvar)<br>  xt = posterior.sample() <span class=\"hljs-comment\"># [B, K, C_latent]</span><br>  kl = posterior.kl()     <span class=\"hljs-comment\"># [B, K] 或标量</span><br></code></pre></td></tr></table></figure>\n<p>最后把 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 拼接在一起</p>\n<p>返回 <code>kl</code> encode的最终结果<code>x</code> 采样的结果 <code>idx</code> ，原始的未采样的 <code>pc0_embed_ori</code></p>\n<p><strong>decode</strong></p>\n<p>定义及传入参数</p>\n<ul>\n<li>encode 中拼接了初始的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 得到这里输入的 <code>x</code></li>\n<li>queries 是原始的 <code>N</code> 个点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>B</mi><mo separator=\"true\">,</mo><mi>N</mi><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[B,N,3]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>pc0_embed_ori 是特征增强的原始的 <code>N</code> 个点 <code>[B,N,C]</code></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decode</span>(<span class=\"hljs-params\">self, x, queries, pc0_embed_ori</span>):<br></code></pre></td></tr></table></figure>\n<p>首先拆掉拼接在一起的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>然后把他们从 <code>C_latent</code> 维度投影到 <code>C</code> 维度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 1. 拆分形状 Latent 和 动作 Latent</span><br>  x0_latent, xt_latent = x.chunk(<span class=\"hljs-number\">2</span>, dim=-<span class=\"hljs-number\">1</span>) <span class=\"hljs-comment\"># 分别为 [B, K, C_latent]</span><br><br>  <span class=\"hljs-comment\"># 2. 投影回隐藏层维度</span><br>  x0 = <span class=\"hljs-variable language_\">self</span>.proj_x0(x0_latent) <span class=\"hljs-comment\"># [B, K, C]</span><br>  xt = <span class=\"hljs-variable language_\">self</span>.proj_xt(xt_latent) <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>然后是解码自注意力</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 3. 解码器自注意力块 (代表点之间进行信息交换)</span><br><span class=\"hljs-keyword\">for</span> dec_attn, dec_ffn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.dec_blocks:<br>    <span class=\"hljs-comment\"># Self-Attention: 代表点之间互相观察，优化动作逻辑</span><br>    attn_res_0, attn_res_t = dec_attn(<br>        q_stream=x0, <br>        k_stream=x0, <br>        v1_stream=x0, <br>        v2_stream=xt<br>    )<br>    x0 = x0 + attn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>    xt = xt + attn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br><br>    <span class=\"hljs-comment\"># FFN 层</span><br>    ffn_res_0, ffn_res_t = dec_ffn(x0, xt)<br>    x0 = x0 + ffn_res_0 <span class=\"hljs-comment\"># [B, K, C]</span><br>    xt = xt + ffn_res_t <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>把全量点的形状特征作为 <code>Query</code></p>\n<p>使用 <code>cross-attention</code></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key</code></p>\n<p>而轨迹的特征 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Value</code></p>\n<p>使得每一个点(全量)都能查询到关于运动轨迹的信息</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 4. 最终交叉注意力 (从 K 个代表点上采样到 N 个原始点)</span><br>  <span class=\"hljs-comment\"># query_embed: 将全量点的形状特征作为查询 [B, N, C]</span><br>  query_embed = <span class=\"hljs-variable language_\">self</span>.fc_query(pc0_embed_ori) <span class=\"hljs-comment\"># [B, N, C]</span><br><br>  <span class=\"hljs-comment\"># Cross-Attention: </span><br>  <span class=\"hljs-comment\"># 每个原始点 (N) 去询问代表点 (K)：“我该怎么动？”</span><br>  <span class=\"hljs-comment\"># key=x0 (形状参考), value=xt (动作参考)</span><br>  latents = <span class=\"hljs-variable language_\">self</span>.decoder_final_ca(query_embed, key=x0, value=xt) <span class=\"hljs-comment\"># [B, N, C]</span><br></code></pre></td></tr></table></figure>\n<p>这时，每个点都得到了关于运动轨迹的信息，就可以开始做输出了</p>\n<p>其实就是在后面接一个 <code>Linear</code> (不是<code>mlp</code>)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 5. 投影到 3D 坐标偏移空间</span><br><span class=\"hljs-comment\"># self.to_outputs 将 C 维映射到 (T-1)*3 维</span><br>outputs = <span class=\"hljs-variable language_\">self</span>.to_outputs(latents) <span class=\"hljs-comment\"># [B, N, (T-1)*3]</span><br></code></pre></td></tr></table></figure>\n<p>然后就是调整一下维度 由于我们得到的都是相对于第一帧的位置偏移，所以<code>outputs</code> 中的每一个输出都要与第一帧的点云相加，才能得到4D的运动序列</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 6. 重塑维度还原为序列格式</span><br><span class=\"hljs-comment\"># .view(...) -&gt; [B, N, T-1, 3]</span><br><span class=\"hljs-comment\"># .permute(0, 2, 1, 3) -&gt; [B, T-1, N, 3] (时间维度排在前面)</span><br>outputs = outputs.view(x.shape[<span class=\"hljs-number\">0</span>], queries.shape[<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>).permute(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>) <span class=\"hljs-comment\"># [B, T-1, N, 3]</span><br><br><span class=\"hljs-comment\"># 7. 合成最终动画 (公式 1)</span><br><span class=\"hljs-comment\"># queries[:, None] 维度是 [B, 1, N, 3] (初始帧)</span><br><span class=\"hljs-comment\"># 将初始位置与每一帧的相对位移相加</span><br>outputs = queries[:, <span class=\"hljs-literal\">None</span>] + outputs <span class=\"hljs-comment\"># [B, T-1, N, 3]</span><br><br><span class=\"hljs-keyword\">return</span> outputs <span class=\"hljs-comment\"># 返回完整的动态序列 (不含第一帧，或根据实现包含第一帧)</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"shape-guided-text-to-trajectory-model\"><a class=\"markdownIt-Anchor\" href=\"#shape-guided-text-to-trajectory-model\"></a> Shape-Guided Text-to-Trajectory Model</h4>\n<p>基于 <code>MMDiT</code></p>\n<blockquote>\n<p>传统的 <code>DiT</code> 对 <code>image</code> 做 self attention 然后对 <code>text</code> 做 <code>cross attention</code> 其中 image 是主体 text 是条件</p>\n<p>MMDiT: MultiModel DiT</p>\n<p>把 <code>text</code> 和 <code>image</code> 同时做 <code>self-attention</code></p>\n<p>传统的 <code>DiT</code> 只有 <code>image</code> 到 <code>text</code> 的 query</p>\n<p>而在MMDiT中，同时存在</p>\n<ul>\n<li>image -&gt; image</li>\n<li>Text -&gt; text</li>\n<li>image -&gt; text</li>\n<li>Text -&gt; image</li>\n</ul>\n<p>的query</p>\n</blockquote>\n<p><strong>整体结构</strong></p>\n<figure class=\"highlight tex\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tex\">输入: x (动作Latent噪声) [B,K,C], t (时间步) [B], texts (文本列表)<br>                          │<br>          ┌───────────────┼───────────────┐<br>          ▼               ▼               ▼<br>    timestep<span class=\"hljs-built_in\">_</span>embedding  CLIP Text       input<span class=\"hljs-built_in\">_</span>proj<br>    + time<span class=\"hljs-built_in\">_</span>embed(MLP)   Encoder         (Linear)<br>          │             + clip<span class=\"hljs-built_in\">_</span>token<span class=\"hljs-built_in\">_</span>mlp      │<br>          ▼               ▼               ▼<br>        t<span class=\"hljs-built_in\">_</span>emb          text<span class=\"hljs-built_in\">_</span>embed          h<br>       [B, W]          [B, 77, W]       [B, K, W]<br>          │               │               │<br>          └───────┬───────┘               │<br>                  ▼                       ▼<br>            ┌─────────────────────────────────┐<br>            │   Transformer<span class=\"hljs-built_in\">_</span>cogx (×N layers)  │<br>            │   CogXAttentionBlock:           │<br>            │     - AdaLN-Zero (x <span class=\"hljs-built_in\">&amp;</span> text)     │<br>            │     - Joint Self-Attention       │<br>            │     - Joint MLP                  │<br>            └─────────────────────────────────┘<br>                          │<br>                    output<span class=\"hljs-built_in\">_</span>proj → 预测噪声/速度场 [B, K, C]<br></code></pre></td></tr></table></figure>\n<p>这一部分考虑了文本信息和静态结构，输出是一个速度场，用来为扩散过程提供指导。</p>\n<p>每一步扩散都会调用这个 <code>MMDiT</code> 得到引导</p>\n<h4 id=\"diffusion-pipeline\"><a class=\"markdownIt-Anchor\" href=\"#diffusion-pipeline\"></a> <strong>Diffusion Pipeline</strong></h4>\n<p>Training</p>\n<p>得到时间步</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 1. 采样时间步 ----</span><br>    times = torch.rand(x_start.shape[<span class=\"hljs-number\">0</span>], device=x_start.device)  <span class=\"hljs-comment\"># [B] — t ~ U(0,1)</span><br>    padded_times = append_dims(times, x_start.ndim - <span class=\"hljs-number\">1</span>)           <span class=\"hljs-comment\"># [B, 1, 1] — 扩展维度以广播</span><br>    <br>    <span class=\"hljs-comment\"># ---- 2. 构造加噪样本 ----</span><br>    t = cosmap(padded_times)                           <span class=\"hljs-comment\"># [B, 1, 1] — cosine 重映射后的时间步</span><br>    x_t = t * x_start + (<span class=\"hljs-number\">1.</span> - t) * noise              <span class=\"hljs-comment\"># [B, K, C] — 线性插值 (t=1→数据, t=0→噪声)</span><br>    <br>    <span class=\"hljs-comment\"># ---- 3. 保护 f0 通道: 用原始 x_start 的 f0 替换加噪版本 ----</span><br>    <span class=\"hljs-comment\"># x_start[:, :, :f0_channels] → [B, K, f0] 静态形状，不加噪</span><br>    <span class=\"hljs-comment\"># x_t[:, :, f0_channels:]     → [B, K, ft] 动态运动，已加噪</span><br>    x_t = torch.cat([x_start[:, :, :f0_channels], x_t[:, :, f0_channels:]], dim=-<span class=\"hljs-number\">1</span>)  <span class=\"hljs-comment\"># [B, K, C]</span><br></code></pre></td></tr></table></figure>\n<p>其中 <code>cosmap</code> 会做时间步的重映射，中间的时间步 例如 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">t=0.5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span></span></span></span> 会被采样得更多</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 会得到 静态形状 + 动态运动的混合张量，只有动态运动的部分混上噪声</p>\n<p>然后计算 <code>flow</code> 也就是从 <code>noise</code> 到 <code>x_start</code> 的直线方向</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 4. 计算目标 flow ----</span><br>    flow = x_start - noise     <br></code></pre></td></tr></table></figure>\n<p>然后使用 <code>DyMeshMMDiT</code> 考虑 <code>text</code> 、 运动轨迹，期望得到的是从 <code>noise</code> 到 <code>x_start</code> 或者预测结果的 方向向量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 5. 模型前向传播 ----</span><br><span class=\"hljs-comment\"># model = DyMeshMMDiT, 调用其 forward(x_t, t, texts=...)</span><br>model_output = model(                              <span class=\"hljs-comment\"># [B, K, C] — 模型预测的 flow 或 noise</span><br>    x_t,                                           <span class=\"hljs-comment\"># [B, K, C] — 加噪样本 (f0 未加噪)</span><br>    t.squeeze(-<span class=\"hljs-number\">1</span>).squeeze(-<span class=\"hljs-number\">1</span>),                     <span class=\"hljs-comment\"># [B]       — 时间步 (去掉扩展的维度)</span><br>    **model_kwargs<br>)<br></code></pre></td></tr></table></figure>\n<p>然后把 <code>model_output</code> 和实际得到的 <code>flow</code> 去做 <code>mse</code> 得到 <code>loss</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># ---- 6. 选择预测目标 ----</span><br><span class=\"hljs-keyword\">if</span> predict == <span class=\"hljs-string\">&#x27;flow&#x27;</span>:<br>    target = flow                                  <span class=\"hljs-comment\"># [B, K, C] — 目标: x_start - noise</span><br><span class=\"hljs-keyword\">elif</span> predict == <span class=\"hljs-string\">&#x27;noise&#x27;</span>:<br>    target = noise                                 <span class=\"hljs-comment\"># [B, K, C] — 目标: 噪声本身</span><br><span class=\"hljs-keyword\">else</span>:<br>    <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">f&#x27;unknown objective <span class=\"hljs-subst\">&#123;predict&#125;</span>&#x27;</span>)<br><br><span class=\"hljs-comment\"># ---- 7. 计算 MSE 损失 (仅在 ft 动态通道上) ----</span><br>ft_channels = x_start.shape[-<span class=\"hljs-number\">1</span>] - f0_channels      <span class=\"hljs-comment\"># ft 通道数 = C - f0</span><br><span class=\"hljs-comment\"># 只取最后 ft_channels 个通道计算损失，忽略 f0 (静态形状不需要预测)</span><br>terms[<span class=\"hljs-string\">&quot;mse&quot;</span>] = mean_flat(                          <span class=\"hljs-comment\"># [B] — 逐样本 MSE</span><br>    (target[:, :, -ft_channels:] - model_output[:, :, -ft_channels:]) ** <span class=\"hljs-number\">2</span><br>)                                                  <span class=\"hljs-comment\"># target/output 切片: [B, K, ft]</span><br><br>terms[<span class=\"hljs-string\">&quot;loss&quot;</span>] = terms[<span class=\"hljs-string\">&quot;mse&quot;</span>]                       <span class=\"hljs-comment\"># [B]</span><br><br><span class=\"hljs-keyword\">return</span> terms<br></code></pre></td></tr></table></figure>\n<p>训练的结果就是 <code>DyMeshMMDiT</code> 学会了生成 <code>flow</code></p>\n<blockquote>\n<p>Flow =&gt;也就是 <code>noise</code> 到目标 <code>latent</code> （运动轨迹）的直线方向。</p>\n</blockquote>\n<h3 id=\"egotwin\"><a class=\"markdownIt-Anchor\" href=\"#egotwin\"></a> EgoTwin</h3>\n<p>标题：EgoTwin: Dreaming Body and View in First Person</p>\n<p>生成第一人称视角的视频</p>\n<p>有两个<strong>对齐</strong>的挑战，一个是相机轨迹(决定了相机拍到什么)和人体的头部运动的对齐</p>\n<p>二是人体与环境交互的动作和环境变化的对齐（因果交互）</p>\n<h4 id=\"问题定义\"><a class=\"markdownIt-Anchor\" href=\"#问题定义\"></a> 问题定义</h4>\n<p>输入</p>\n<ul>\n<li>骨骼序列</li>\n<li>RGB ego View 首帧</li>\n<li>Text Prompt</li>\n</ul>\n<p>输出</p>\n<ul>\n<li>骨骼运动序列 4D  pose sequence</li>\n<li>RGB ego 视频 view sequence</li>\n</ul>\n<h4 id=\"modality-tokenization-不同模态怎么做tokenization\"><a class=\"markdownIt-Anchor\" href=\"#modality-tokenization-不同模态怎么做tokenization\"></a> Modality Tokenization 不同模态怎么做tokenization</h4>\n<p><strong>视频</strong> 使用 3D VAE，使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn><mo>×</mo><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">4\\times 8\\times 8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">8</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">8</span></span></span></span> 的压缩率</p>\n<blockquote>\n<p><code>3D VAE</code> 传统的 VAE 处理二维图像，3D考虑了时间维度</p>\n</blockquote>\n<p><strong>文本</strong> 使用 <code>T5-XXL</code></p>\n<h5 id=\"motion-representation-动作表征\"><a class=\"markdownIt-Anchor\" href=\"#motion-representation-动作表征\"></a> motion representation 动作表征</h5>\n<blockquote>\n<p>传统表征：过参数化，记录七个参数</p>\n<ol>\n<li>根部转圈的角速度</li>\n<li>走位的速度，根部的平面线速度</li>\n<li>根部的高度(屁股的高度)</li>\n<li>关节的位置（除了屁股之外，其他关节相对于屁股的位置）</li>\n<li>局部关节的速度</li>\n<li>局部关节的旋转</li>\n<li>脚与地面是否接触</li>\n</ol>\n</blockquote>\n<p>传统表示难以做到与 <code>ego view</code> 做对齐，需要 <code>head-centric</code> 以头部为中心</p>\n<blockquote>\n<ol>\n<li>头部的移动</li>\n<li>头部的速度</li>\n<li>头部的旋转角度</li>\n<li>头部的旋转速度</li>\n<li>关节的位置  =&gt; 关节是以头为参考系的相对表示</li>\n<li>关节的速度</li>\n<li>关节的旋转</li>\n</ol>\n</blockquote>\n<h5 id=\"motion-tokenization\"><a class=\"markdownIt-Anchor\" href=\"#motion-tokenization\"></a> motion tokenization</h5>\n<blockquote>\n<p>causal 1D CNN 处理音频或着视频生成</p>\n<p>普通的 <code>CNN</code>  =&gt; 模型可以看到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t-1, t, t+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 但是在生成任务中，看不到未来的数据！</p>\n<p>做法：</p>\n<p>左侧填充 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 个 0， 每次运算只涉及 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t-k+1, ... , t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 的数据</p>\n</blockquote>\n<p>我们想要做的是可交互的4D生成。从具体的任务而言，包括应用于具身的任务 一般场景的4D重建 主体的运动4D生成</p>\n<p>具身的任务是指对场景，机器人等做4D的表征，让模型了解这一个场景，然后做出决策，例如Dream2Flow、PointWorld</p>\n<p>一般场景的4D重建包括 Any4D、D4RT、TrackingWorld。</p>\n<p>这两种任务关注于对场景的表征，而主体的运动4D生成更加关注于对于特定主体的表征，往往需要添加骨骼信息，运动序列，而不仅仅是4D点流了，包括 <code>AnimateAnyMesh</code> <code>EgoTwin</code> <code>Uni-Inter</code> <code>Mo-CapAnything</code></p>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2026-02-02T17:12:34.320Z","updated":"2026-02-02T17:38:12.268Z","comments":1,"layout":"post","photos":[],"_id":"cmlnjmvur0001a5jka9dtc89d","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"quick-start\"><a class=\"markdownIt-Anchor\" href=\"#quick-start\"></a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"markdownIt-Anchor\" href=\"#create-a-new-post\"></a> Create a new post</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"run-server\"><a class=\"markdownIt-Anchor\" href=\"#run-server\"></a> Run server</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"generate-static-files\"><a class=\"markdownIt-Anchor\" href=\"#generate-static-files\"></a> Generate static files</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"markdownIt-Anchor\" href=\"#deploy-to-remote-sites\"></a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"quick-start\"><a class=\"markdownIt-Anchor\" href=\"#quick-start\"></a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"markdownIt-Anchor\" href=\"#create-a-new-post\"></a> Create a new post</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"run-server\"><a class=\"markdownIt-Anchor\" href=\"#run-server\"></a> Run server</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"generate-static-files\"><a class=\"markdownIt-Anchor\" href=\"#generate-static-files\"></a> Generate static files</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"markdownIt-Anchor\" href=\"#deploy-to-remote-sites\"></a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"init","date":"2026-02-02T18:37:16.000Z","_content":"","source":"_posts/init.md","raw":"---\ntitle: init\ndate: 2026-02-03 02:37:16\ntags:\n---\n","slug":"init","published":1,"updated":"2026-02-02T18:37:16.323Z","comments":1,"layout":"post","photos":[],"_id":"cmlnjmvus0002a5jk7ac9f4x8","content":"","excerpt":"","more":""},{"title":"reading DiT code","date":"2026-02-05T19:28:36.000Z","_content":"\n# Time Embedding\n\nwe try to enrich the information of a time scalar!\n\nif we dont do so, the info that the model can get from the time scalar is poor.\n\n```python\ndef forward(self, t):\n        # t_freq [batch, ..., t, dim]\n        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n        t_emb = self.mlp(t_freq)\n        # t_emb [batch, ..., t, hidden]\n        return t_emb\n```\n\n这里的 `t` 其实就是 `[batch, ]`\n\nlike `[4,4,4,4,4,4,...]` \n\n`timestep_embedding` using sin and cos to encode the number\n\ncode is like:\n\n```python\n@staticmethod\n    def timestep_embedding(t, dim, max_period=10000):\n        \"\"\"\n        Create sinusoidal timestep embeddings.\n        :param t: a 1-D Tensor of N indices, one per batch element.\n                          These may be fractional.\n        :param dim: the dimension of the output.\n        :param max_period: controls the minimum frequency of the embeddings.\n        :return: an (N, D) Tensor of positional embeddings.\n        \"\"\"\n        # https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py\n        half = dim // 2\n        # freqs = exp(-log(max_period) * [0, ..., half - 1] / half)\n        # [dim // 2]\n        freqs = torch.exp(\n            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n        ).to(device=t.device)\n        # t 应该是位置信息 [batch, ..., t, 1]\n        # freqs [1, dim // 2]\n        # args -> [batch, ..., t, dim // 2]\n        args = t[:, None].float() * freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n        # embedding -> [batch, ..., t, dim]\n        return embedding\n```\n\nafter the `timestep_embedding` we got the torch like [batch, dim]\n\nafter the mlp, we got [batch, hidden]\n\nthat is, TimestepEmbedder change from  `[batch]` to.`[batch, hidden]`\n\n\n\n# LabelEmbedder\n\nwe are using **Classifier-Free Guidance (CFG)** \n\n先考虑条件生成，模型有时候的生成结果和条件拟合的不够好。比如生成的图片结果和你的 `text prompt` 在语义上靠的还不够近。这时候，你希望生成的结果再靠近条件一点，和条件更加贴合！\n\n对于带条件的生成，我们往往需要先训练一个 Classifier，它的作用是对于给定的图像，输出它的分类类别。训练好了以后，他就有了看图的能力。\n\n在扩散的过程中，每次 sample 一个噪音，使用Classifier对 input 求梯度，用这个梯度去 modify sample出来的噪音，给这个noise以引导。然后用这个noise去更新 `x` \n\n使用CFG就不用一个额外的classfier了。训练的时候，他会随机的丢弃标签，进行无标签的生成\n\n形式化来讲，每次的输入是一个\n$$\n<x_t,t,c>\n$$\n**训练时：**\n\n我们有概率地（`p=0.1~0.2`）令\n$$\nc = \\empty\n$$\n 这样模型同时学会了无条件生成和带条件生成\n\n**推理时**\n\n走两次\n\n1. $$\n   input = <x_t,t, c>\n   $$\n\n2. $$\n   input=<x_t,t,\\empty>\n   $$\n\n然后两个结果进行综合\n$$\n\\hat{\\epsilon}=s\\epsilon_{conditioned}+(1-s)\\epsilon_{unconditioned}\n$$\n一般\n$$\ns = [5, 7]\n$$\n相当于有了一个 $\\epsilon_{uncond}$ 又有了一个 $\\epsilon_{cond}$  两者做差你就知道 $cond$ 的方向在哪里了！\n\n`LabelEmbedder` 的 `__init__`\n\n```python\ndef __init__(self, num_classes, hidden_size, dropout_prob):\n```\n\n这里 `dropout_prob` 应该是随机丢掉分类的概率\n\n```python\nuse_cfg_embedding = dropout_prob > 0\nself.embedding_table = nn.Embedding(num_classes  + use_cfg_embedding, hidden_size)\n```\n\n如果不打算使用 CFG 的话，dropout_prob 可以设置为一个负数\n\n如果设置为正数，表示 `dropout` 的概率\n\n那么在注册 `Embedding_table` 的时候会多加一个分类\n\n`forward` 的定义\n\n```python\ndef forward(self, labels, train, force_drop_ids=None):\n```\n\n`train` 是一个 `boolean` 决定是否在训练模式\n\n`labels` 是一个标签的列表 `[batch, ]`\n\n```python\ndef forward(self, labels, train, force_drop_ids=None):\n        # 无分类引导\n        use_dropout = self.dropout_prob > 0\n        if (train and use_dropout) or (force_drop_ids is not None):\n          # token_drop 随机把一些标签打掉\n            labels = self.token_drop(labels, force_drop_ids)\n        # 然后把labels拿去做embeddings\n        embeddings = self.embedding_table(labels)\n        return embeddings\n```\n\n总的来说，`Label_embedder` \n\ndo such changes\n\n`[batchsize, ]` -> `[batchsize, hidden_size]`\n\n支持随机的把一些标签置空\n\n```python\nlabels = torch.where(drop_ids, self.num_classes, labels)\n```\n\n如果 `drop_ids` 对应的位置是 `True` 就把这里的 `label_id` 值换成 `self.num_classes` 表示 `invalid` \n\n## DIT Block\n\n`forward` 实现\n\n```python\ndef forward(self, x, c):\n        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=1)\n        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))\n        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n        return x\n```\n\n先看 `adaLN_modulation` 的实现\n\n```python\nself.adaLN_modulation = nn.Sequential(\n            nn.SiLU(),\n            nn.Linear(hidden_size, 6 * hidden_size, bias=True)\n        )\n```\n\n输入是条件 `c` \n\n这里的 `c` 是把 `time_embedding` 和 `label_embedding` 加在一起\n\n在 `class DiT` 中使用了 `DiTBlock`\n\n```python\nself.blocks = nn.ModuleList([\n            DiTBlock(hidden_size, num_heads, mlp_ratio=mlp_ratio) for _ in range(depth)\n        ])\n```\n\n为什么使用 `nn.ModuleList` 而不是直接使用 `[]` 呢，使用 `nn.ModuleList` `pytorch` 才能看见这些模型，会为模型自动注册对应的参数。和 `nn.Sequential` 的区别在于，`nn.Sequential` 中数据会自动流过每一 `layer` 而 `nn.ModuleList` 更像是一个容器而已\n\n节选自 `DiT` 的 `forward`\n\n```python\nx = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n        t = self.t_embedder(t)                   # (N, D)\n        y = self.y_embedder(y, self.training)    # (N, D)\n        c = t + y                                # (N, D)\n        for block in self.blocks:\n            x = block(x, c)                      # (N, T, D)\n```\n\n可以看到条件就是把 time embedder, label embedder 的结果加在一起\n\n\n\nForward 中的 `adaLN_modulation` 返回一个长度为 6 的列表，每一个元素就是 `[batch_size, hidden_size]`\n\n```python\nshift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=1)\n```\n\n一个 `DitBlock` 分为两个阶段：\n\n- **MHSA（多头自注意力）\\**负责\\**“横向沟通”**：它的作用是让不同的 Patch（Token）互相看一看，理解空间关系（比如：这个补丁里的猫耳朵和另一个补丁里的猫眼睛是什么关系）。\n- **FFN（前馈网络）\\**负责\\**“纵向挖掘”**：在注意力机制帮 Token 收集完周围的信息后，FFN 负责对这些收集到的信息进行深度处理和非线性变换，将原始特征转化为更高级的概念表示。\n\n代码实现\n\n```python\nx = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))\n        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n        \n```\n\n其中 `modulate` 实现，残差连接 + （乘以 scale + shift）\n\n```python\n\ndef modulate(x, shift, scale):\n    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n```\n\n\n\n其中 `mlp` 就是 `FFN` 前馈网络(Pointwise Feedforward)\n\n多头注意力实现\n\n```python\nself.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=True, **block_kwargs)\n```\n\n前馈网络，`DitBlock` 中的定义\n\n```python\nself.mlp = Mlp(in_features=hidden_size, hidden_features=mlp_hidden_dim, act_layer=approx_gelu, drop=0)\n```\n\n实际上 `Mlp` 中会经历一个先提升维度，再降低维度的过程\n\n以下是 `Mlp` 的具体实现\n\n```python\nclass Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features, out_features, act_layer):\n        super().__init__()\n        # 第一层：将维度从 in_features (hidden_size) 增加到 hidden_features (通常是 4倍)\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        # 第二层：将维度从 hidden_features 还原回 in_features\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.drop = nn.Dropout(0)\n\n    def forward(self, x):\n        x = self.fc1(x)  # 升维操作\n        x = self.act(x)  # 非线性激活\n        x = self.fc2(x)  # 降维操作\n        return x\n\n```\n\n各个模块搭建好了，接下来可以看 `DiT` 了\n\n输入是 `x`  使用 `VAE` 进行下采样\n\n`256, 256` -> `32, 32` 论文中 `VAE` 后的通道数为 `4`\n\n输入 `x` `batch_size, 4, 32, 32` \n\n```python\nx = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n```\n\n","source":"_posts/reading-DiT-code.md","raw":"---\ntitle: reading DiT code\ndate: 2026-02-06 03:28:36\ntags:\n---\n\n# Time Embedding\n\nwe try to enrich the information of a time scalar!\n\nif we dont do so, the info that the model can get from the time scalar is poor.\n\n```python\ndef forward(self, t):\n        # t_freq [batch, ..., t, dim]\n        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n        t_emb = self.mlp(t_freq)\n        # t_emb [batch, ..., t, hidden]\n        return t_emb\n```\n\n这里的 `t` 其实就是 `[batch, ]`\n\nlike `[4,4,4,4,4,4,...]` \n\n`timestep_embedding` using sin and cos to encode the number\n\ncode is like:\n\n```python\n@staticmethod\n    def timestep_embedding(t, dim, max_period=10000):\n        \"\"\"\n        Create sinusoidal timestep embeddings.\n        :param t: a 1-D Tensor of N indices, one per batch element.\n                          These may be fractional.\n        :param dim: the dimension of the output.\n        :param max_period: controls the minimum frequency of the embeddings.\n        :return: an (N, D) Tensor of positional embeddings.\n        \"\"\"\n        # https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py\n        half = dim // 2\n        # freqs = exp(-log(max_period) * [0, ..., half - 1] / half)\n        # [dim // 2]\n        freqs = torch.exp(\n            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n        ).to(device=t.device)\n        # t 应该是位置信息 [batch, ..., t, 1]\n        # freqs [1, dim // 2]\n        # args -> [batch, ..., t, dim // 2]\n        args = t[:, None].float() * freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n        # embedding -> [batch, ..., t, dim]\n        return embedding\n```\n\nafter the `timestep_embedding` we got the torch like [batch, dim]\n\nafter the mlp, we got [batch, hidden]\n\nthat is, TimestepEmbedder change from  `[batch]` to.`[batch, hidden]`\n\n\n\n# LabelEmbedder\n\nwe are using **Classifier-Free Guidance (CFG)** \n\n先考虑条件生成，模型有时候的生成结果和条件拟合的不够好。比如生成的图片结果和你的 `text prompt` 在语义上靠的还不够近。这时候，你希望生成的结果再靠近条件一点，和条件更加贴合！\n\n对于带条件的生成，我们往往需要先训练一个 Classifier，它的作用是对于给定的图像，输出它的分类类别。训练好了以后，他就有了看图的能力。\n\n在扩散的过程中，每次 sample 一个噪音，使用Classifier对 input 求梯度，用这个梯度去 modify sample出来的噪音，给这个noise以引导。然后用这个noise去更新 `x` \n\n使用CFG就不用一个额外的classfier了。训练的时候，他会随机的丢弃标签，进行无标签的生成\n\n形式化来讲，每次的输入是一个\n$$\n<x_t,t,c>\n$$\n**训练时：**\n\n我们有概率地（`p=0.1~0.2`）令\n$$\nc = \\empty\n$$\n 这样模型同时学会了无条件生成和带条件生成\n\n**推理时**\n\n走两次\n\n1. $$\n   input = <x_t,t, c>\n   $$\n\n2. $$\n   input=<x_t,t,\\empty>\n   $$\n\n然后两个结果进行综合\n$$\n\\hat{\\epsilon}=s\\epsilon_{conditioned}+(1-s)\\epsilon_{unconditioned}\n$$\n一般\n$$\ns = [5, 7]\n$$\n相当于有了一个 $\\epsilon_{uncond}$ 又有了一个 $\\epsilon_{cond}$  两者做差你就知道 $cond$ 的方向在哪里了！\n\n`LabelEmbedder` 的 `__init__`\n\n```python\ndef __init__(self, num_classes, hidden_size, dropout_prob):\n```\n\n这里 `dropout_prob` 应该是随机丢掉分类的概率\n\n```python\nuse_cfg_embedding = dropout_prob > 0\nself.embedding_table = nn.Embedding(num_classes  + use_cfg_embedding, hidden_size)\n```\n\n如果不打算使用 CFG 的话，dropout_prob 可以设置为一个负数\n\n如果设置为正数，表示 `dropout` 的概率\n\n那么在注册 `Embedding_table` 的时候会多加一个分类\n\n`forward` 的定义\n\n```python\ndef forward(self, labels, train, force_drop_ids=None):\n```\n\n`train` 是一个 `boolean` 决定是否在训练模式\n\n`labels` 是一个标签的列表 `[batch, ]`\n\n```python\ndef forward(self, labels, train, force_drop_ids=None):\n        # 无分类引导\n        use_dropout = self.dropout_prob > 0\n        if (train and use_dropout) or (force_drop_ids is not None):\n          # token_drop 随机把一些标签打掉\n            labels = self.token_drop(labels, force_drop_ids)\n        # 然后把labels拿去做embeddings\n        embeddings = self.embedding_table(labels)\n        return embeddings\n```\n\n总的来说，`Label_embedder` \n\ndo such changes\n\n`[batchsize, ]` -> `[batchsize, hidden_size]`\n\n支持随机的把一些标签置空\n\n```python\nlabels = torch.where(drop_ids, self.num_classes, labels)\n```\n\n如果 `drop_ids` 对应的位置是 `True` 就把这里的 `label_id` 值换成 `self.num_classes` 表示 `invalid` \n\n## DIT Block\n\n`forward` 实现\n\n```python\ndef forward(self, x, c):\n        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=1)\n        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))\n        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n        return x\n```\n\n先看 `adaLN_modulation` 的实现\n\n```python\nself.adaLN_modulation = nn.Sequential(\n            nn.SiLU(),\n            nn.Linear(hidden_size, 6 * hidden_size, bias=True)\n        )\n```\n\n输入是条件 `c` \n\n这里的 `c` 是把 `time_embedding` 和 `label_embedding` 加在一起\n\n在 `class DiT` 中使用了 `DiTBlock`\n\n```python\nself.blocks = nn.ModuleList([\n            DiTBlock(hidden_size, num_heads, mlp_ratio=mlp_ratio) for _ in range(depth)\n        ])\n```\n\n为什么使用 `nn.ModuleList` 而不是直接使用 `[]` 呢，使用 `nn.ModuleList` `pytorch` 才能看见这些模型，会为模型自动注册对应的参数。和 `nn.Sequential` 的区别在于，`nn.Sequential` 中数据会自动流过每一 `layer` 而 `nn.ModuleList` 更像是一个容器而已\n\n节选自 `DiT` 的 `forward`\n\n```python\nx = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n        t = self.t_embedder(t)                   # (N, D)\n        y = self.y_embedder(y, self.training)    # (N, D)\n        c = t + y                                # (N, D)\n        for block in self.blocks:\n            x = block(x, c)                      # (N, T, D)\n```\n\n可以看到条件就是把 time embedder, label embedder 的结果加在一起\n\n\n\nForward 中的 `adaLN_modulation` 返回一个长度为 6 的列表，每一个元素就是 `[batch_size, hidden_size]`\n\n```python\nshift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=1)\n```\n\n一个 `DitBlock` 分为两个阶段：\n\n- **MHSA（多头自注意力）\\**负责\\**“横向沟通”**：它的作用是让不同的 Patch（Token）互相看一看，理解空间关系（比如：这个补丁里的猫耳朵和另一个补丁里的猫眼睛是什么关系）。\n- **FFN（前馈网络）\\**负责\\**“纵向挖掘”**：在注意力机制帮 Token 收集完周围的信息后，FFN 负责对这些收集到的信息进行深度处理和非线性变换，将原始特征转化为更高级的概念表示。\n\n代码实现\n\n```python\nx = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))\n        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n        \n```\n\n其中 `modulate` 实现，残差连接 + （乘以 scale + shift）\n\n```python\n\ndef modulate(x, shift, scale):\n    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n```\n\n\n\n其中 `mlp` 就是 `FFN` 前馈网络(Pointwise Feedforward)\n\n多头注意力实现\n\n```python\nself.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=True, **block_kwargs)\n```\n\n前馈网络，`DitBlock` 中的定义\n\n```python\nself.mlp = Mlp(in_features=hidden_size, hidden_features=mlp_hidden_dim, act_layer=approx_gelu, drop=0)\n```\n\n实际上 `Mlp` 中会经历一个先提升维度，再降低维度的过程\n\n以下是 `Mlp` 的具体实现\n\n```python\nclass Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features, out_features, act_layer):\n        super().__init__()\n        # 第一层：将维度从 in_features (hidden_size) 增加到 hidden_features (通常是 4倍)\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        # 第二层：将维度从 hidden_features 还原回 in_features\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.drop = nn.Dropout(0)\n\n    def forward(self, x):\n        x = self.fc1(x)  # 升维操作\n        x = self.act(x)  # 非线性激活\n        x = self.fc2(x)  # 降维操作\n        return x\n\n```\n\n各个模块搭建好了，接下来可以看 `DiT` 了\n\n输入是 `x`  使用 `VAE` 进行下采样\n\n`256, 256` -> `32, 32` 论文中 `VAE` 后的通道数为 `4`\n\n输入 `x` `batch_size, 4, 32, 32` \n\n```python\nx = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n```\n\n","slug":"reading-DiT-code","published":1,"updated":"2026-02-09T00:37:33.044Z","comments":1,"layout":"post","photos":[],"_id":"cmlnjmvus0003a5jkb39ma0vz","content":"<h1 id=\"time-embedding\"><a class=\"markdownIt-Anchor\" href=\"#time-embedding\"></a> Time Embedding</h1>\n<p>we try to enrich the information of a time scalar!</p>\n<p>if we dont do so, the info that the model can get from the time scalar is poor.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, t</span>):<br>        <span class=\"hljs-comment\"># t_freq [batch, ..., t, dim]</span><br>        t_freq = <span class=\"hljs-variable language_\">self</span>.timestep_embedding(t, <span class=\"hljs-variable language_\">self</span>.frequency_embedding_size)<br>        t_emb = <span class=\"hljs-variable language_\">self</span>.mlp(t_freq)<br>        <span class=\"hljs-comment\"># t_emb [batch, ..., t, hidden]</span><br>        <span class=\"hljs-keyword\">return</span> t_emb<br></code></pre></td></tr></table></figure>\n<p>这里的 <code>t</code> 其实就是 <code>[batch, ]</code></p>\n<p>like <code>[4,4,4,4,4,4,...]</code></p>\n<p><code>timestep_embedding</code> using sin and cos to encode the number</p>\n<p>code is like:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@staticmethod</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">timestep_embedding</span>(<span class=\"hljs-params\">t, dim, max_period=<span class=\"hljs-number\">10000</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Create sinusoidal timestep embeddings.</span><br><span class=\"hljs-string\">        :param t: a 1-D Tensor of N indices, one per batch element.</span><br><span class=\"hljs-string\">                          These may be fractional.</span><br><span class=\"hljs-string\">        :param dim: the dimension of the output.</span><br><span class=\"hljs-string\">        :param max_period: controls the minimum frequency of the embeddings.</span><br><span class=\"hljs-string\">        :return: an (N, D) Tensor of positional embeddings.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py</span><br>        half = dim // <span class=\"hljs-number\">2</span><br>        <span class=\"hljs-comment\"># freqs = exp(-log(max_period) * [0, ..., half - 1] / half)</span><br>        <span class=\"hljs-comment\"># [dim // 2]</span><br>        freqs = torch.exp(<br>            -math.log(max_period) * torch.arange(start=<span class=\"hljs-number\">0</span>, end=half, dtype=torch.float32) / half<br>        ).to(device=t.device)<br>        <span class=\"hljs-comment\"># t 应该是位置信息 [batch, ..., t, 1]</span><br>        <span class=\"hljs-comment\"># freqs [1, dim // 2]</span><br>        <span class=\"hljs-comment\"># args -&gt; [batch, ..., t, dim // 2]</span><br>        args = t[:, <span class=\"hljs-literal\">None</span>].<span class=\"hljs-built_in\">float</span>() * freqs[<span class=\"hljs-literal\">None</span>]<br>        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-keyword\">if</span> dim % <span class=\"hljs-number\">2</span>:<br>            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :<span class=\"hljs-number\">1</span>])], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># embedding -&gt; [batch, ..., t, dim]</span><br>        <span class=\"hljs-keyword\">return</span> embedding<br></code></pre></td></tr></table></figure>\n<p>after the <code>timestep_embedding</code> we got the torch like [batch, dim]</p>\n<p>after the mlp, we got [batch, hidden]</p>\n<p>that is, TimestepEmbedder change from  <code>[batch]</code> to.<code>[batch, hidden]</code></p>\n<h1 id=\"labelembedder\"><a class=\"markdownIt-Anchor\" href=\"#labelembedder\"></a> LabelEmbedder</h1>\n<p>we are using <strong>Classifier-Free Guidance (CFG)</strong></p>\n<p>先考虑条件生成，模型有时候的生成结果和条件拟合的不够好。比如生成的图片结果和你的 <code>text prompt</code> 在语义上靠的还不够近。这时候，你希望生成的结果再靠近条件一点，和条件更加贴合！</p>\n<p>对于带条件的生成，我们往往需要先训练一个 Classifier，它的作用是对于给定的图像，输出它的分类类别。训练好了以后，他就有了看图的能力。</p>\n<p>在扩散的过程中，每次 sample 一个噪音，使用Classifier对 input 求梯度，用这个梯度去 modify sample出来的噪音，给这个noise以引导。然后用这个noise去更新 <code>x</code></p>\n<p>使用CFG就不用一个额外的classfier了。训练的时候，他会随机的丢弃标签，进行无标签的生成</p>\n<p>形式化来讲，每次的输入是一个</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>c</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">&lt;x_t,t,c&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n<p><strong>训练时：</strong></p>\n<p>我们有概率地（<code>p=0.1~0.2</code>）令</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>c</mi><mo>=</mo><mi mathvariant=\"normal\">∅</mi></mrow><annotation encoding=\"application/x-tex\">c = \\empty\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80556em;vertical-align:-0.05556em;\"></span><span class=\"mord\">∅</span></span></span></span></span></p>\n<p>这样模型同时学会了无条件生成和带条件生成</p>\n<p><strong>推理时</strong></p>\n<p>走两次</p>\n<ol>\n<li>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>c</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">input = &lt;x_t,t, c&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.85396em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n</li>\n<li>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∅</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">input=&lt;x_t,t,\\empty&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.85396em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.94444em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∅</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n</li>\n</ol>\n<p>然后两个结果进行综合</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>ϵ</mi><mo>^</mo></mover><mo>=</mo><mi>s</mi><msub><mi>ϵ</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>s</mi><mo stretchy=\"false\">)</mo><msub><mi>ϵ</mi><mrow><mi>u</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\hat{\\epsilon}=s\\epsilon_{conditioned}+(1-s)\\epsilon_{unconditioned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>一般</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mn>5</mn><mo separator=\"true\">,</mo><mn>7</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">s = [5, 7]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">5</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">7</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>相当于有了一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>u</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\epsilon_{uncond}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 又有了一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\epsilon_{cond}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>  两者做差你就知道 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">cond</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">d</span></span></span></span> 的方向在哪里了！</p>\n<p><code>LabelEmbedder</code> 的 <code>__init__</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, num_classes, hidden_size, dropout_prob</span>):<br></code></pre></td></tr></table></figure>\n<p>这里 <code>dropout_prob</code> 应该是随机丢掉分类的概率</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">use_cfg_embedding = dropout_prob &gt; <span class=\"hljs-number\">0</span><br><span class=\"hljs-variable language_\">self</span>.embedding_table = nn.Embedding(num_classes  + use_cfg_embedding, hidden_size)<br></code></pre></td></tr></table></figure>\n<p>如果不打算使用 CFG 的话，dropout_prob 可以设置为一个负数</p>\n<p>如果设置为正数，表示 <code>dropout</code> 的概率</p>\n<p>那么在注册 <code>Embedding_table</code> 的时候会多加一个分类</p>\n<p><code>forward</code> 的定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, labels, train, force_drop_ids=<span class=\"hljs-literal\">None</span></span>):<br></code></pre></td></tr></table></figure>\n<p><code>train</code> 是一个 <code>boolean</code> 决定是否在训练模式</p>\n<p><code>labels</code> 是一个标签的列表 <code>[batch, ]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, labels, train, force_drop_ids=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-comment\"># 无分类引导</span><br>        use_dropout = <span class=\"hljs-variable language_\">self</span>.dropout_prob &gt; <span class=\"hljs-number\">0</span><br>        <span class=\"hljs-keyword\">if</span> (train <span class=\"hljs-keyword\">and</span> use_dropout) <span class=\"hljs-keyword\">or</span> (force_drop_ids <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>):<br>          <span class=\"hljs-comment\"># token_drop 随机把一些标签打掉</span><br>            labels = <span class=\"hljs-variable language_\">self</span>.token_drop(labels, force_drop_ids)<br>        <span class=\"hljs-comment\"># 然后把labels拿去做embeddings</span><br>        embeddings = <span class=\"hljs-variable language_\">self</span>.embedding_table(labels)<br>        <span class=\"hljs-keyword\">return</span> embeddings<br></code></pre></td></tr></table></figure>\n<p>总的来说，<code>Label_embedder</code></p>\n<p>do such changes</p>\n<p><code>[batchsize, ]</code> -&gt; <code>[batchsize, hidden_size]</code></p>\n<p>支持随机的把一些标签置空</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">labels = torch.where(drop_ids, <span class=\"hljs-variable language_\">self</span>.num_classes, labels)<br></code></pre></td></tr></table></figure>\n<p>如果 <code>drop_ids</code> 对应的位置是 <code>True</code> 就把这里的 <code>label_id</code> 值换成 <code>self.num_classes</code> 表示 <code>invalid</code></p>\n<h2 id=\"dit-block\"><a class=\"markdownIt-Anchor\" href=\"#dit-block\"></a> DIT Block</h2>\n<p><code>forward</code> 实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, c</span>):<br>        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = <span class=\"hljs-variable language_\">self</span>.adaLN_modulation(c).chunk(<span class=\"hljs-number\">6</span>, dim=<span class=\"hljs-number\">1</span>)<br>        x = x + gate_msa.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.attn(modulate(<span class=\"hljs-variable language_\">self</span>.norm1(x), shift_msa, scale_msa))<br>        x = x + gate_mlp.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.mlp(modulate(<span class=\"hljs-variable language_\">self</span>.norm2(x), shift_mlp, scale_mlp))<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<p>先看 <code>adaLN_modulation</code> 的实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.adaLN_modulation = nn.Sequential(<br>            nn.SiLU(),<br>            nn.Linear(hidden_size, <span class=\"hljs-number\">6</span> * hidden_size, bias=<span class=\"hljs-literal\">True</span>)<br>        )<br></code></pre></td></tr></table></figure>\n<p>输入是条件 <code>c</code></p>\n<p>这里的 <code>c</code> 是把 <code>time_embedding</code> 和 <code>label_embedding</code> 加在一起</p>\n<p>在 <code>class DiT</code> 中使用了 <code>DiTBlock</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.blocks = nn.ModuleList([<br>            DiTBlock(hidden_size, num_heads, mlp_ratio=mlp_ratio) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(depth)<br>        ])<br></code></pre></td></tr></table></figure>\n<p>为什么使用 <code>nn.ModuleList</code> 而不是直接使用 <code>[]</code> 呢，使用 <code>nn.ModuleList</code> <code>pytorch</code> 才能看见这些模型，会为模型自动注册对应的参数。和 <code>nn.Sequential</code> 的区别在于，<code>nn.Sequential</code> 中数据会自动流过每一 <code>layer</code> 而 <code>nn.ModuleList</code> 更像是一个容器而已</p>\n<p>节选自 <code>DiT</code> 的 <code>forward</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = <span class=\"hljs-variable language_\">self</span>.x_embedder(x) + <span class=\"hljs-variable language_\">self</span>.pos_embed  <span class=\"hljs-comment\"># (N, T, D), where T = H * W / patch_size ** 2</span><br>        t = <span class=\"hljs-variable language_\">self</span>.t_embedder(t)                   <span class=\"hljs-comment\"># (N, D)</span><br>        y = <span class=\"hljs-variable language_\">self</span>.y_embedder(y, <span class=\"hljs-variable language_\">self</span>.training)    <span class=\"hljs-comment\"># (N, D)</span><br>        c = t + y                                <span class=\"hljs-comment\"># (N, D)</span><br>        <span class=\"hljs-keyword\">for</span> block <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.blocks:<br>            x = block(x, c)                      <span class=\"hljs-comment\"># (N, T, D)</span><br></code></pre></td></tr></table></figure>\n<p>可以看到条件就是把 time embedder, label embedder 的结果加在一起</p>\n<p>Forward 中的 <code>adaLN_modulation</code> 返回一个长度为 6 的列表，每一个元素就是 <code>[batch_size, hidden_size]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = <span class=\"hljs-variable language_\">self</span>.adaLN_modulation(c).chunk(<span class=\"hljs-number\">6</span>, dim=<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<p>一个 <code>DitBlock</code> 分为两个阶段：</p>\n<ul>\n<li><strong>MHSA（多头自注意力）*<em>负责*</em>“横向沟通”</strong>：它的作用是让不同的 Patch（Token）互相看一看，理解空间关系（比如：这个补丁里的猫耳朵和另一个补丁里的猫眼睛是什么关系）。</li>\n<li><strong>FFN（前馈网络）*<em>负责*</em>“纵向挖掘”</strong>：在注意力机制帮 Token 收集完周围的信息后，FFN 负责对这些收集到的信息进行深度处理和非线性变换，将原始特征转化为更高级的概念表示。</li>\n</ul>\n<p>代码实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = x + gate_msa.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.attn(modulate(<span class=\"hljs-variable language_\">self</span>.norm1(x), shift_msa, scale_msa))<br>        x = x + gate_mlp.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.mlp(modulate(<span class=\"hljs-variable language_\">self</span>.norm2(x), shift_mlp, scale_mlp))<br>        <br></code></pre></td></tr></table></figure>\n<p>其中 <code>modulate</code> 实现，残差连接 + （乘以 scale + shift）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">modulate</span>(<span class=\"hljs-params\">x, shift, scale</span>):<br>    <span class=\"hljs-keyword\">return</span> x * (<span class=\"hljs-number\">1</span> + scale.unsqueeze(<span class=\"hljs-number\">1</span>)) + shift.unsqueeze(<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<p>其中 <code>mlp</code> 就是 <code>FFN</code> 前馈网络(Pointwise Feedforward)</p>\n<p>多头注意力实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=<span class=\"hljs-literal\">True</span>, **block_kwargs)<br></code></pre></td></tr></table></figure>\n<p>前馈网络，<code>DitBlock</code> 中的定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.mlp = Mlp(in_features=hidden_size, hidden_features=mlp_hidden_dim, act_layer=approx_gelu, drop=<span class=\"hljs-number\">0</span>)<br></code></pre></td></tr></table></figure>\n<p>实际上 <code>Mlp</code> 中会经历一个先提升维度，再降低维度的过程</p>\n<p>以下是 <code>Mlp</code> 的具体实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Mlp</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, in_features, hidden_features, out_features, act_layer</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-comment\"># 第一层：将维度从 in_features (hidden_size) 增加到 hidden_features (通常是 4倍)</span><br>        <span class=\"hljs-variable language_\">self</span>.fc1 = nn.Linear(in_features, hidden_features)<br>        <span class=\"hljs-variable language_\">self</span>.act = act_layer()<br>        <span class=\"hljs-comment\"># 第二层：将维度从 hidden_features 还原回 in_features</span><br>        <span class=\"hljs-variable language_\">self</span>.fc2 = nn.Linear(hidden_features, in_features)<br>        <span class=\"hljs-variable language_\">self</span>.drop = nn.Dropout(<span class=\"hljs-number\">0</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = <span class=\"hljs-variable language_\">self</span>.fc1(x)  <span class=\"hljs-comment\"># 升维操作</span><br>        x = <span class=\"hljs-variable language_\">self</span>.act(x)  <span class=\"hljs-comment\"># 非线性激活</span><br>        x = <span class=\"hljs-variable language_\">self</span>.fc2(x)  <span class=\"hljs-comment\"># 降维操作</span><br>        <span class=\"hljs-keyword\">return</span> x<br><br></code></pre></td></tr></table></figure>\n<p>各个模块搭建好了，接下来可以看 <code>DiT</code> 了</p>\n<p>输入是 <code>x</code>  使用 <code>VAE</code> 进行下采样</p>\n<p><code>256, 256</code> -&gt; <code>32, 32</code> 论文中 <code>VAE</code> 后的通道数为 <code>4</code></p>\n<p>输入 <code>x</code> <code>batch_size, 4, 32, 32</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = <span class=\"hljs-variable language_\">self</span>.x_embedder(x) + <span class=\"hljs-variable language_\">self</span>.pos_embed  <span class=\"hljs-comment\"># (N, T, D), where T = H * W / patch_size ** 2</span><br></code></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"time-embedding\"><a class=\"markdownIt-Anchor\" href=\"#time-embedding\"></a> Time Embedding</h1>\n<p>we try to enrich the information of a time scalar!</p>\n<p>if we dont do so, the info that the model can get from the time scalar is poor.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, t</span>):<br>        <span class=\"hljs-comment\"># t_freq [batch, ..., t, dim]</span><br>        t_freq = <span class=\"hljs-variable language_\">self</span>.timestep_embedding(t, <span class=\"hljs-variable language_\">self</span>.frequency_embedding_size)<br>        t_emb = <span class=\"hljs-variable language_\">self</span>.mlp(t_freq)<br>        <span class=\"hljs-comment\"># t_emb [batch, ..., t, hidden]</span><br>        <span class=\"hljs-keyword\">return</span> t_emb<br></code></pre></td></tr></table></figure>\n<p>这里的 <code>t</code> 其实就是 <code>[batch, ]</code></p>\n<p>like <code>[4,4,4,4,4,4,...]</code></p>\n<p><code>timestep_embedding</code> using sin and cos to encode the number</p>\n<p>code is like:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@staticmethod</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">timestep_embedding</span>(<span class=\"hljs-params\">t, dim, max_period=<span class=\"hljs-number\">10000</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Create sinusoidal timestep embeddings.</span><br><span class=\"hljs-string\">        :param t: a 1-D Tensor of N indices, one per batch element.</span><br><span class=\"hljs-string\">                          These may be fractional.</span><br><span class=\"hljs-string\">        :param dim: the dimension of the output.</span><br><span class=\"hljs-string\">        :param max_period: controls the minimum frequency of the embeddings.</span><br><span class=\"hljs-string\">        :return: an (N, D) Tensor of positional embeddings.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py</span><br>        half = dim // <span class=\"hljs-number\">2</span><br>        <span class=\"hljs-comment\"># freqs = exp(-log(max_period) * [0, ..., half - 1] / half)</span><br>        <span class=\"hljs-comment\"># [dim // 2]</span><br>        freqs = torch.exp(<br>            -math.log(max_period) * torch.arange(start=<span class=\"hljs-number\">0</span>, end=half, dtype=torch.float32) / half<br>        ).to(device=t.device)<br>        <span class=\"hljs-comment\"># t 应该是位置信息 [batch, ..., t, 1]</span><br>        <span class=\"hljs-comment\"># freqs [1, dim // 2]</span><br>        <span class=\"hljs-comment\"># args -&gt; [batch, ..., t, dim // 2]</span><br>        args = t[:, <span class=\"hljs-literal\">None</span>].<span class=\"hljs-built_in\">float</span>() * freqs[<span class=\"hljs-literal\">None</span>]<br>        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-keyword\">if</span> dim % <span class=\"hljs-number\">2</span>:<br>            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :<span class=\"hljs-number\">1</span>])], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># embedding -&gt; [batch, ..., t, dim]</span><br>        <span class=\"hljs-keyword\">return</span> embedding<br></code></pre></td></tr></table></figure>\n<p>after the <code>timestep_embedding</code> we got the torch like [batch, dim]</p>\n<p>after the mlp, we got [batch, hidden]</p>\n<p>that is, TimestepEmbedder change from  <code>[batch]</code> to.<code>[batch, hidden]</code></p>\n<h1 id=\"labelembedder\"><a class=\"markdownIt-Anchor\" href=\"#labelembedder\"></a> LabelEmbedder</h1>\n<p>we are using <strong>Classifier-Free Guidance (CFG)</strong></p>\n<p>先考虑条件生成，模型有时候的生成结果和条件拟合的不够好。比如生成的图片结果和你的 <code>text prompt</code> 在语义上靠的还不够近。这时候，你希望生成的结果再靠近条件一点，和条件更加贴合！</p>\n<p>对于带条件的生成，我们往往需要先训练一个 Classifier，它的作用是对于给定的图像，输出它的分类类别。训练好了以后，他就有了看图的能力。</p>\n<p>在扩散的过程中，每次 sample 一个噪音，使用Classifier对 input 求梯度，用这个梯度去 modify sample出来的噪音，给这个noise以引导。然后用这个noise去更新 <code>x</code></p>\n<p>使用CFG就不用一个额外的classfier了。训练的时候，他会随机的丢弃标签，进行无标签的生成</p>\n<p>形式化来讲，每次的输入是一个</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>c</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">&lt;x_t,t,c&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n<p><strong>训练时：</strong></p>\n<p>我们有概率地（<code>p=0.1~0.2</code>）令</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>c</mi><mo>=</mo><mi mathvariant=\"normal\">∅</mi></mrow><annotation encoding=\"application/x-tex\">c = \\empty\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80556em;vertical-align:-0.05556em;\"></span><span class=\"mord\">∅</span></span></span></span></span></p>\n<p>这样模型同时学会了无条件生成和带条件生成</p>\n<p><strong>推理时</strong></p>\n<p>走两次</p>\n<ol>\n<li>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi>c</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">input = &lt;x_t,t, c&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.85396em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n</li>\n<li>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>&lt;</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∅</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">input=&lt;x_t,t,\\empty&gt;\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.85396em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.94444em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∅</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span></span></p>\n</li>\n</ol>\n<p>然后两个结果进行综合</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>ϵ</mi><mo>^</mo></mover><mo>=</mo><mi>s</mi><msub><mi>ϵ</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>s</mi><mo stretchy=\"false\">)</mo><msub><mi>ϵ</mi><mrow><mi>u</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\hat{\\epsilon}=s\\epsilon_{conditioned}+(1-s)\\epsilon_{unconditioned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>一般</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mn>5</mn><mo separator=\"true\">,</mo><mn>7</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">s = [5, 7]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">5</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">7</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>相当于有了一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>u</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\epsilon_{uncond}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 又有了一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\epsilon_{cond}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>  两者做差你就知道 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">cond</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">d</span></span></span></span> 的方向在哪里了！</p>\n<p><code>LabelEmbedder</code> 的 <code>__init__</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, num_classes, hidden_size, dropout_prob</span>):<br></code></pre></td></tr></table></figure>\n<p>这里 <code>dropout_prob</code> 应该是随机丢掉分类的概率</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">use_cfg_embedding = dropout_prob &gt; <span class=\"hljs-number\">0</span><br><span class=\"hljs-variable language_\">self</span>.embedding_table = nn.Embedding(num_classes  + use_cfg_embedding, hidden_size)<br></code></pre></td></tr></table></figure>\n<p>如果不打算使用 CFG 的话，dropout_prob 可以设置为一个负数</p>\n<p>如果设置为正数，表示 <code>dropout</code> 的概率</p>\n<p>那么在注册 <code>Embedding_table</code> 的时候会多加一个分类</p>\n<p><code>forward</code> 的定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, labels, train, force_drop_ids=<span class=\"hljs-literal\">None</span></span>):<br></code></pre></td></tr></table></figure>\n<p><code>train</code> 是一个 <code>boolean</code> 决定是否在训练模式</p>\n<p><code>labels</code> 是一个标签的列表 <code>[batch, ]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, labels, train, force_drop_ids=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-comment\"># 无分类引导</span><br>        use_dropout = <span class=\"hljs-variable language_\">self</span>.dropout_prob &gt; <span class=\"hljs-number\">0</span><br>        <span class=\"hljs-keyword\">if</span> (train <span class=\"hljs-keyword\">and</span> use_dropout) <span class=\"hljs-keyword\">or</span> (force_drop_ids <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>):<br>          <span class=\"hljs-comment\"># token_drop 随机把一些标签打掉</span><br>            labels = <span class=\"hljs-variable language_\">self</span>.token_drop(labels, force_drop_ids)<br>        <span class=\"hljs-comment\"># 然后把labels拿去做embeddings</span><br>        embeddings = <span class=\"hljs-variable language_\">self</span>.embedding_table(labels)<br>        <span class=\"hljs-keyword\">return</span> embeddings<br></code></pre></td></tr></table></figure>\n<p>总的来说，<code>Label_embedder</code></p>\n<p>do such changes</p>\n<p><code>[batchsize, ]</code> -&gt; <code>[batchsize, hidden_size]</code></p>\n<p>支持随机的把一些标签置空</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">labels = torch.where(drop_ids, <span class=\"hljs-variable language_\">self</span>.num_classes, labels)<br></code></pre></td></tr></table></figure>\n<p>如果 <code>drop_ids</code> 对应的位置是 <code>True</code> 就把这里的 <code>label_id</code> 值换成 <code>self.num_classes</code> 表示 <code>invalid</code></p>\n<h2 id=\"dit-block\"><a class=\"markdownIt-Anchor\" href=\"#dit-block\"></a> DIT Block</h2>\n<p><code>forward</code> 实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, c</span>):<br>        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = <span class=\"hljs-variable language_\">self</span>.adaLN_modulation(c).chunk(<span class=\"hljs-number\">6</span>, dim=<span class=\"hljs-number\">1</span>)<br>        x = x + gate_msa.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.attn(modulate(<span class=\"hljs-variable language_\">self</span>.norm1(x), shift_msa, scale_msa))<br>        x = x + gate_mlp.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.mlp(modulate(<span class=\"hljs-variable language_\">self</span>.norm2(x), shift_mlp, scale_mlp))<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<p>先看 <code>adaLN_modulation</code> 的实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.adaLN_modulation = nn.Sequential(<br>            nn.SiLU(),<br>            nn.Linear(hidden_size, <span class=\"hljs-number\">6</span> * hidden_size, bias=<span class=\"hljs-literal\">True</span>)<br>        )<br></code></pre></td></tr></table></figure>\n<p>输入是条件 <code>c</code></p>\n<p>这里的 <code>c</code> 是把 <code>time_embedding</code> 和 <code>label_embedding</code> 加在一起</p>\n<p>在 <code>class DiT</code> 中使用了 <code>DiTBlock</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.blocks = nn.ModuleList([<br>            DiTBlock(hidden_size, num_heads, mlp_ratio=mlp_ratio) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(depth)<br>        ])<br></code></pre></td></tr></table></figure>\n<p>为什么使用 <code>nn.ModuleList</code> 而不是直接使用 <code>[]</code> 呢，使用 <code>nn.ModuleList</code> <code>pytorch</code> 才能看见这些模型，会为模型自动注册对应的参数。和 <code>nn.Sequential</code> 的区别在于，<code>nn.Sequential</code> 中数据会自动流过每一 <code>layer</code> 而 <code>nn.ModuleList</code> 更像是一个容器而已</p>\n<p>节选自 <code>DiT</code> 的 <code>forward</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = <span class=\"hljs-variable language_\">self</span>.x_embedder(x) + <span class=\"hljs-variable language_\">self</span>.pos_embed  <span class=\"hljs-comment\"># (N, T, D), where T = H * W / patch_size ** 2</span><br>        t = <span class=\"hljs-variable language_\">self</span>.t_embedder(t)                   <span class=\"hljs-comment\"># (N, D)</span><br>        y = <span class=\"hljs-variable language_\">self</span>.y_embedder(y, <span class=\"hljs-variable language_\">self</span>.training)    <span class=\"hljs-comment\"># (N, D)</span><br>        c = t + y                                <span class=\"hljs-comment\"># (N, D)</span><br>        <span class=\"hljs-keyword\">for</span> block <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.blocks:<br>            x = block(x, c)                      <span class=\"hljs-comment\"># (N, T, D)</span><br></code></pre></td></tr></table></figure>\n<p>可以看到条件就是把 time embedder, label embedder 的结果加在一起</p>\n<p>Forward 中的 <code>adaLN_modulation</code> 返回一个长度为 6 的列表，每一个元素就是 <code>[batch_size, hidden_size]</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = <span class=\"hljs-variable language_\">self</span>.adaLN_modulation(c).chunk(<span class=\"hljs-number\">6</span>, dim=<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<p>一个 <code>DitBlock</code> 分为两个阶段：</p>\n<ul>\n<li><strong>MHSA（多头自注意力）*<em>负责*</em>“横向沟通”</strong>：它的作用是让不同的 Patch（Token）互相看一看，理解空间关系（比如：这个补丁里的猫耳朵和另一个补丁里的猫眼睛是什么关系）。</li>\n<li><strong>FFN（前馈网络）*<em>负责*</em>“纵向挖掘”</strong>：在注意力机制帮 Token 收集完周围的信息后，FFN 负责对这些收集到的信息进行深度处理和非线性变换，将原始特征转化为更高级的概念表示。</li>\n</ul>\n<p>代码实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = x + gate_msa.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.attn(modulate(<span class=\"hljs-variable language_\">self</span>.norm1(x), shift_msa, scale_msa))<br>        x = x + gate_mlp.unsqueeze(<span class=\"hljs-number\">1</span>) * <span class=\"hljs-variable language_\">self</span>.mlp(modulate(<span class=\"hljs-variable language_\">self</span>.norm2(x), shift_mlp, scale_mlp))<br>        <br></code></pre></td></tr></table></figure>\n<p>其中 <code>modulate</code> 实现，残差连接 + （乘以 scale + shift）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">modulate</span>(<span class=\"hljs-params\">x, shift, scale</span>):<br>    <span class=\"hljs-keyword\">return</span> x * (<span class=\"hljs-number\">1</span> + scale.unsqueeze(<span class=\"hljs-number\">1</span>)) + shift.unsqueeze(<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<p>其中 <code>mlp</code> 就是 <code>FFN</code> 前馈网络(Pointwise Feedforward)</p>\n<p>多头注意力实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=<span class=\"hljs-literal\">True</span>, **block_kwargs)<br></code></pre></td></tr></table></figure>\n<p>前馈网络，<code>DitBlock</code> 中的定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-variable language_\">self</span>.mlp = Mlp(in_features=hidden_size, hidden_features=mlp_hidden_dim, act_layer=approx_gelu, drop=<span class=\"hljs-number\">0</span>)<br></code></pre></td></tr></table></figure>\n<p>实际上 <code>Mlp</code> 中会经历一个先提升维度，再降低维度的过程</p>\n<p>以下是 <code>Mlp</code> 的具体实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Mlp</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, in_features, hidden_features, out_features, act_layer</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-comment\"># 第一层：将维度从 in_features (hidden_size) 增加到 hidden_features (通常是 4倍)</span><br>        <span class=\"hljs-variable language_\">self</span>.fc1 = nn.Linear(in_features, hidden_features)<br>        <span class=\"hljs-variable language_\">self</span>.act = act_layer()<br>        <span class=\"hljs-comment\"># 第二层：将维度从 hidden_features 还原回 in_features</span><br>        <span class=\"hljs-variable language_\">self</span>.fc2 = nn.Linear(hidden_features, in_features)<br>        <span class=\"hljs-variable language_\">self</span>.drop = nn.Dropout(<span class=\"hljs-number\">0</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = <span class=\"hljs-variable language_\">self</span>.fc1(x)  <span class=\"hljs-comment\"># 升维操作</span><br>        x = <span class=\"hljs-variable language_\">self</span>.act(x)  <span class=\"hljs-comment\"># 非线性激活</span><br>        x = <span class=\"hljs-variable language_\">self</span>.fc2(x)  <span class=\"hljs-comment\"># 降维操作</span><br>        <span class=\"hljs-keyword\">return</span> x<br><br></code></pre></td></tr></table></figure>\n<p>各个模块搭建好了，接下来可以看 <code>DiT</code> 了</p>\n<p>输入是 <code>x</code>  使用 <code>VAE</code> 进行下采样</p>\n<p><code>256, 256</code> -&gt; <code>32, 32</code> 论文中 <code>VAE</code> 后的通道数为 <code>4</code></p>\n<p>输入 <code>x</code> <code>batch_size, 4, 32, 32</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = <span class=\"hljs-variable language_\">self</span>.x_embedder(x) + <span class=\"hljs-variable language_\">self</span>.pos_embed  <span class=\"hljs-comment\"># (N, T, D), where T = H * W / patch_size ** 2</span><br></code></pre></td></tr></table></figure>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}